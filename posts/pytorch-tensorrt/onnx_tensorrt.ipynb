{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "title: \"Speeding up Inference with TensorRT\"\n",
        "author: \"chris\"\n",
        "date: 2024-05-27\n",
        "draft: false\n",
        "---"
      ],
      "metadata": {
        "id": "A9dd8Ap9hTgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "follow up post to pytorch quantization ... can we make it faster with GPU and TensorRT"
      ],
      "metadata": {
        "id": "BT5j7sb7gPJp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62hA1w2emFWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random colab error: \"A UTF-8 locale is required. Got ANSI_X3.4-1968\"\n",
        "# https://github.com/googlecolab/colabtools/issues/3409\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "n--1mEV8YsiY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get FasterRCNN as before with a resnet101 backbone..."
      ],
      "metadata": {
        "id": "QDiHrmX7GOtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "from torchvision.models.resnet import ResNet, Bottleneck, ResNet101_Weights\n",
        "from torchvision.models._utils import IntermediateLayerGetter\n",
        "from torchvision.models.detection.backbone_utils import BackboneWithFPN\n",
        "from torchvision.models.detection.faster_rcnn import FasterRCNN\n",
        "\n",
        "\n",
        "def resnet_101():\n",
        "    resnet = ResNet(block=Bottleneck, layers=[3, 4, 23, 3])\n",
        "    resnet.load_state_dict(ResNet101_Weights.DEFAULT.get_state_dict(progress=True))\n",
        "    return resnet\n",
        "\n",
        "\n",
        "resnet = resnet_101()\n",
        "\n",
        "# same as before, get intermediate layers and their output dimensions\n",
        "returned_layers = [1, 2, 3, 4]\n",
        "return_layers = {f\"layer{k}\": str(v) for v, k in enumerate(returned_layers)}\n",
        "in_channels_list = []\n",
        "for k1, m1 in resnet.named_children():\n",
        "    if 'layer' in k1:\n",
        "        in_channels_list.append((m1[-1].bn3.num_features))\n",
        "\n",
        "rcnn = FasterRCNN(\n",
        "    BackboneWithFPN(\n",
        "        backbone=resnet,\n",
        "        return_layers=return_layers,\n",
        "        in_channels_list=in_channels_list,\n",
        "        out_channels=256,\n",
        "        extra_blocks=None,\n",
        "        norm_layer=None,\n",
        "        ),\n",
        "    num_classes=2\n",
        ")\n",
        "\n",
        "rcnn.eval()"
      ],
      "metadata": {
        "id": "d4JoXjgZyB_D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "time the RCNN on both CPU and GPU.  I don't recall what the specs were the last time I used colab to profile the inference time so I'll document that here as well.  I'm using a T4 GPU and the following CPU"
      ],
      "metadata": {
        "id": "CpEzZqORGVmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat /proc/cpuinfo  | grep 'name' | uniq\n",
        "!lscpu | grep 'name'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OLr1uWrGsct",
        "outputId": "fa2236d5-0840-479b-abff-b1bae1ea82d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEOPFQatLmMy",
        "outputId": "fc5a4674-a2ca-49d8-dbc9-db204c3a9e6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA L4 (UUID: GPU-393b8fe1-1ca8-7aaf-94b9-04eef8e2fda5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random image\n",
        "image = torch.rand(3, 200, 200)\n",
        "# put on CPU\n",
        "rcnn.to(torch.device('cpu'))\n",
        "image_cpu = image.to(torch.device('cpu'))\n",
        "\n",
        "with torch.no_grad():\n",
        "    cpu_time = %timeit -o rcnn([image_cpu])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwJ7sfCI7sjl",
        "outputId": "0f904955-6634-4ed8-cd69-3f27840ada77"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.47 s ± 137 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# on GPU\n",
        "rcnn_gpu = deepcopy(rcnn).to(torch.device('cuda'))\n",
        "# rcnn.to(torch.device('cuda'))\n",
        "image_gpu = image.to(torch.device('cuda'))\n",
        "\n",
        "with torch.no_grad():\n",
        "    gpu_time = %timeit -o rcnn_gpu([image_gpu])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksm0gZ6p72xB",
        "outputId": "26a679b0-e7f7-4185-f34c-bc6b294e984e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37.9 ms ± 235 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can also test with half precision..."
      ],
      "metadata": {
        "id": "bg5cr_ZWNu1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcnn_gpu_half = rcnn_gpu.half().to(torch.device('cuda'))\n",
        "input_half = image_gpu.half()\n",
        "\n",
        "with torch.no_grad():\n",
        "    gpu_half_time = %timeit -o rcnn_gpu_half([input_half])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmnqW54iM_l7",
        "outputId": "fc71979d-2d72-4c39-f0fd-4e5d22769230"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29.1 ms ± 1.13 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "also re-clock the quantized model using FX Graph Mode since it's performance is also CPU specific"
      ],
      "metadata": {
        "id": "1u_V_fCuFmLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from torch.ao.quantization import quantize_fx\n",
        "from torch.ao.quantization.qconfig_mapping import get_default_qconfig_mapping\n",
        "\n",
        "\n",
        "quant_rcnn = deepcopy(rcnn)\n",
        "\n",
        "qconfig_mapping = get_default_qconfig_mapping(\"fbgemm\")  # \"qnnpack\"\n",
        "# assume calibrated already\n",
        "quant_rcnn.eval()\n",
        "quant_rcnn.to(torch.device('cpu'))\n",
        "# prepare and quantize\n",
        "example_input = torch.randn(1, 3, 200, 200)\n",
        "quant_rcnn.backbone = quantize_fx.prepare_fx(quant_rcnn.backbone, qconfig_mapping, example_input)\n",
        "quant_rcnn.backbone = quantize_fx.convert_fx(quant_rcnn.backbone)\n",
        "\n",
        "script_module = torch.jit.script(quant_rcnn)\n",
        "script_module.save(\"./quant_rcnn.pt\")\n",
        "quant_rcnn_jit = torch.jit.load(\"./quant_rcnn.pt\", map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "wbJ0CJBaBmav"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# warmup\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter('ignore')\n",
        "    for _ in range(3):\n",
        "        __ = quant_rcnn_jit([image_cpu])\n",
        "\n",
        "with torch.no_grad():\n",
        "    quant_time = %timeit -o quant_rcnn_jit([image_cpu])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuUDsHb9Dx0c",
        "outputId": "da6c8f97-c132-47c0-d677-b81839aa1003"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "652 ms ± 81 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLbX86tVZCg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below I convert the float model to onnx.  I went through onnx because that used to be the preferred way of converting to TensorRT.  However, the onnx conversion didn't play well with the `trtexec` command line utility for TensorRT regardless of the torch to onnx exporter used.  Below the [old torch script onnx converter](https://pytorch.org/docs/stable/onnx_torchscript.html) is used but the [newer 'dynamo' converter](https://pytorch.org/docs/stable/onnx_dynamo.html) also had issues.  Thankfully PyTorch has a very easy TensorRT API now, but I keep the ONNX model and evaluate it to see if a simple conversion offers any benefits."
      ],
      "metadata": {
        "id": "PJGIDCMxH6MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "Ak4nk7AmzI6h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "torch.onnx.export(\n",
        "    deepcopy(rcnn),\n",
        "    # onnx wants a tuple of 2 or bombs:  https://github.com/zhiqwang/yolort/issues/485\n",
        "    ([torch.randn(3, 200, 200)], ),\n",
        "    \"rcnn.onnx\",\n",
        "    # do_constant_folding=True,\n",
        "    opset_version = 11,\n",
        "    verbose=False\n",
        "    )\n",
        "# make sure the onnx proto is valid\n",
        "rcnn_onnx = onnx.load(\"rcnn.onnx\")\n",
        "onnx.checker.check_model(rcnn_onnx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSVGaGV7fj69",
        "outputId": "bba7b721-159f-4c2b-ce53-ae5ca800489b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4009: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  (torch.floor((input.size(i + 2).float() * torch.tensor(scale_factors[i], dtype=torch.float32)).float()))\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py:166: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py:168: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1559: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert condition, message\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/transform.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(s, dtype=torch.float32, device=boxes.device)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/transform.py:309: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset9.py:5858: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run inference on onnx model, make sure outputs are as expected, then clock-it..."
      ],
      "metadata": {
        "id": "zBYYNDkcVeVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "import numpy as np\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"rcnn.onnx\", providers=[\"CPUExecutionProvider\"])\n",
        "# good to make sure inputs are as expected: '[i.name for i in ort_session.get_inputs()]'\n",
        "\n",
        "# onnx wants numpy tensor not torch tensor\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# get a prediction.  onnx doesn't need a list input like torch model does\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(image)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)"
      ],
      "metadata": {
        "id": "1sM1p_37QgFn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# onxx outputs are list of three arrays corresponding to 'boxes', 'labels', and 'scores'\n",
        "print(\"onnx out shapes: \", [arr.shape for arr in ort_outs])\n",
        "# quant model out is tuple of (losses, outputs)\n",
        "torch_outs = __[1][0]\n",
        "print(\"torch out shapes: \", [torch_outs[k].shape for k in torch_outs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9Oy1RW0VUnm",
        "outputId": "c63ab32c-123a-421b-e5ed-2695362647f0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "onnx out shapes:  [(100, 4), (100,), (100,)]\n",
            "torch out shapes:  [torch.Size([100, 4]), torch.Size([100]), torch.Size([100])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_time = %timeit -o ort_session.run(None, ort_inputs)\n",
        "\n",
        "# sess = onnxruntime.InferenceSession('rcnn.onnx', providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider'])\n",
        "# onnx_trt_time = %timeit -o sess.run(None, ort_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSUs1zDVWdVt",
        "outputId": "45740ebf-76f6-47eb-8f1c-dfec0fa29f55"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.05 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# more steps for using trtexec which has issues with rcnn input shape\n",
        "# !sudo apt-get install tensorrt\n",
        "# !pip install tensorrt\n",
        "# !ls /usr/src/tensorrt/bin  # make sure trtexec is there\n",
        "# !/usr/src/tensorrt/bin/trtexec --onnx=rcnn.onnx --saveEngine=rcnn_engine_pytorch.trt"
      ],
      "metadata": {
        "id": "QXijN-ogNnd6"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use the handy `torch-tensorrt` package..."
      ],
      "metadata": {
        "id": "RYHMkM1ViZCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!python -m pip install torch-tensorrt"
      ],
      "metadata": {
        "id": "VDRRz-Fgj2D3"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "rcnn.to(device)"
      ],
      "metadata": {
        "id": "kIJbkDBVnrc4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_tensorrt\n",
        "\n",
        "# need to wrap rcnn inputs in list\n",
        "inputs = [[torch.randn(3, 200, 200).to(\"cuda\")]]  # .half()]\n",
        "\n",
        "trt_model = torch_tensorrt.compile(\n",
        "    deepcopy(rcnn),\n",
        "    ir=\"torch_compile\",\n",
        "    # frontend api below complains about input shape\n",
        "    # backend=\"torch_tensorrt\",\n",
        "    inputs=inputs,\n",
        "    enabled_precisions={torch.float32},  #  {torch.half}\n",
        "    debug=True,\n",
        "    workspace_size=20 << 30,\n",
        "    min_block_size=7,\n",
        "    torch_executed_ops={},\n",
        ")"
      ],
      "metadata": {
        "id": "hkLAvXMEXBRj"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# contrary to docs, first run actually compiles model\n",
        "# https://pytorch.org/TensorRT/tutorials/_rendered_examples/dynamo/torch_compile_resnet_example.html#torch-compile-resnet\n",
        "outputs = trt_model(*inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8cKcrb-XO74",
        "outputId": "45273ee3-5d63-4633-8c3a-63ea3fb13571"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "    %_tensor_constant140 : [num_users=1] = get_attr[target=_tensor_constant140]\n",
            "    %_tensor_constant141 : [num_users=1] = get_attr[target=_tensor_constant141]\n",
            "    %_native_batch_norm_legit_no_training_69 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_69, %_param_constant208, %_param_constant209, %_tensor_constant140, %_tensor_constant141, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_209 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_69, 0), kwargs = {})\n",
            "    %add_28 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_209, %relu_63), kwargs = {})\n",
            "    %relu_66 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_28,), kwargs = {})\n",
            "    %_param_constant210 : [num_users=1] = get_attr[target=_param_constant210]\n",
            "    %convolution_70 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_66, %_param_constant210, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant211 : [num_users=1] = get_attr[target=_param_constant211]\n",
            "    %_param_constant212 : [num_users=1] = get_attr[target=_param_constant212]\n",
            "    %_tensor_constant142 : [num_users=1] = get_attr[target=_tensor_constant142]\n",
            "    %_tensor_constant143 : [num_users=1] = get_attr[target=_tensor_constant143]\n",
            "    %_native_batch_norm_legit_no_training_70 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_70, %_param_constant211, %_param_constant212, %_tensor_constant142, %_tensor_constant143, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_212 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_70, 0), kwargs = {})\n",
            "    %relu_67 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_212,), kwargs = {})\n",
            "    %_param_constant213 : [num_users=1] = get_attr[target=_param_constant213]\n",
            "    %convolution_71 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_67, %_param_constant213, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant214 : [num_users=1] = get_attr[target=_param_constant214]\n",
            "    %_param_constant215 : [num_users=1] = get_attr[target=_param_constant215]\n",
            "    %_tensor_constant144 : [num_users=1] = get_attr[target=_tensor_constant144]\n",
            "    %_tensor_constant145 : [num_users=1] = get_attr[target=_tensor_constant145]\n",
            "    %_native_batch_norm_legit_no_training_71 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_71, %_param_constant214, %_param_constant215, %_tensor_constant144, %_tensor_constant145, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_215 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_71, 0), kwargs = {})\n",
            "    %relu_68 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_215,), kwargs = {})\n",
            "    %_param_constant216 : [num_users=1] = get_attr[target=_param_constant216]\n",
            "    %convolution_72 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_68, %_param_constant216, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant217 : [num_users=1] = get_attr[target=_param_constant217]\n",
            "    %_param_constant218 : [num_users=1] = get_attr[target=_param_constant218]\n",
            "    %_tensor_constant146 : [num_users=1] = get_attr[target=_tensor_constant146]\n",
            "    %_tensor_constant147 : [num_users=1] = get_attr[target=_tensor_constant147]\n",
            "    %_native_batch_norm_legit_no_training_72 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_72, %_param_constant217, %_param_constant218, %_tensor_constant146, %_tensor_constant147, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_218 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_72, 0), kwargs = {})\n",
            "    %add_29 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_218, %relu_66), kwargs = {})\n",
            "    %relu_69 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_29,), kwargs = {})\n",
            "    %_param_constant219 : [num_users=1] = get_attr[target=_param_constant219]\n",
            "    %convolution_73 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_69, %_param_constant219, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant220 : [num_users=1] = get_attr[target=_param_constant220]\n",
            "    %_param_constant221 : [num_users=1] = get_attr[target=_param_constant221]\n",
            "    %_tensor_constant148 : [num_users=1] = get_attr[target=_tensor_constant148]\n",
            "    %_tensor_constant149 : [num_users=1] = get_attr[target=_tensor_constant149]\n",
            "    %_native_batch_norm_legit_no_training_73 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_73, %_param_constant220, %_param_constant221, %_tensor_constant148, %_tensor_constant149, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_221 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_73, 0), kwargs = {})\n",
            "    %relu_70 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_221,), kwargs = {})\n",
            "    %_param_constant222 : [num_users=1] = get_attr[target=_param_constant222]\n",
            "    %convolution_74 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_70, %_param_constant222, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant223 : [num_users=1] = get_attr[target=_param_constant223]\n",
            "    %_param_constant224 : [num_users=1] = get_attr[target=_param_constant224]\n",
            "    %_tensor_constant150 : [num_users=1] = get_attr[target=_tensor_constant150]\n",
            "    %_tensor_constant151 : [num_users=1] = get_attr[target=_tensor_constant151]\n",
            "    %_native_batch_norm_legit_no_training_74 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_74, %_param_constant223, %_param_constant224, %_tensor_constant150, %_tensor_constant151, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_224 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_74, 0), kwargs = {})\n",
            "    %relu_71 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_224,), kwargs = {})\n",
            "    %_param_constant225 : [num_users=1] = get_attr[target=_param_constant225]\n",
            "    %convolution_75 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_71, %_param_constant225, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant226 : [num_users=1] = get_attr[target=_param_constant226]\n",
            "    %_param_constant227 : [num_users=1] = get_attr[target=_param_constant227]\n",
            "    %_tensor_constant152 : [num_users=1] = get_attr[target=_tensor_constant152]\n",
            "    %_tensor_constant153 : [num_users=1] = get_attr[target=_tensor_constant153]\n",
            "    %_native_batch_norm_legit_no_training_75 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_75, %_param_constant226, %_param_constant227, %_tensor_constant152, %_tensor_constant153, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_227 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_75, 0), kwargs = {})\n",
            "    %add_30 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_227, %relu_69), kwargs = {})\n",
            "    %relu_72 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_30,), kwargs = {})\n",
            "    %_param_constant228 : [num_users=1] = get_attr[target=_param_constant228]\n",
            "    %convolution_76 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_72, %_param_constant228, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant229 : [num_users=1] = get_attr[target=_param_constant229]\n",
            "    %_param_constant230 : [num_users=1] = get_attr[target=_param_constant230]\n",
            "    %_tensor_constant154 : [num_users=1] = get_attr[target=_tensor_constant154]\n",
            "    %_tensor_constant155 : [num_users=1] = get_attr[target=_tensor_constant155]\n",
            "    %_native_batch_norm_legit_no_training_76 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_76, %_param_constant229, %_param_constant230, %_tensor_constant154, %_tensor_constant155, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_230 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_76, 0), kwargs = {})\n",
            "    %relu_73 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_230,), kwargs = {})\n",
            "    %_param_constant231 : [num_users=1] = get_attr[target=_param_constant231]\n",
            "    %convolution_77 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_73, %_param_constant231, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant232 : [num_users=1] = get_attr[target=_param_constant232]\n",
            "    %_param_constant233 : [num_users=1] = get_attr[target=_param_constant233]\n",
            "    %_tensor_constant156 : [num_users=1] = get_attr[target=_tensor_constant156]\n",
            "    %_tensor_constant157 : [num_users=1] = get_attr[target=_tensor_constant157]\n",
            "    %_native_batch_norm_legit_no_training_77 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_77, %_param_constant232, %_param_constant233, %_tensor_constant156, %_tensor_constant157, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_233 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_77, 0), kwargs = {})\n",
            "    %relu_74 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_233,), kwargs = {})\n",
            "    %_param_constant234 : [num_users=1] = get_attr[target=_param_constant234]\n",
            "    %convolution_78 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_74, %_param_constant234, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant235 : [num_users=1] = get_attr[target=_param_constant235]\n",
            "    %_param_constant236 : [num_users=1] = get_attr[target=_param_constant236]\n",
            "    %_tensor_constant158 : [num_users=1] = get_attr[target=_tensor_constant158]\n",
            "    %_tensor_constant159 : [num_users=1] = get_attr[target=_tensor_constant159]\n",
            "    %_native_batch_norm_legit_no_training_78 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_78, %_param_constant235, %_param_constant236, %_tensor_constant158, %_tensor_constant159, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_236 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_78, 0), kwargs = {})\n",
            "    %add_31 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_236, %relu_72), kwargs = {})\n",
            "    %relu_75 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_31,), kwargs = {})\n",
            "    %_param_constant237 : [num_users=1] = get_attr[target=_param_constant237]\n",
            "    %convolution_79 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_75, %_param_constant237, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant238 : [num_users=1] = get_attr[target=_param_constant238]\n",
            "    %_param_constant239 : [num_users=1] = get_attr[target=_param_constant239]\n",
            "    %_tensor_constant160 : [num_users=1] = get_attr[target=_tensor_constant160]\n",
            "    %_tensor_constant161 : [num_users=1] = get_attr[target=_tensor_constant161]\n",
            "    %_native_batch_norm_legit_no_training_79 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_79, %_param_constant238, %_param_constant239, %_tensor_constant160, %_tensor_constant161, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_239 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_79, 0), kwargs = {})\n",
            "    %relu_76 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_239,), kwargs = {})\n",
            "    %_param_constant240 : [num_users=1] = get_attr[target=_param_constant240]\n",
            "    %convolution_80 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_76, %_param_constant240, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant241 : [num_users=1] = get_attr[target=_param_constant241]\n",
            "    %_param_constant242 : [num_users=1] = get_attr[target=_param_constant242]\n",
            "    %_tensor_constant162 : [num_users=1] = get_attr[target=_tensor_constant162]\n",
            "    %_tensor_constant163 : [num_users=1] = get_attr[target=_tensor_constant163]\n",
            "    %_native_batch_norm_legit_no_training_80 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_80, %_param_constant241, %_param_constant242, %_tensor_constant162, %_tensor_constant163, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_242 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_80, 0), kwargs = {})\n",
            "    %relu_77 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_242,), kwargs = {})\n",
            "    %_param_constant243 : [num_users=1] = get_attr[target=_param_constant243]\n",
            "    %convolution_81 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_77, %_param_constant243, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant244 : [num_users=1] = get_attr[target=_param_constant244]\n",
            "    %_param_constant245 : [num_users=1] = get_attr[target=_param_constant245]\n",
            "    %_tensor_constant164 : [num_users=1] = get_attr[target=_tensor_constant164]\n",
            "    %_tensor_constant165 : [num_users=1] = get_attr[target=_tensor_constant165]\n",
            "    %_native_batch_norm_legit_no_training_81 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_81, %_param_constant244, %_param_constant245, %_tensor_constant164, %_tensor_constant165, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_245 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_81, 0), kwargs = {})\n",
            "    %add_32 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_245, %relu_75), kwargs = {})\n",
            "    %relu_78 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_32,), kwargs = {})\n",
            "    %_param_constant246 : [num_users=1] = get_attr[target=_param_constant246]\n",
            "    %convolution_82 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_78, %_param_constant246, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant247 : [num_users=1] = get_attr[target=_param_constant247]\n",
            "    %_param_constant248 : [num_users=1] = get_attr[target=_param_constant248]\n",
            "    %_tensor_constant166 : [num_users=1] = get_attr[target=_tensor_constant166]\n",
            "    %_tensor_constant167 : [num_users=1] = get_attr[target=_tensor_constant167]\n",
            "    %_native_batch_norm_legit_no_training_82 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_82, %_param_constant247, %_param_constant248, %_tensor_constant166, %_tensor_constant167, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_248 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_82, 0), kwargs = {})\n",
            "    %relu_79 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_248,), kwargs = {})\n",
            "    %_param_constant249 : [num_users=1] = get_attr[target=_param_constant249]\n",
            "    %convolution_83 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_79, %_param_constant249, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant250 : [num_users=1] = get_attr[target=_param_constant250]\n",
            "    %_param_constant251 : [num_users=1] = get_attr[target=_param_constant251]\n",
            "    %_tensor_constant168 : [num_users=1] = get_attr[target=_tensor_constant168]\n",
            "    %_tensor_constant169 : [num_users=1] = get_attr[target=_tensor_constant169]\n",
            "    %_native_batch_norm_legit_no_training_83 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_83, %_param_constant250, %_param_constant251, %_tensor_constant168, %_tensor_constant169, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_251 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_83, 0), kwargs = {})\n",
            "    %relu_80 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_251,), kwargs = {})\n",
            "    %_param_constant252 : [num_users=1] = get_attr[target=_param_constant252]\n",
            "    %convolution_84 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_80, %_param_constant252, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant253 : [num_users=1] = get_attr[target=_param_constant253]\n",
            "    %_param_constant254 : [num_users=1] = get_attr[target=_param_constant254]\n",
            "    %_tensor_constant170 : [num_users=1] = get_attr[target=_tensor_constant170]\n",
            "    %_tensor_constant171 : [num_users=1] = get_attr[target=_tensor_constant171]\n",
            "    %_native_batch_norm_legit_no_training_84 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_84, %_param_constant253, %_param_constant254, %_tensor_constant170, %_tensor_constant171, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_254 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_84, 0), kwargs = {})\n",
            "    %add_33 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_254, %relu_78), kwargs = {})\n",
            "    %relu_81 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_33,), kwargs = {})\n",
            "    %_param_constant255 : [num_users=1] = get_attr[target=_param_constant255]\n",
            "    %convolution_85 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_81, %_param_constant255, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant256 : [num_users=1] = get_attr[target=_param_constant256]\n",
            "    %_param_constant257 : [num_users=1] = get_attr[target=_param_constant257]\n",
            "    %_tensor_constant172 : [num_users=1] = get_attr[target=_tensor_constant172]\n",
            "    %_tensor_constant173 : [num_users=1] = get_attr[target=_tensor_constant173]\n",
            "    %_native_batch_norm_legit_no_training_85 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_85, %_param_constant256, %_param_constant257, %_tensor_constant172, %_tensor_constant173, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_257 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_85, 0), kwargs = {})\n",
            "    %relu_82 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_257,), kwargs = {})\n",
            "    %_param_constant258 : [num_users=1] = get_attr[target=_param_constant258]\n",
            "    %convolution_86 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_82, %_param_constant258, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant259 : [num_users=1] = get_attr[target=_param_constant259]\n",
            "    %_param_constant260 : [num_users=1] = get_attr[target=_param_constant260]\n",
            "    %_tensor_constant174 : [num_users=1] = get_attr[target=_tensor_constant174]\n",
            "    %_tensor_constant175 : [num_users=1] = get_attr[target=_tensor_constant175]\n",
            "    %_native_batch_norm_legit_no_training_86 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_86, %_param_constant259, %_param_constant260, %_tensor_constant174, %_tensor_constant175, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_260 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_86, 0), kwargs = {})\n",
            "    %relu_83 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_260,), kwargs = {})\n",
            "    %_param_constant261 : [num_users=1] = get_attr[target=_param_constant261]\n",
            "    %convolution_87 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_83, %_param_constant261, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant262 : [num_users=1] = get_attr[target=_param_constant262]\n",
            "    %_param_constant263 : [num_users=1] = get_attr[target=_param_constant263]\n",
            "    %_tensor_constant176 : [num_users=1] = get_attr[target=_tensor_constant176]\n",
            "    %_tensor_constant177 : [num_users=1] = get_attr[target=_tensor_constant177]\n",
            "    %_native_batch_norm_legit_no_training_87 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_87, %_param_constant262, %_param_constant263, %_tensor_constant176, %_tensor_constant177, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_263 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_87, 0), kwargs = {})\n",
            "    %add_34 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_263, %relu_81), kwargs = {})\n",
            "    %relu_84 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_34,), kwargs = {})\n",
            "    %_param_constant264 : [num_users=1] = get_attr[target=_param_constant264]\n",
            "    %convolution_88 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_84, %_param_constant264, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant265 : [num_users=1] = get_attr[target=_param_constant265]\n",
            "    %_param_constant266 : [num_users=1] = get_attr[target=_param_constant266]\n",
            "    %_tensor_constant178 : [num_users=1] = get_attr[target=_tensor_constant178]\n",
            "    %_tensor_constant179 : [num_users=1] = get_attr[target=_tensor_constant179]\n",
            "    %_native_batch_norm_legit_no_training_88 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_88, %_param_constant265, %_param_constant266, %_tensor_constant178, %_tensor_constant179, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_266 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_88, 0), kwargs = {})\n",
            "    %relu_85 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_266,), kwargs = {})\n",
            "    %_param_constant267 : [num_users=1] = get_attr[target=_param_constant267]\n",
            "    %convolution_89 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_85, %_param_constant267, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant268 : [num_users=1] = get_attr[target=_param_constant268]\n",
            "    %_param_constant269 : [num_users=1] = get_attr[target=_param_constant269]\n",
            "    %_tensor_constant180 : [num_users=1] = get_attr[target=_tensor_constant180]\n",
            "    %_tensor_constant181 : [num_users=1] = get_attr[target=_tensor_constant181]\n",
            "    %_native_batch_norm_legit_no_training_89 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_89, %_param_constant268, %_param_constant269, %_tensor_constant180, %_tensor_constant181, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_269 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_89, 0), kwargs = {})\n",
            "    %relu_86 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_269,), kwargs = {})\n",
            "    %_param_constant270 : [num_users=1] = get_attr[target=_param_constant270]\n",
            "    %convolution_90 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_86, %_param_constant270, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant271 : [num_users=1] = get_attr[target=_param_constant271]\n",
            "    %_param_constant272 : [num_users=1] = get_attr[target=_param_constant272]\n",
            "    %_tensor_constant182 : [num_users=1] = get_attr[target=_tensor_constant182]\n",
            "    %_tensor_constant183 : [num_users=1] = get_attr[target=_tensor_constant183]\n",
            "    %_native_batch_norm_legit_no_training_90 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_90, %_param_constant271, %_param_constant272, %_tensor_constant182, %_tensor_constant183, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_272 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_90, 0), kwargs = {})\n",
            "    %add_35 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_272, %relu_84), kwargs = {})\n",
            "    %relu_87 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_35,), kwargs = {})\n",
            "    %_param_constant273 : [num_users=1] = get_attr[target=_param_constant273]\n",
            "    %convolution_91 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_87, %_param_constant273, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant274 : [num_users=1] = get_attr[target=_param_constant274]\n",
            "    %_param_constant275 : [num_users=1] = get_attr[target=_param_constant275]\n",
            "    %_tensor_constant184 : [num_users=1] = get_attr[target=_tensor_constant184]\n",
            "    %_tensor_constant185 : [num_users=1] = get_attr[target=_tensor_constant185]\n",
            "    %_native_batch_norm_legit_no_training_91 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_91, %_param_constant274, %_param_constant275, %_tensor_constant184, %_tensor_constant185, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_275 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_91, 0), kwargs = {})\n",
            "    %relu_88 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_275,), kwargs = {})\n",
            "    %_param_constant276 : [num_users=1] = get_attr[target=_param_constant276]\n",
            "    %convolution_92 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_88, %_param_constant276, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant277 : [num_users=1] = get_attr[target=_param_constant277]\n",
            "    %_param_constant278 : [num_users=1] = get_attr[target=_param_constant278]\n",
            "    %_tensor_constant186 : [num_users=1] = get_attr[target=_tensor_constant186]\n",
            "    %_tensor_constant187 : [num_users=1] = get_attr[target=_tensor_constant187]\n",
            "    %_native_batch_norm_legit_no_training_92 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_92, %_param_constant277, %_param_constant278, %_tensor_constant186, %_tensor_constant187, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_278 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_92, 0), kwargs = {})\n",
            "    %relu_89 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_278,), kwargs = {})\n",
            "    %_param_constant279 : [num_users=1] = get_attr[target=_param_constant279]\n",
            "    %convolution_93 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_89, %_param_constant279, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant280 : [num_users=1] = get_attr[target=_param_constant280]\n",
            "    %_param_constant281 : [num_users=1] = get_attr[target=_param_constant281]\n",
            "    %_tensor_constant188 : [num_users=1] = get_attr[target=_tensor_constant188]\n",
            "    %_tensor_constant189 : [num_users=1] = get_attr[target=_tensor_constant189]\n",
            "    %_native_batch_norm_legit_no_training_93 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_93, %_param_constant280, %_param_constant281, %_tensor_constant188, %_tensor_constant189, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_281 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_93, 0), kwargs = {})\n",
            "    %add_36 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_281, %relu_87), kwargs = {})\n",
            "    %relu_90 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_36,), kwargs = {})\n",
            "    %_param_constant282 : [num_users=1] = get_attr[target=_param_constant282]\n",
            "    %convolution_94 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_90, %_param_constant282, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant283 : [num_users=1] = get_attr[target=_param_constant283]\n",
            "    %_param_constant284 : [num_users=1] = get_attr[target=_param_constant284]\n",
            "    %_tensor_constant190 : [num_users=1] = get_attr[target=_tensor_constant190]\n",
            "    %_tensor_constant191 : [num_users=1] = get_attr[target=_tensor_constant191]\n",
            "    %_native_batch_norm_legit_no_training_94 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_94, %_param_constant283, %_param_constant284, %_tensor_constant190, %_tensor_constant191, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_284 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_94, 0), kwargs = {})\n",
            "    %relu_91 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_284,), kwargs = {})\n",
            "    %_param_constant285 : [num_users=1] = get_attr[target=_param_constant285]\n",
            "    %convolution_95 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_91, %_param_constant285, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant286 : [num_users=1] = get_attr[target=_param_constant286]\n",
            "    %_param_constant287 : [num_users=1] = get_attr[target=_param_constant287]\n",
            "    %_tensor_constant192 : [num_users=1] = get_attr[target=_tensor_constant192]\n",
            "    %_tensor_constant193 : [num_users=1] = get_attr[target=_tensor_constant193]\n",
            "    %_native_batch_norm_legit_no_training_95 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_95, %_param_constant286, %_param_constant287, %_tensor_constant192, %_tensor_constant193, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_287 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_95, 0), kwargs = {})\n",
            "    %relu_92 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_287,), kwargs = {})\n",
            "    %_param_constant288 : [num_users=1] = get_attr[target=_param_constant288]\n",
            "    %convolution_96 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_92, %_param_constant288, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant289 : [num_users=1] = get_attr[target=_param_constant289]\n",
            "    %_param_constant290 : [num_users=1] = get_attr[target=_param_constant290]\n",
            "    %_tensor_constant194 : [num_users=1] = get_attr[target=_tensor_constant194]\n",
            "    %_tensor_constant195 : [num_users=1] = get_attr[target=_tensor_constant195]\n",
            "    %_native_batch_norm_legit_no_training_96 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_96, %_param_constant289, %_param_constant290, %_tensor_constant194, %_tensor_constant195, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_290 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_96, 0), kwargs = {})\n",
            "    %_param_constant291 : [num_users=1] = get_attr[target=_param_constant291]\n",
            "    %convolution_97 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_90, %_param_constant291, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant292 : [num_users=1] = get_attr[target=_param_constant292]\n",
            "    %_param_constant293 : [num_users=1] = get_attr[target=_param_constant293]\n",
            "    %_tensor_constant196 : [num_users=1] = get_attr[target=_tensor_constant196]\n",
            "    %_tensor_constant197 : [num_users=1] = get_attr[target=_tensor_constant197]\n",
            "    %_native_batch_norm_legit_no_training_97 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_97, %_param_constant292, %_param_constant293, %_tensor_constant196, %_tensor_constant197, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_293 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_97, 0), kwargs = {})\n",
            "    %add_37 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_290, %getitem_293), kwargs = {})\n",
            "    %relu_93 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_37,), kwargs = {})\n",
            "    %_param_constant294 : [num_users=1] = get_attr[target=_param_constant294]\n",
            "    %convolution_98 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_93, %_param_constant294, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant295 : [num_users=1] = get_attr[target=_param_constant295]\n",
            "    %_param_constant296 : [num_users=1] = get_attr[target=_param_constant296]\n",
            "    %_tensor_constant198 : [num_users=1] = get_attr[target=_tensor_constant198]\n",
            "    %_tensor_constant199 : [num_users=1] = get_attr[target=_tensor_constant199]\n",
            "    %_native_batch_norm_legit_no_training_98 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_98, %_param_constant295, %_param_constant296, %_tensor_constant198, %_tensor_constant199, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_296 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_98, 0), kwargs = {})\n",
            "    %relu_94 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_296,), kwargs = {})\n",
            "    %_param_constant297 : [num_users=1] = get_attr[target=_param_constant297]\n",
            "    %convolution_99 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_94, %_param_constant297, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant298 : [num_users=1] = get_attr[target=_param_constant298]\n",
            "    %_param_constant299 : [num_users=1] = get_attr[target=_param_constant299]\n",
            "    %_tensor_constant200 : [num_users=1] = get_attr[target=_tensor_constant200]\n",
            "    %_tensor_constant201 : [num_users=1] = get_attr[target=_tensor_constant201]\n",
            "    %_native_batch_norm_legit_no_training_99 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_99, %_param_constant298, %_param_constant299, %_tensor_constant200, %_tensor_constant201, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_299 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_99, 0), kwargs = {})\n",
            "    %relu_95 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_299,), kwargs = {})\n",
            "    %_param_constant300 : [num_users=1] = get_attr[target=_param_constant300]\n",
            "    %convolution_100 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_95, %_param_constant300, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant301 : [num_users=1] = get_attr[target=_param_constant301]\n",
            "    %_param_constant302 : [num_users=1] = get_attr[target=_param_constant302]\n",
            "    %_tensor_constant202 : [num_users=1] = get_attr[target=_tensor_constant202]\n",
            "    %_tensor_constant203 : [num_users=1] = get_attr[target=_tensor_constant203]\n",
            "    %_native_batch_norm_legit_no_training_100 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_100, %_param_constant301, %_param_constant302, %_tensor_constant202, %_tensor_constant203, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_302 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_100, 0), kwargs = {})\n",
            "    %add_38 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_302, %relu_93), kwargs = {})\n",
            "    %relu_96 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%add_38,), kwargs = {})\n",
            "    %_param_constant303 : [num_users=1] = get_attr[target=_param_constant303]\n",
            "    %convolution_101 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_96, %_param_constant303, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant304 : [num_users=1] = get_attr[target=_param_constant304]\n",
            "    %_param_constant305 : [num_users=1] = get_attr[target=_param_constant305]\n",
            "    %_tensor_constant204 : [num_users=1] = get_attr[target=_tensor_constant204]\n",
            "    %_tensor_constant205 : [num_users=1] = get_attr[target=_tensor_constant205]\n",
            "    %_native_batch_norm_legit_no_training_101 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_101, %_param_constant304, %_param_constant305, %_tensor_constant204, %_tensor_constant205, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_305 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_101, 0), kwargs = {})\n",
            "    %relu_97 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_305,), kwargs = {})\n",
            "    %_param_constant306 : [num_users=1] = get_attr[target=_param_constant306]\n",
            "    %convolution_102 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_97, %_param_constant306, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant307 : [num_users=1] = get_attr[target=_param_constant307]\n",
            "    %_param_constant308 : [num_users=1] = get_attr[target=_param_constant308]\n",
            "    %_tensor_constant206 : [num_users=1] = get_attr[target=_tensor_constant206]\n",
            "    %_tensor_constant207 : [num_users=1] = get_attr[target=_tensor_constant207]\n",
            "    %_native_batch_norm_legit_no_training_102 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_102, %_param_constant307, %_param_constant308, %_tensor_constant206, %_tensor_constant207, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_308 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_102, 0), kwargs = {})\n",
            "    %relu_98 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_308,), kwargs = {})\n",
            "    %_param_constant309 : [num_users=1] = get_attr[target=_param_constant309]\n",
            "    %convolution_103 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_98, %_param_constant309, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant310 : [num_users=1] = get_attr[target=_param_constant310]\n",
            "    %_param_constant311 : [num_users=1] = get_attr[target=_param_constant311]\n",
            "    %_tensor_constant208 : [num_users=1] = get_attr[target=_tensor_constant208]\n",
            "    %_tensor_constant209 : [num_users=1] = get_attr[target=_tensor_constant209]\n",
            "    %_native_batch_norm_legit_no_training_103 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%convolution_103, %_param_constant310, %_param_constant311, %_tensor_constant208, %_tensor_constant209, 0.1, 1e-05), kwargs = {})\n",
            "    %getitem_311 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_no_training_103, 0), kwargs = {})\n",
            "    %add_39 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_311, %relu_96), kwargs = {})\n",
            "    %relu_99 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_39,), kwargs = {})\n",
            "    %_param_constant312 : [num_users=1] = get_attr[target=_param_constant312]\n",
            "    %_param_constant313 : [num_users=1] = get_attr[target=_param_constant313]\n",
            "    %convolution_104 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_99, %_param_constant312, %_param_constant313, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant314 : [num_users=1] = get_attr[target=_param_constant314]\n",
            "    %_param_constant315 : [num_users=1] = get_attr[target=_param_constant315]\n",
            "    %convolution_105 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%convolution_104, %_param_constant314, %_param_constant315, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant316 : [num_users=1] = get_attr[target=_param_constant316]\n",
            "    %_param_constant317 : [num_users=1] = get_attr[target=_param_constant317]\n",
            "    %convolution_106 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_90, %_param_constant316, %_param_constant317, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_frozen_param10 : [num_users=1] = get_attr[target=_frozen_param10]\n",
            "    %_frozen_param11 : [num_users=1] = get_attr[target=_frozen_param11]\n",
            "    %index_4 : [num_users=1] = call_function[target=torch.ops.aten.index.Tensor](args = (%convolution_104, [None, None, %_frozen_param10, %_frozen_param11]), kwargs = {})\n",
            "    %add_42 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%convolution_106, %index_4), kwargs = {})\n",
            "    %_param_constant318 : [num_users=1] = get_attr[target=_param_constant318]\n",
            "    %_param_constant319 : [num_users=1] = get_attr[target=_param_constant319]\n",
            "    %convolution_107 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%add_42, %_param_constant318, %_param_constant319, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant320 : [num_users=1] = get_attr[target=_param_constant320]\n",
            "    %_param_constant321 : [num_users=1] = get_attr[target=_param_constant321]\n",
            "    %convolution_108 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %_param_constant320, %_param_constant321, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_frozen_param12 : [num_users=1] = get_attr[target=_frozen_param12]\n",
            "    %_frozen_param13 : [num_users=1] = get_attr[target=_frozen_param13]\n",
            "    %index_5 : [num_users=1] = call_function[target=torch.ops.aten.index.Tensor](args = (%add_42, [None, None, %_frozen_param12, %_frozen_param13]), kwargs = {})\n",
            "    %add_45 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%convolution_108, %index_5), kwargs = {})\n",
            "    %_param_constant322 : [num_users=1] = get_attr[target=_param_constant322]\n",
            "    %_param_constant323 : [num_users=1] = get_attr[target=_param_constant323]\n",
            "    %convolution_109 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%add_45, %_param_constant322, %_param_constant323, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant324 : [num_users=1] = get_attr[target=_param_constant324]\n",
            "    %_param_constant325 : [num_users=1] = get_attr[target=_param_constant325]\n",
            "    %convolution_110 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %_param_constant324, %_param_constant325, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_frozen_param14 : [num_users=1] = get_attr[target=_frozen_param14]\n",
            "    %_frozen_param15 : [num_users=1] = get_attr[target=_frozen_param15]\n",
            "    %index_6 : [num_users=1] = call_function[target=torch.ops.aten.index.Tensor](args = (%add_45, [None, None, %_frozen_param14, %_frozen_param15]), kwargs = {})\n",
            "    %add_48 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convolution_110, %index_6), kwargs = {})\n",
            "    %_param_constant326 : [num_users=1] = get_attr[target=_param_constant326]\n",
            "    %_param_constant327 : [num_users=1] = get_attr[target=_param_constant327]\n",
            "    %convolution_111 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%add_48, %_param_constant326, %_param_constant327, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %max_pool2d_default_1 : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%convolution_105, [1, 1], [2, 2]), kwargs = {})\n",
            "    return (convolution_111, convolution_109, convolution_107, convolution_105, max_pool2d_default_1)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: select_scatter [shape=[1, 3, 800, 800], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution (kind: aten.convolution.default, args: ('select_scatter <tensorrt.ITensor [shape=(1, 3, 800, 800), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64, 3, 7, 7), dtype=float32]>', None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution]_output <tensorrt.ITensor [shape=(1, 64, 400, 400), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training]_output <tensorrt.ITensor [shape=(1, 64, 400, 400), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training]_output <tensorrt.ITensor [shape=(1, 64, 400, 400), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node max_pool2d_default (kind: aten.max_pool2d.default, args: ('[RELU]-[aten_ops.relu.default]-[relu]_output <tensorrt.ITensor [shape=(1, 64, 400, 400), dtype=DataType.FLOAT]>', [3, 3], [2, 2], [1, 1]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_1 (kind: aten.convolution.default, args: ('[MAX]-[aten_ops.max_pool2d.default]-[max_pool2d_default]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64, 64, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_1 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_1]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_5 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_1]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_5\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_1 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_1]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_2 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_1]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64, 64, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_2 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_2]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_8 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_2]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_8\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_2 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_2]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_3 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_2]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 64, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_3 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_3]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_11 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_3]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_11\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_4 (kind: aten.convolution.default, args: ('[MAX]-[aten_ops.max_pool2d.default]-[max_pool2d_default]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 64, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_4 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_4]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_14 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_4]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_14\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_7 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_3]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_4]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_3 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_7]_output_add.Tensor <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_5 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_3]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_5 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_5]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_17 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_5]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_17\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_4 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_5]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_6 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_4]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64, 64, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_6 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_6]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_20 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_6]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_20\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_5 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_6]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_7 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_5]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 64, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_7 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_7]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_23 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_7]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_23\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_8 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_7]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_3]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_6 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_8]_output_add.Tensor <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_8 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_6]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_8 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_8]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_26 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_8]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_26\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_7 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_8]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_9 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_7]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64, 64, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_9 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_9]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(64,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_29 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_9]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_29\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_8 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_9]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_10 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_8]_output <tensorrt.ITensor [shape=(1, 64, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 64, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_10 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_10]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_32 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_10]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_32\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_9 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_10]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_6]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_9 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_9]_output_add.Tensor <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_11 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_9]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_11 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_11]_output <tensorrt.ITensor [shape=(1, 128, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_35 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_11]_output <tensorrt.ITensor [shape=(1, 128, 200, 200), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_35\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_10 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_11]_output <tensorrt.ITensor [shape=(1, 128, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_12 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_10]_output <tensorrt.ITensor [shape=(1, 128, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128, 128, 3, 3), dtype=float32]>', None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_12 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_12]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_38 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_12]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_38\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_11 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_12]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_13 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_11]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 128, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_13 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_13]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_41 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_13]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_41\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_14 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_9]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 256, 1, 1), dtype=float32]>', None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_14 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_14]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_44 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_14]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_44\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_10 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_13]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_14]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_12 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_10]_output_add.Tensor <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_15 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_12]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128, 512, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_15 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_15]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_47 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_15]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_47\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_13 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_15]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_16 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_13]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128, 128, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_16 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_16]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_50 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_16]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_50\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_14 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_16]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_17 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_14]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 128, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_17 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_17]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_53 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_17]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_53\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_11 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_17]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_12]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_15 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_11]_output_add.Tensor <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_18 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_15]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128, 512, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_18 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_18]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_56 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_18]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_56\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_16 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_18]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_19 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_16]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128, 128, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_19 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_19]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_59 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_19]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_59\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_17 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_19]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_20 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_17]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 128, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_20 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_20]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_62 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_20]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_62\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_12 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_20]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_15]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_18 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_12]_output_add.Tensor <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_21 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_18]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128, 512, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_21 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_21]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_65 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_21]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_65\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_19 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_21]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_22 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_19]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128, 128, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_22 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_22]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(128,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_68 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_22]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_68\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_20 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_22]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_23 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_20]_output <tensorrt.ITensor [shape=(1, 128, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 128, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_23 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_23]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_71 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_23]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_71\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_13 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_23]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_18]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_21 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_13]_output_add.Tensor <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_24 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_21]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 512, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_24 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_24]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_74 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_24]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_74\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_22 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_24]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_25 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_22]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_25 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_25]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_77 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_25]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_77\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_23 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_25]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_26 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_23]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_26 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_26]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_80 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_26]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_80\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_27 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_21]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 512, 1, 1), dtype=float32]>', None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_27 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_27]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_83 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_27]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_83\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_14 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_26]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_27]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_24 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_14]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_28 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_24]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_28 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_28]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_86 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_28]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_86\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_25 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_28]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_29 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_25]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_29 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_29]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_89 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_29]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_89\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_26 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_29]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_30 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_26]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_30 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_30]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_92 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_30]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_92\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_15 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_30]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_24]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_27 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_15]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_31 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_27]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_31 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_31]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_95 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_31]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_95\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_28 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_31]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_32 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_28]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_32 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_32]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_98 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_32]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_98\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_29 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_32]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_33 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_29]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_33 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_33]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_101 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_33]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_101\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_16 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_33]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_27]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_30 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_16]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_34 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_30]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_34 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_34]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_104 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_34]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_104\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_31 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_34]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_35 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_31]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_35 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_35]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_107 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_35]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_107\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_32 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_35]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_36 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_32]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_36 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_36]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_110 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_36]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_110\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_17 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_36]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_30]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_33 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_17]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_37 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_33]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_37 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_37]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_113 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_37]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_113\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_34 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_37]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_38 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_34]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_38 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_38]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_116 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_38]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_116\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_35 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_38]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_39 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_35]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_39 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_39]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_119 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_39]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_119\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_18 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_39]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_33]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_36 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_18]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_40 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_36]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_40 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_40]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_122 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_40]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_122\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_37 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_40]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_41 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_37]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_41 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_41]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_125 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_41]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_125\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_38 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_41]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_42 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_38]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_42 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_42]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_128 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_42]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_128\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_19 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_42]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_36]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_39 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_19]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_43 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_39]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_43 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_43]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_131 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_43]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_131\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_40 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_43]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_44 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_40]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_44 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_44]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_134 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_44]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_134\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_41 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_44]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_45 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_41]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_45 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_45]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_137 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_45]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_137\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_20 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_45]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_39]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_42 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_20]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_46 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_42]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_46 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_46]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_140 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_46]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_140\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_43 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_46]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_47 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_43]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_47 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_47]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_143 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_47]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_143\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_44 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_47]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_48 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_44]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_48 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_48]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_146 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_48]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_146\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_21 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_48]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_42]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_45 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_21]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_49 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_45]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_49 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_49]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_149 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_49]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_149\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_46 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_49]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_50 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_46]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_50 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_50]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_152 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_50]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_152\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_47 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_50]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_51 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_47]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_51 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_51]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_155 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_51]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_155\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_22 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_51]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_45]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_48 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_22]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_52 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_48]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_52 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_52]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_158 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_52]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_158\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_49 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_52]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_53 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_49]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_53 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_53]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_161 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_53]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_161\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_50 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_53]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_54 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_50]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_54 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_54]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_164 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_54]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_164\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_23 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_54]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_48]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_51 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_23]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_55 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_51]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_55 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_55]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_167 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_55]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_167\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_52 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_55]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_56 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_52]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_56 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_56]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_170 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_56]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_170\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_53 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_56]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_57 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_53]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_57 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_57]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_173 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_57]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_173\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_24 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_57]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_51]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_54 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_24]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_58 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_54]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_58 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_58]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_176 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_58]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_176\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_55 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_58]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_59 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_55]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_59 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_59]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_179 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_59]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_179\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_56 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_59]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_60 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_56]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_60 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_60]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_182 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_60]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_182\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_25 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_60]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_54]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_57 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_25]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_61 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_57]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_61 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_61]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_185 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_61]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_185\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_58 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_61]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_62 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_58]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_62 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_62]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_188 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_62]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_188\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_59 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_62]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_63 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_59]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_63 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_63]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_191 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_63]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_191\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_26 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_63]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_57]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_60 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_26]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_64 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_60]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_64 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_64]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_194 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_64]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_194\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_61 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_64]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_65 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_61]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_65 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_65]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_197 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_65]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_197\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_62 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_65]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_66 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_62]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_66 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_66]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_200 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_66]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_200\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_27 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_66]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_60]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_63 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_27]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_67 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_63]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_67 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_67]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_203 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_67]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_203\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_64 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_67]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_68 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_64]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_68 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_68]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_206 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_68]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_206\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_65 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_68]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_69 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_65]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_69 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_69]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_209 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_69]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_209\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_28 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_69]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_63]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_66 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_28]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_70 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_66]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_70 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_70]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_212 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_70]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_212\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_67 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_70]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_71 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_67]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_71 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_71]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_215 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_71]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_215\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_68 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_71]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_72 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_68]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_72 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_72]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_218 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_72]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_218\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_29 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_72]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_66]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_69 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_29]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_73 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_69]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_73 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_73]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_221 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_73]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_221\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_70 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_73]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_74 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_70]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_74 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_74]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_224 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_74]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_224\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_71 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_74]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_75 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_71]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_75 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_75]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_227 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_75]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_227\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_30 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_75]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_69]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_72 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_30]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_76 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_72]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_76 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_76]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_230 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_76]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_230\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_73 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_76]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_77 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_73]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_77 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_77]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_233 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_77]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_233\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_74 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_77]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_78 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_74]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_78 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_78]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_236 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_78]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_236\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_31 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_78]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_72]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_75 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_31]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_79 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_75]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_79 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_79]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_239 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_79]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_239\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_76 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_79]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_80 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_76]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_80 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_80]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_242 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_80]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_242\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_77 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_80]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_81 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_77]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_81 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_81]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_245 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_81]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_245\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_32 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_81]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_75]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_78 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_32]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_82 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_78]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_82 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_82]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_248 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_82]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_248\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_79 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_82]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_83 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_79]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_83 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_83]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_251 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_83]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_251\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_80 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_83]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_84 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_80]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_84 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_84]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_254 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_84]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_254\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_33 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_84]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_78]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_81 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_33]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_85 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_81]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_85 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_85]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_257 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_85]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_257\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_82 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_85]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_86 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_82]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_86 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_86]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_260 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_86]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_260\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_83 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_86]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_87 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_83]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_87 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_87]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_263 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_87]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_263\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_34 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_87]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_81]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_84 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_34]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_88 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_84]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_88 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_88]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_266 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_88]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_266\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_85 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_88]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_89 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_85]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_89 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_89]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_269 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_89]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_269\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_86 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_89]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_90 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_86]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_90 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_90]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_272 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_90]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_272\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_35 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_90]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_84]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_87 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_35]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_91 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_87]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_91 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_91]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_275 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_91]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_275\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_88 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_91]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_92 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_88]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_92 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_92]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_278 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_92]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_278\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_89 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_92]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_93 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_89]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 256, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_93 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_93]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_281 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_93]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_281\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_36 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_93]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_87]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_90 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_36]_output_add.Tensor <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_94 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_90]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 1024, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_94 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_94]_output <tensorrt.ITensor [shape=(1, 512, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_284 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_94]_output <tensorrt.ITensor [shape=(1, 512, 50, 50), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_284\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_91 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_94]_output <tensorrt.ITensor [shape=(1, 512, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_95 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_91]_output <tensorrt.ITensor [shape=(1, 512, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 512, 3, 3), dtype=float32]>', None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_95 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_95]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_287 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_95]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_287\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_92 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_95]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_96 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_92]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(2048, 512, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_96 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_96]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_290 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_96]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_290\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_97 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_90]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(2048, 1024, 1, 1), dtype=float32]>', None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_97 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_97]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_293 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_97]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_293\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_37 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_96]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_97]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_93 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_37]_output_add.Tensor <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_98 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_93]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 2048, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_98 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_98]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_296 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_98]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_296\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_94 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_98]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_99 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_94]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 512, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_99 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_99]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_299 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_99]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_299\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_95 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_99]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_100 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_95]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(2048, 512, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_100 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_100]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_302 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_100]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_302\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_38 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_100]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_93]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_96 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_38]_output_add.Tensor <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_101 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_96]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 2048, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_101 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_101]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_305 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_101]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_305\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_97 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_101]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_102 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_97]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512, 512, 3, 3), dtype=float32]>', None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_102 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_102]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(512,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_308 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_102]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_308\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_98 (kind: aten.relu.default, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_102]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_103 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_98]_output <tensorrt.ITensor [shape=(1, 512, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(2048, 512, 1, 1), dtype=float32]>', None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _native_batch_norm_legit_no_training_103 (kind: aten._native_batch_norm_legit_no_training.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_103]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(2048,), dtype=float32]>', 0.1, 1e-05))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node getitem_311 (kind: <built-in function getitem>, args: (('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_103]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', None, None), 0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.ops_evaluators:Evaluating _operator.getitem on object with name: getitem_311\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_39 (kind: aten.add.Tensor, args: ('[SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[_native_batch_norm_legit_no_training_103]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '[RELU]-[aten_ops.relu.default]-[relu_96]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_99 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_39]_output_add.Tensor <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_104 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_99]_output <tensorrt.ITensor [shape=(1, 2048, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 2048, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_105 (kind: aten.convolution.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_104]_output <tensorrt.ITensor [shape=(1, 256, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_106 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_90]_output <tensorrt.ITensor [shape=(1, 1024, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 1024, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node index_4 (kind: aten.index.Tensor, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_104]_output <tensorrt.ITensor [shape=(1, 256, 25, 25), dtype=DataType.FLOAT]>', [None, None, '<torch.Tensor as np.ndarray [shape=(50, 1), dtype=int64]>', '<torch.Tensor as np.ndarray [shape=(50,), dtype=int64]>']))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Determining whether aten.index constant-index optimization can be invoked\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Shape of 2 index is (50, 1)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Shape of 3 index is (50,)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The input shape is (1, 256, 25, 25)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The new transpose order is [2, 3, 0, 1]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape of transpose tensor is (25, 25, 1, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The flatten tensor shape is (625, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape after cumultative gather is (50, 50, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape for cumulative adv index is <tensorrt_bindings.tensorrt.ITensor object at 0x7bb08db61870>\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape for cumulative adv index is (50, 50)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The indices are continuous in this case\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The tensor is unfolded now\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The unfolded tensor shape is (2500, 1, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Transposing the indices to correct position [1, 2, 0]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_42 (kind: aten.add.Tensor, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_106]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.index.Tensor]-[index_4_unfold_advanced_index]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_107 (kind: aten.convolution.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_42]_output_add.Tensor <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_108 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_21]_output <tensorrt.ITensor [shape=(1, 512, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 512, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node index_5 (kind: aten.index.Tensor, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_42]_output_add.Tensor <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', [None, None, '<torch.Tensor as np.ndarray [shape=(100, 1), dtype=int64]>', '<torch.Tensor as np.ndarray [shape=(100,), dtype=int64]>']))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Determining whether aten.index constant-index optimization can be invoked\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Shape of 2 index is (100, 1)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Shape of 3 index is (100,)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The input shape is (1, 256, 50, 50)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The new transpose order is [2, 3, 0, 1]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape of transpose tensor is (50, 50, 1, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The flatten tensor shape is (2500, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape after cumultative gather is (100, 100, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape for cumulative adv index is <tensorrt_bindings.tensorrt.ITensor object at 0x7bb08df3ca70>\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape for cumulative adv index is (100, 100)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The indices are continuous in this case\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The tensor is unfolded now\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The unfolded tensor shape is (10000, 1, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Transposing the indices to correct position [1, 2, 0]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_45 (kind: aten.add.Tensor, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_108]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.index.Tensor]-[index_5_unfold_advanced_index]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_109 (kind: aten.convolution.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_45]_output_add.Tensor <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_110 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_9]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node index_6 (kind: aten.index.Tensor, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_45]_output_add.Tensor <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', [None, None, '<torch.Tensor as np.ndarray [shape=(200, 1), dtype=int64]>', '<torch.Tensor as np.ndarray [shape=(200,), dtype=int64]>']))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Determining whether aten.index constant-index optimization can be invoked\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Shape of 2 index is (200, 1)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Shape of 3 index is (200,)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The input shape is (1, 256, 100, 100)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The new transpose order is [2, 3, 0, 1]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape of transpose tensor is (100, 100, 1, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The flatten tensor shape is (10000, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape after cumultative gather is (200, 200, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape for cumulative adv index is <tensorrt_bindings.tensorrt.ITensor object at 0x7bb08df3f230>\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The shape for cumulative adv index is (200, 200)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The indices are continuous in this case\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The tensor is unfolded now\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:The unfolded tensor shape is (40000, 1, 256)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.impl.select:Transposing the indices to correct position [1, 2, 0]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_48 (kind: aten.add.Tensor, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_110]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.index.Tensor]-[index_6_unfold_advanced_index]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_111 (kind: aten.convolution.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_48]_output_add.Tensor <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node max_pool2d_default_1 (kind: aten.max_pool2d.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_105]_output <tensorrt.ITensor [shape=(1, 256, 25, 25), dtype=DataType.FLOAT]>', [1, 1], [2, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output0 [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output1 [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output2 [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output3 [shape=(1, 256, 25, 25), dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output4 [shape=(1, 256, 13, 13), dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:07.288187\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:21.682833\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 189290524 bytes of Memory\n",
            "DEBUG:torch_tensorrt.dynamo._DryRunTracker:\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++ Dry-Run Results for Graph ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "The graph consists of 480 Total Operators, of which 479 operators are supported, 99.79% coverage\n",
            "\n",
            "The following ops are currently unsupported or excluded from conversion, and are listed with their op-count in the graph:\n",
            " torch.ops.aten.select_scatter.default: 1\n",
            "\n",
            "The following nodes are currently set to run in Torch:\n",
            "Node: torch.ops.aten.select_scatter.default, with layer location: select_scatter\n",
            "Note: Some of the above nodes may be supported, but were not included in a TRT graph by the partitioner\n",
            "\n",
            "Compiled with: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "  Graph Structure:\n",
            "\n",
            "   Inputs: List[Tensor: (3, 200, 200)@float32]\n",
            "    ...\n",
            "    TRT Engine #1 - Submodule name: _run_on_acc_0\n",
            "     Engine Inputs: List[Tensor: (3, 200, 200)@float32]\n",
            "     Number of Operators in Engine: 18\n",
            "     Engine Outputs: Tensor: (3, 800, 800)@float32\n",
            "    ...\n",
            "    TRT Engine #2 - Submodule name: _run_on_acc_2\n",
            "     Engine Inputs: List[Tensor: (1, 3, 800, 800)@float32]\n",
            "     Number of Operators in Engine: 461\n",
            "     Engine Outputs: Tuple(Tensor: (1, 256, 200, 200)@float32, Tensor: (1, 256, 100, 100)@float32, Tensor: (1, 256, 50, 50)@float32, Tensor: (1, 256, 25, 25)@float32, Tensor: (1, 256, 13, 13)@float32)\n",
            "    ...\n",
            "   Outputs: Tuple(Tensor: (1, 256, 200, 200)@float32, Tensor: (1, 256, 100, 100)@float32, Tensor: (1, 256, 50, 50)@float32, Tensor: (1, 256, 25, 25)@float32, Tensor: (1, 256, 13, 13)@float32, Tensor: (1, 3, 800, 800)@float32)\n",
            "\n",
            "  ------------------------- Aggregate Stats -------------------------\n",
            "\n",
            "   Average Number of Operators per TRT Engine: 239.5\n",
            "   Most Operators in a TRT Engine: 461\n",
            "\n",
            "  ********** Recommendations **********\n",
            "\n",
            "   - For minimal graph segmentation, select min_block_size=461 which would generate 1 TRT engine(s)\n",
            "   - For moderate graph segmentation, select min_block_size=240 which would generate 1 TRT engine(s)\n",
            "   - The current level of graph segmentation is equivalent to selecting min_block_size=18 which generates 2 TRT engine(s)\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %feature_map : torch.Tensor [num_users=1] = placeholder[target=L_features_0_]\n",
            "    %feature_map_1 : torch.Tensor [num_users=1] = placeholder[target=L_features_1_]\n",
            "    %feature_map_2 : torch.Tensor [num_users=1] = placeholder[target=L_features_2_]\n",
            "    %feature_map_3 : torch.Tensor [num_users=1] = placeholder[target=L_features_3_]\n",
            "    %feature_map_4 : torch.Tensor [num_users=1] = placeholder[target=L_features_pool_]\n",
            "    %l__self___head_conv_0_0 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%feature_map,), kwargs = {})\n",
            "    %t : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_0,), kwargs = {})\n",
            "    %box_cls_per_level : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t,), kwargs = {})\n",
            "    %box_regression_per_level : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t,), kwargs = {})\n",
            "    %l__self___head_conv_0_2 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%feature_map_1,), kwargs = {})\n",
            "    %t_1 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_2,), kwargs = {})\n",
            "    %box_cls_per_level_2 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_1,), kwargs = {})\n",
            "    %box_regression_per_level_2 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_1,), kwargs = {})\n",
            "    %l__self___head_conv_0_4 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%feature_map_2,), kwargs = {})\n",
            "    %t_2 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_4,), kwargs = {})\n",
            "    %box_cls_per_level_4 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_2,), kwargs = {})\n",
            "    %box_regression_per_level_4 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_2,), kwargs = {})\n",
            "    %l__self___head_conv_0_6 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%feature_map_3,), kwargs = {})\n",
            "    %t_3 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_6,), kwargs = {})\n",
            "    %box_cls_per_level_6 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_3,), kwargs = {})\n",
            "    %box_regression_per_level_6 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_3,), kwargs = {})\n",
            "    %l__self___head_conv_0_8 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%feature_map_4,), kwargs = {})\n",
            "    %t_4 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_8,), kwargs = {})\n",
            "    %box_cls_per_level_8 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_4,), kwargs = {})\n",
            "    %box_regression_per_level_8 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_4,), kwargs = {})\n",
            "    %empty : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height : [num_users=1] = call_method[target=fill_](args = (%empty, 4), kwargs = {})\n",
            "    %empty_1 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width : [num_users=1] = call_method[target=fill_](args = (%empty_1, 4), kwargs = {})\n",
            "    %empty_2 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_1 : [num_users=1] = call_method[target=fill_](args = (%empty_2, 8), kwargs = {})\n",
            "    %empty_3 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_1 : [num_users=1] = call_method[target=fill_](args = (%empty_3, 8), kwargs = {})\n",
            "    %empty_4 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_2 : [num_users=1] = call_method[target=fill_](args = (%empty_4, 16), kwargs = {})\n",
            "    %empty_5 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_2 : [num_users=1] = call_method[target=fill_](args = (%empty_5, 16), kwargs = {})\n",
            "    %empty_6 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_3 : [num_users=1] = call_method[target=fill_](args = (%empty_6, 32), kwargs = {})\n",
            "    %empty_7 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_3 : [num_users=1] = call_method[target=fill_](args = (%empty_7, 32), kwargs = {})\n",
            "    %empty_8 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_4 : [num_users=1] = call_method[target=fill_](args = (%empty_8, 61), kwargs = {})\n",
            "    %empty_9 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_4 : [num_users=1] = call_method[target=fill_](args = (%empty_9, 61), kwargs = {})\n",
            "    %cell_anchor : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_0]\n",
            "    %base_anchors : [num_users=2] = call_method[target=to](args = (%cell_anchor,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_1 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_1]\n",
            "    %base_anchors_1 : [num_users=2] = call_method[target=to](args = (%cell_anchor_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_2 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_2]\n",
            "    %base_anchors_2 : [num_users=2] = call_method[target=to](args = (%cell_anchor_2,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_3 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_3]\n",
            "    %base_anchors_3 : [num_users=2] = call_method[target=to](args = (%cell_anchor_3,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_4 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_4]\n",
            "    %base_anchors_4 : [num_users=2] = call_method[target=to](args = (%cell_anchor_4,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %arange : [num_users=1] = call_function[target=torch.arange](args = (0, 200), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x : [num_users=1] = call_function[target=operator.mul](args = (%arange, %stride_width), kwargs = {})\n",
            "    %arange_1 : [num_users=1] = call_function[target=torch.arange](args = (0, 200), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y : [num_users=1] = call_function[target=operator.mul](args = (%arange_1, %stride_height), kwargs = {})\n",
            "    %meshgrid : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y, %shifts_x), kwargs = {indexing: ij})\n",
            "    %shift_y : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid, 0), kwargs = {})\n",
            "    %shift_x : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid, 1), kwargs = {})\n",
            "    %shift_x_1 : [num_users=1] = call_method[target=reshape](args = (%shift_x, -1), kwargs = {})\n",
            "    %shift_y_1 : [num_users=1] = call_method[target=reshape](args = (%shift_y, -1), kwargs = {})\n",
            "    %shifts : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_1, %shift_y_1, %shift_x_1, %shift_y_1),), kwargs = {dim: 1})\n",
            "    %view : [num_users=1] = call_method[target=view](args = (%shifts, -1, 1, 4), kwargs = {})\n",
            "    %view_1 : [num_users=1] = call_method[target=view](args = (%base_anchors, 1, -1, 4), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%view, %view_1), kwargs = {})\n",
            "    %anchors_per_feature_map : [num_users=1] = call_method[target=reshape](args = (%add, -1, 4), kwargs = {})\n",
            "    %arange_2 : [num_users=1] = call_function[target=torch.arange](args = (0, 100), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_1 : [num_users=1] = call_function[target=operator.mul](args = (%arange_2, %stride_width_1), kwargs = {})\n",
            "    %arange_3 : [num_users=1] = call_function[target=torch.arange](args = (0, 100), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_1 : [num_users=1] = call_function[target=operator.mul](args = (%arange_3, %stride_height_1), kwargs = {})\n",
            "    %meshgrid_1 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_1, %shifts_x_1), kwargs = {indexing: ij})\n",
            "    %shift_y_2 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_1, 0), kwargs = {})\n",
            "    %shift_x_2 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_1, 1), kwargs = {})\n",
            "    %shift_x_3 : [num_users=1] = call_method[target=reshape](args = (%shift_x_2, -1), kwargs = {})\n",
            "    %shift_y_3 : [num_users=1] = call_method[target=reshape](args = (%shift_y_2, -1), kwargs = {})\n",
            "    %shifts_1 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_3, %shift_y_3, %shift_x_3, %shift_y_3),), kwargs = {dim: 1})\n",
            "    %view_2 : [num_users=1] = call_method[target=view](args = (%shifts_1, -1, 1, 4), kwargs = {})\n",
            "    %view_3 : [num_users=1] = call_method[target=view](args = (%base_anchors_1, 1, -1, 4), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%view_2, %view_3), kwargs = {})\n",
            "    %anchors_per_feature_map_1 : [num_users=1] = call_method[target=reshape](args = (%add_1, -1, 4), kwargs = {})\n",
            "    %arange_4 : [num_users=1] = call_function[target=torch.arange](args = (0, 50), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_2 : [num_users=1] = call_function[target=operator.mul](args = (%arange_4, %stride_width_2), kwargs = {})\n",
            "    %arange_5 : [num_users=1] = call_function[target=torch.arange](args = (0, 50), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_2 : [num_users=1] = call_function[target=operator.mul](args = (%arange_5, %stride_height_2), kwargs = {})\n",
            "    %meshgrid_2 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_2, %shifts_x_2), kwargs = {indexing: ij})\n",
            "    %shift_y_4 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_2, 0), kwargs = {})\n",
            "    %shift_x_4 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_2, 1), kwargs = {})\n",
            "    %shift_x_5 : [num_users=1] = call_method[target=reshape](args = (%shift_x_4, -1), kwargs = {})\n",
            "    %shift_y_5 : [num_users=1] = call_method[target=reshape](args = (%shift_y_4, -1), kwargs = {})\n",
            "    %shifts_2 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_5, %shift_y_5, %shift_x_5, %shift_y_5),), kwargs = {dim: 1})\n",
            "    %view_4 : [num_users=1] = call_method[target=view](args = (%shifts_2, -1, 1, 4), kwargs = {})\n",
            "    %view_5 : [num_users=1] = call_method[target=view](args = (%base_anchors_2, 1, -1, 4), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%view_4, %view_5), kwargs = {})\n",
            "    %anchors_per_feature_map_2 : [num_users=1] = call_method[target=reshape](args = (%add_2, -1, 4), kwargs = {})\n",
            "    %arange_6 : [num_users=1] = call_function[target=torch.arange](args = (0, 25), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_3 : [num_users=1] = call_function[target=operator.mul](args = (%arange_6, %stride_width_3), kwargs = {})\n",
            "    %arange_7 : [num_users=1] = call_function[target=torch.arange](args = (0, 25), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_3 : [num_users=1] = call_function[target=operator.mul](args = (%arange_7, %stride_height_3), kwargs = {})\n",
            "    %meshgrid_3 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_3, %shifts_x_3), kwargs = {indexing: ij})\n",
            "    %shift_y_6 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_3, 0), kwargs = {})\n",
            "    %shift_x_6 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_3, 1), kwargs = {})\n",
            "    %shift_x_7 : [num_users=1] = call_method[target=reshape](args = (%shift_x_6, -1), kwargs = {})\n",
            "    %shift_y_7 : [num_users=1] = call_method[target=reshape](args = (%shift_y_6, -1), kwargs = {})\n",
            "    %shifts_3 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_7, %shift_y_7, %shift_x_7, %shift_y_7),), kwargs = {dim: 1})\n",
            "    %view_6 : [num_users=1] = call_method[target=view](args = (%shifts_3, -1, 1, 4), kwargs = {})\n",
            "    %view_7 : [num_users=1] = call_method[target=view](args = (%base_anchors_3, 1, -1, 4), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%view_6, %view_7), kwargs = {})\n",
            "    %anchors_per_feature_map_3 : [num_users=1] = call_method[target=reshape](args = (%add_3, -1, 4), kwargs = {})\n",
            "    %arange_8 : [num_users=1] = call_function[target=torch.arange](args = (0, 13), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_4 : [num_users=1] = call_function[target=operator.mul](args = (%arange_8, %stride_width_4), kwargs = {})\n",
            "    %arange_9 : [num_users=1] = call_function[target=torch.arange](args = (0, 13), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_4 : [num_users=1] = call_function[target=operator.mul](args = (%arange_9, %stride_height_4), kwargs = {})\n",
            "    %meshgrid_4 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_4, %shifts_x_4), kwargs = {indexing: ij})\n",
            "    %shift_y_8 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_4, 0), kwargs = {})\n",
            "    %shift_x_8 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_4, 1), kwargs = {})\n",
            "    %shift_x_9 : [num_users=1] = call_method[target=reshape](args = (%shift_x_8, -1), kwargs = {})\n",
            "    %shift_y_9 : [num_users=1] = call_method[target=reshape](args = (%shift_y_8, -1), kwargs = {})\n",
            "    %shifts_4 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_9, %shift_y_9, %shift_x_9, %shift_y_9),), kwargs = {dim: 1})\n",
            "    %view_8 : [num_users=1] = call_method[target=view](args = (%shifts_4, -1, 1, 4), kwargs = {})\n",
            "    %view_9 : [num_users=1] = call_method[target=view](args = (%base_anchors_4, 1, -1, 4), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%view_8, %view_9), kwargs = {})\n",
            "    %anchors_per_feature_map_4 : [num_users=1] = call_method[target=reshape](args = (%add_4, -1, 4), kwargs = {})\n",
            "    %b : [num_users=2] = call_function[target=torch.cat](args = ([%anchors_per_feature_map, %anchors_per_feature_map_1, %anchors_per_feature_map_2, %anchors_per_feature_map_3, %anchors_per_feature_map_4],), kwargs = {})\n",
            "    %layer : [num_users=1] = call_method[target=view](args = (%box_cls_per_level, 1, -1, 1, 200, 200), kwargs = {})\n",
            "    %layer_1 : [num_users=1] = call_method[target=permute](args = (%layer, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_1 : [num_users=1] = call_method[target=reshape](args = (%layer_1, 1, -1, 1), kwargs = {})\n",
            "    %layer_3 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level, 1, -1, 4, 200, 200), kwargs = {})\n",
            "    %layer_4 : [num_users=1] = call_method[target=permute](args = (%layer_3, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_1 : [num_users=1] = call_method[target=reshape](args = (%layer_4, 1, -1, 4), kwargs = {})\n",
            "    %layer_6 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_2, 1, -1, 1, 100, 100), kwargs = {})\n",
            "    %layer_7 : [num_users=1] = call_method[target=permute](args = (%layer_6, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_3 : [num_users=1] = call_method[target=reshape](args = (%layer_7, 1, -1, 1), kwargs = {})\n",
            "    %layer_9 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_2, 1, -1, 4, 100, 100), kwargs = {})\n",
            "    %layer_10 : [num_users=1] = call_method[target=permute](args = (%layer_9, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_3 : [num_users=1] = call_method[target=reshape](args = (%layer_10, 1, -1, 4), kwargs = {})\n",
            "    %layer_12 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_4, 1, -1, 1, 50, 50), kwargs = {})\n",
            "    %layer_13 : [num_users=1] = call_method[target=permute](args = (%layer_12, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_5 : [num_users=1] = call_method[target=reshape](args = (%layer_13, 1, -1, 1), kwargs = {})\n",
            "    %layer_15 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_4, 1, -1, 4, 50, 50), kwargs = {})\n",
            "    %layer_16 : [num_users=1] = call_method[target=permute](args = (%layer_15, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_5 : [num_users=1] = call_method[target=reshape](args = (%layer_16, 1, -1, 4), kwargs = {})\n",
            "    %layer_18 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_6, 1, -1, 1, 25, 25), kwargs = {})\n",
            "    %layer_19 : [num_users=1] = call_method[target=permute](args = (%layer_18, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_7 : [num_users=1] = call_method[target=reshape](args = (%layer_19, 1, -1, 1), kwargs = {})\n",
            "    %layer_21 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_6, 1, -1, 4, 25, 25), kwargs = {})\n",
            "    %layer_22 : [num_users=1] = call_method[target=permute](args = (%layer_21, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_7 : [num_users=1] = call_method[target=reshape](args = (%layer_22, 1, -1, 4), kwargs = {})\n",
            "    %layer_24 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_8, 1, -1, 1, 13, 13), kwargs = {})\n",
            "    %layer_25 : [num_users=1] = call_method[target=permute](args = (%layer_24, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_9 : [num_users=1] = call_method[target=reshape](args = (%layer_25, 1, -1, 1), kwargs = {})\n",
            "    %layer_27 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_8, 1, -1, 4, 13, 13), kwargs = {})\n",
            "    %layer_28 : [num_users=1] = call_method[target=permute](args = (%layer_27, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_9 : [num_users=1] = call_method[target=reshape](args = (%layer_28, 1, -1, 4), kwargs = {})\n",
            "    %cat_1 : [num_users=1] = call_function[target=torch.cat](args = ([%box_cls_per_level_1, %box_cls_per_level_3, %box_cls_per_level_5, %box_cls_per_level_7, %box_cls_per_level_9],), kwargs = {dim: 1})\n",
            "    %objectness : [num_users=1] = call_method[target=flatten](args = (%cat_1, 0, -2), kwargs = {})\n",
            "    %cat_2 : [num_users=1] = call_function[target=torch.cat](args = ([%box_regression_per_level_1, %box_regression_per_level_3, %box_regression_per_level_5, %box_regression_per_level_7, %box_regression_per_level_9],), kwargs = {dim: 1})\n",
            "    %pred_bbox_deltas : [num_users=2] = call_method[target=reshape](args = (%cat_2, -1, 4), kwargs = {})\n",
            "    %detach : [num_users=1] = call_method[target=detach](args = (%pred_bbox_deltas,), kwargs = {})\n",
            "    %concat_boxes : [num_users=1] = call_function[target=torch.cat](args = ([%b],), kwargs = {dim: 0})\n",
            "    %rel_codes : [num_users=4] = call_method[target=reshape](args = (%detach, 159882, -1), kwargs = {})\n",
            "    %boxes : [num_users=6] = call_method[target=to](args = (%concat_boxes, torch.float32), kwargs = {})\n",
            "    %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 2)), kwargs = {})\n",
            "    %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 0)), kwargs = {})\n",
            "    %widths : [num_users=3] = call_function[target=operator.sub](args = (%getitem_15, %getitem_16), kwargs = {})\n",
            "    %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 3)), kwargs = {})\n",
            "    %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 1)), kwargs = {})\n",
            "    %heights : [num_users=3] = call_function[target=operator.sub](args = (%getitem_17, %getitem_18), kwargs = {})\n",
            "    %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 0)), kwargs = {})\n",
            "    %mul_10 : [num_users=1] = call_function[target=operator.mul](args = (0.5, %widths), kwargs = {})\n",
            "    %ctr_x : [num_users=1] = call_function[target=operator.add](args = (%getitem_19, %mul_10), kwargs = {})\n",
            "    %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 1)), kwargs = {})\n",
            "    %mul_11 : [num_users=1] = call_function[target=operator.mul](args = (0.5, %heights), kwargs = {})\n",
            "    %ctr_y : [num_users=1] = call_function[target=operator.add](args = (%getitem_20, %mul_11), kwargs = {})\n",
            "    %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(0, None, 4))), kwargs = {})\n",
            "    %dx : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_21, 1.0), kwargs = {})\n",
            "    %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(1, None, 4))), kwargs = {})\n",
            "    %dy : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_22, 1.0), kwargs = {})\n",
            "    %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(2, None, 4))), kwargs = {})\n",
            "    %dw : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_23, 1.0), kwargs = {})\n",
            "    %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(3, None, 4))), kwargs = {})\n",
            "    %dh : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_24, 1.0), kwargs = {})\n",
            "    %dw_1 : [num_users=1] = call_function[target=torch.clamp](args = (%dw,), kwargs = {max: 4.135166556742356})\n",
            "    %dh_1 : [num_users=1] = call_function[target=torch.clamp](args = (%dh,), kwargs = {max: 4.135166556742356})\n",
            "    %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%widths, (slice(None, None, None), None)), kwargs = {})\n",
            "    %mul_12 : [num_users=1] = call_function[target=operator.mul](args = (%dx, %getitem_25), kwargs = {})\n",
            "    %getitem_26 : [num_users=1] = call_function[target=operator.getitem](args = (%ctr_x, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_ctr_x : [num_users=2] = call_function[target=operator.add](args = (%mul_12, %getitem_26), kwargs = {})\n",
            "    %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%heights, (slice(None, None, None), None)), kwargs = {})\n",
            "    %mul_13 : [num_users=1] = call_function[target=operator.mul](args = (%dy, %getitem_27), kwargs = {})\n",
            "    %getitem_28 : [num_users=1] = call_function[target=operator.getitem](args = (%ctr_y, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_ctr_y : [num_users=2] = call_function[target=operator.add](args = (%mul_13, %getitem_28), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.exp](args = (%dw_1,), kwargs = {})\n",
            "    %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%widths, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_w : [num_users=1] = call_function[target=operator.mul](args = (%exp, %getitem_29), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.exp](args = (%dh_1,), kwargs = {})\n",
            "    %getitem_30 : [num_users=1] = call_function[target=operator.getitem](args = (%heights, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_h : [num_users=1] = call_function[target=operator.mul](args = (%exp_1, %getitem_30), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (0.5,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %c_to_c_h : [num_users=2] = call_function[target=operator.mul](args = (%tensor, %pred_h), kwargs = {})\n",
            "    %tensor_1 : [num_users=1] = call_function[target=torch.tensor](args = (0.5,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %c_to_c_w : [num_users=2] = call_function[target=operator.mul](args = (%tensor_1, %pred_w), kwargs = {})\n",
            "    %pred_boxes1 : [num_users=1] = call_function[target=operator.sub](args = (%pred_ctr_x, %c_to_c_w), kwargs = {})\n",
            "    %pred_boxes2 : [num_users=1] = call_function[target=operator.sub](args = (%pred_ctr_y, %c_to_c_h), kwargs = {})\n",
            "    %pred_boxes3 : [num_users=1] = call_function[target=operator.add](args = (%pred_ctr_x, %c_to_c_w), kwargs = {})\n",
            "    %pred_boxes4 : [num_users=1] = call_function[target=operator.add](args = (%pred_ctr_y, %c_to_c_h), kwargs = {})\n",
            "    %stack_5 : [num_users=1] = call_function[target=torch.stack](args = ((%pred_boxes1, %pred_boxes2, %pred_boxes3, %pred_boxes4),), kwargs = {dim: 2})\n",
            "    %pred_boxes : [num_users=1] = call_method[target=flatten](args = (%stack_5, 1), kwargs = {})\n",
            "    %proposals : [num_users=1] = call_method[target=reshape](args = (%pred_boxes, 159882, -1, 4), kwargs = {})\n",
            "    %proposals_1 : [num_users=1] = call_method[target=view](args = (%proposals, 1, -1, 4), kwargs = {})\n",
            "    return (proposals_1, objectness, pred_bbox_deltas, b, base_anchors, base_anchors_1, base_anchors_2, base_anchors_3, base_anchors_4)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %feature_map : torch.Tensor [num_users=1] = placeholder[target=L_features_0_]\n",
            "    %feature_map_1 : torch.Tensor [num_users=1] = placeholder[target=L_features_1_]\n",
            "    %feature_map_2 : torch.Tensor [num_users=1] = placeholder[target=L_features_2_]\n",
            "    %feature_map_3 : torch.Tensor [num_users=1] = placeholder[target=L_features_3_]\n",
            "    %feature_map_4 : torch.Tensor [num_users=1] = placeholder[target=L_features_pool_]\n",
            "    %clone_default_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_4,), kwargs = {})\n",
            "    %clone_default_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_3,), kwargs = {})\n",
            "    %clone_default_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_2,), kwargs = {})\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_1,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map,), kwargs = {})\n",
            "    %l__self___head_conv_0_0 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default,), kwargs = {})\n",
            "    %t : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_0,), kwargs = {})\n",
            "    %box_cls_per_level : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t,), kwargs = {})\n",
            "    %box_regression_per_level : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t,), kwargs = {})\n",
            "    %l__self___head_conv_0_2 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_1,), kwargs = {})\n",
            "    %t_1 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_2,), kwargs = {})\n",
            "    %box_cls_per_level_2 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_1,), kwargs = {})\n",
            "    %box_regression_per_level_2 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_1,), kwargs = {})\n",
            "    %l__self___head_conv_0_4 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_2,), kwargs = {})\n",
            "    %t_2 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_4,), kwargs = {})\n",
            "    %box_cls_per_level_4 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_2,), kwargs = {})\n",
            "    %box_regression_per_level_4 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_2,), kwargs = {})\n",
            "    %l__self___head_conv_0_6 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_3,), kwargs = {})\n",
            "    %t_3 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_6,), kwargs = {})\n",
            "    %box_cls_per_level_6 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_3,), kwargs = {})\n",
            "    %box_regression_per_level_6 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_3,), kwargs = {})\n",
            "    %l__self___head_conv_0_8 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_4,), kwargs = {})\n",
            "    %t_4 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_8,), kwargs = {})\n",
            "    %box_cls_per_level_8 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_4,), kwargs = {})\n",
            "    %box_regression_per_level_8 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_4,), kwargs = {})\n",
            "    %empty : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height : [num_users=1] = call_method[target=fill_](args = (%empty, 4), kwargs = {})\n",
            "    %empty_1 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width : [num_users=1] = call_method[target=fill_](args = (%empty_1, 4), kwargs = {})\n",
            "    %empty_2 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_1 : [num_users=1] = call_method[target=fill_](args = (%empty_2, 8), kwargs = {})\n",
            "    %empty_3 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_1 : [num_users=1] = call_method[target=fill_](args = (%empty_3, 8), kwargs = {})\n",
            "    %empty_4 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_2 : [num_users=1] = call_method[target=fill_](args = (%empty_4, 16), kwargs = {})\n",
            "    %empty_5 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_2 : [num_users=1] = call_method[target=fill_](args = (%empty_5, 16), kwargs = {})\n",
            "    %empty_6 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_3 : [num_users=1] = call_method[target=fill_](args = (%empty_6, 32), kwargs = {})\n",
            "    %empty_7 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_3 : [num_users=1] = call_method[target=fill_](args = (%empty_7, 32), kwargs = {})\n",
            "    %empty_8 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_4 : [num_users=1] = call_method[target=fill_](args = (%empty_8, 61), kwargs = {})\n",
            "    %empty_9 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_4 : [num_users=1] = call_method[target=fill_](args = (%empty_9, 61), kwargs = {})\n",
            "    %cell_anchor : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_0]\n",
            "    %base_anchors : [num_users=2] = call_method[target=to](args = (%cell_anchor,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_1 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_1]\n",
            "    %base_anchors_1 : [num_users=2] = call_method[target=to](args = (%cell_anchor_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_2 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_2]\n",
            "    %base_anchors_2 : [num_users=2] = call_method[target=to](args = (%cell_anchor_2,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_3 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_3]\n",
            "    %base_anchors_3 : [num_users=2] = call_method[target=to](args = (%cell_anchor_3,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_4 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_4]\n",
            "    %base_anchors_4 : [num_users=2] = call_method[target=to](args = (%cell_anchor_4,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %arange : [num_users=1] = call_function[target=torch.arange](args = (0, 200), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x : [num_users=1] = call_function[target=operator.mul](args = (%arange, %stride_width), kwargs = {})\n",
            "    %arange_1 : [num_users=1] = call_function[target=torch.arange](args = (0, 200), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y : [num_users=1] = call_function[target=operator.mul](args = (%arange_1, %stride_height), kwargs = {})\n",
            "    %meshgrid : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y, %shifts_x), kwargs = {indexing: ij})\n",
            "    %shift_y : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid, 0), kwargs = {})\n",
            "    %shift_x : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid, 1), kwargs = {})\n",
            "    %shift_x_1 : [num_users=1] = call_method[target=reshape](args = (%shift_x, -1), kwargs = {})\n",
            "    %shift_y_1 : [num_users=1] = call_method[target=reshape](args = (%shift_y, -1), kwargs = {})\n",
            "    %shifts : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_1, %shift_y_1, %shift_x_1, %shift_y_1),), kwargs = {dim: 1})\n",
            "    %view : [num_users=1] = call_method[target=view](args = (%shifts, -1, 1, 4), kwargs = {})\n",
            "    %view_1 : [num_users=1] = call_method[target=view](args = (%base_anchors, 1, -1, 4), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%view, %view_1), kwargs = {})\n",
            "    %anchors_per_feature_map : [num_users=1] = call_method[target=reshape](args = (%add, -1, 4), kwargs = {})\n",
            "    %arange_2 : [num_users=1] = call_function[target=torch.arange](args = (0, 100), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_1 : [num_users=1] = call_function[target=operator.mul](args = (%arange_2, %stride_width_1), kwargs = {})\n",
            "    %arange_3 : [num_users=1] = call_function[target=torch.arange](args = (0, 100), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_1 : [num_users=1] = call_function[target=operator.mul](args = (%arange_3, %stride_height_1), kwargs = {})\n",
            "    %meshgrid_1 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_1, %shifts_x_1), kwargs = {indexing: ij})\n",
            "    %shift_y_2 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_1, 0), kwargs = {})\n",
            "    %shift_x_2 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_1, 1), kwargs = {})\n",
            "    %shift_x_3 : [num_users=1] = call_method[target=reshape](args = (%shift_x_2, -1), kwargs = {})\n",
            "    %shift_y_3 : [num_users=1] = call_method[target=reshape](args = (%shift_y_2, -1), kwargs = {})\n",
            "    %shifts_1 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_3, %shift_y_3, %shift_x_3, %shift_y_3),), kwargs = {dim: 1})\n",
            "    %view_2 : [num_users=1] = call_method[target=view](args = (%shifts_1, -1, 1, 4), kwargs = {})\n",
            "    %view_3 : [num_users=1] = call_method[target=view](args = (%base_anchors_1, 1, -1, 4), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%view_2, %view_3), kwargs = {})\n",
            "    %anchors_per_feature_map_1 : [num_users=1] = call_method[target=reshape](args = (%add_1, -1, 4), kwargs = {})\n",
            "    %arange_4 : [num_users=1] = call_function[target=torch.arange](args = (0, 50), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_2 : [num_users=1] = call_function[target=operator.mul](args = (%arange_4, %stride_width_2), kwargs = {})\n",
            "    %arange_5 : [num_users=1] = call_function[target=torch.arange](args = (0, 50), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_2 : [num_users=1] = call_function[target=operator.mul](args = (%arange_5, %stride_height_2), kwargs = {})\n",
            "    %meshgrid_2 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_2, %shifts_x_2), kwargs = {indexing: ij})\n",
            "    %shift_y_4 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_2, 0), kwargs = {})\n",
            "    %shift_x_4 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_2, 1), kwargs = {})\n",
            "    %shift_x_5 : [num_users=1] = call_method[target=reshape](args = (%shift_x_4, -1), kwargs = {})\n",
            "    %shift_y_5 : [num_users=1] = call_method[target=reshape](args = (%shift_y_4, -1), kwargs = {})\n",
            "    %shifts_2 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_5, %shift_y_5, %shift_x_5, %shift_y_5),), kwargs = {dim: 1})\n",
            "    %view_4 : [num_users=1] = call_method[target=view](args = (%shifts_2, -1, 1, 4), kwargs = {})\n",
            "    %view_5 : [num_users=1] = call_method[target=view](args = (%base_anchors_2, 1, -1, 4), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%view_4, %view_5), kwargs = {})\n",
            "    %anchors_per_feature_map_2 : [num_users=1] = call_method[target=reshape](args = (%add_2, -1, 4), kwargs = {})\n",
            "    %arange_6 : [num_users=1] = call_function[target=torch.arange](args = (0, 25), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_3 : [num_users=1] = call_function[target=operator.mul](args = (%arange_6, %stride_width_3), kwargs = {})\n",
            "    %arange_7 : [num_users=1] = call_function[target=torch.arange](args = (0, 25), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_3 : [num_users=1] = call_function[target=operator.mul](args = (%arange_7, %stride_height_3), kwargs = {})\n",
            "    %meshgrid_3 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_3, %shifts_x_3), kwargs = {indexing: ij})\n",
            "    %shift_y_6 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_3, 0), kwargs = {})\n",
            "    %shift_x_6 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_3, 1), kwargs = {})\n",
            "    %shift_x_7 : [num_users=1] = call_method[target=reshape](args = (%shift_x_6, -1), kwargs = {})\n",
            "    %shift_y_7 : [num_users=1] = call_method[target=reshape](args = (%shift_y_6, -1), kwargs = {})\n",
            "    %shifts_3 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_7, %shift_y_7, %shift_x_7, %shift_y_7),), kwargs = {dim: 1})\n",
            "    %view_6 : [num_users=1] = call_method[target=view](args = (%shifts_3, -1, 1, 4), kwargs = {})\n",
            "    %view_7 : [num_users=1] = call_method[target=view](args = (%base_anchors_3, 1, -1, 4), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%view_6, %view_7), kwargs = {})\n",
            "    %anchors_per_feature_map_3 : [num_users=1] = call_method[target=reshape](args = (%add_3, -1, 4), kwargs = {})\n",
            "    %arange_8 : [num_users=1] = call_function[target=torch.arange](args = (0, 13), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_4 : [num_users=1] = call_function[target=operator.mul](args = (%arange_8, %stride_width_4), kwargs = {})\n",
            "    %arange_9 : [num_users=1] = call_function[target=torch.arange](args = (0, 13), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_4 : [num_users=1] = call_function[target=operator.mul](args = (%arange_9, %stride_height_4), kwargs = {})\n",
            "    %meshgrid_4 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_4, %shifts_x_4), kwargs = {indexing: ij})\n",
            "    %shift_y_8 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_4, 0), kwargs = {})\n",
            "    %shift_x_8 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_4, 1), kwargs = {})\n",
            "    %shift_x_9 : [num_users=1] = call_method[target=reshape](args = (%shift_x_8, -1), kwargs = {})\n",
            "    %shift_y_9 : [num_users=1] = call_method[target=reshape](args = (%shift_y_8, -1), kwargs = {})\n",
            "    %shifts_4 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_9, %shift_y_9, %shift_x_9, %shift_y_9),), kwargs = {dim: 1})\n",
            "    %view_8 : [num_users=1] = call_method[target=view](args = (%shifts_4, -1, 1, 4), kwargs = {})\n",
            "    %view_9 : [num_users=1] = call_method[target=view](args = (%base_anchors_4, 1, -1, 4), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%view_8, %view_9), kwargs = {})\n",
            "    %anchors_per_feature_map_4 : [num_users=1] = call_method[target=reshape](args = (%add_4, -1, 4), kwargs = {})\n",
            "    %b : [num_users=2] = call_function[target=torch.cat](args = ([%anchors_per_feature_map, %anchors_per_feature_map_1, %anchors_per_feature_map_2, %anchors_per_feature_map_3, %anchors_per_feature_map_4],), kwargs = {})\n",
            "    %layer : [num_users=1] = call_method[target=view](args = (%box_cls_per_level, 1, -1, 1, 200, 200), kwargs = {})\n",
            "    %layer_1 : [num_users=1] = call_method[target=permute](args = (%layer, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_1 : [num_users=1] = call_method[target=reshape](args = (%layer_1, 1, -1, 1), kwargs = {})\n",
            "    %layer_3 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level, 1, -1, 4, 200, 200), kwargs = {})\n",
            "    %layer_4 : [num_users=1] = call_method[target=permute](args = (%layer_3, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_1 : [num_users=1] = call_method[target=reshape](args = (%layer_4, 1, -1, 4), kwargs = {})\n",
            "    %layer_6 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_2, 1, -1, 1, 100, 100), kwargs = {})\n",
            "    %layer_7 : [num_users=1] = call_method[target=permute](args = (%layer_6, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_3 : [num_users=1] = call_method[target=reshape](args = (%layer_7, 1, -1, 1), kwargs = {})\n",
            "    %layer_9 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_2, 1, -1, 4, 100, 100), kwargs = {})\n",
            "    %layer_10 : [num_users=1] = call_method[target=permute](args = (%layer_9, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_3 : [num_users=1] = call_method[target=reshape](args = (%layer_10, 1, -1, 4), kwargs = {})\n",
            "    %layer_12 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_4, 1, -1, 1, 50, 50), kwargs = {})\n",
            "    %layer_13 : [num_users=1] = call_method[target=permute](args = (%layer_12, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_5 : [num_users=1] = call_method[target=reshape](args = (%layer_13, 1, -1, 1), kwargs = {})\n",
            "    %layer_15 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_4, 1, -1, 4, 50, 50), kwargs = {})\n",
            "    %layer_16 : [num_users=1] = call_method[target=permute](args = (%layer_15, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_5 : [num_users=1] = call_method[target=reshape](args = (%layer_16, 1, -1, 4), kwargs = {})\n",
            "    %layer_18 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_6, 1, -1, 1, 25, 25), kwargs = {})\n",
            "    %layer_19 : [num_users=1] = call_method[target=permute](args = (%layer_18, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_7 : [num_users=1] = call_method[target=reshape](args = (%layer_19, 1, -1, 1), kwargs = {})\n",
            "    %layer_21 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_6, 1, -1, 4, 25, 25), kwargs = {})\n",
            "    %layer_22 : [num_users=1] = call_method[target=permute](args = (%layer_21, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_7 : [num_users=1] = call_method[target=reshape](args = (%layer_22, 1, -1, 4), kwargs = {})\n",
            "    %layer_24 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_8, 1, -1, 1, 13, 13), kwargs = {})\n",
            "    %layer_25 : [num_users=1] = call_method[target=permute](args = (%layer_24, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_9 : [num_users=1] = call_method[target=reshape](args = (%layer_25, 1, -1, 1), kwargs = {})\n",
            "    %layer_27 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_8, 1, -1, 4, 13, 13), kwargs = {})\n",
            "    %layer_28 : [num_users=1] = call_method[target=permute](args = (%layer_27, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_9 : [num_users=1] = call_method[target=reshape](args = (%layer_28, 1, -1, 4), kwargs = {})\n",
            "    %cat_1 : [num_users=1] = call_function[target=torch.cat](args = ([%box_cls_per_level_1, %box_cls_per_level_3, %box_cls_per_level_5, %box_cls_per_level_7, %box_cls_per_level_9],), kwargs = {dim: 1})\n",
            "    %objectness : [num_users=1] = call_method[target=flatten](args = (%cat_1, 0, -2), kwargs = {})\n",
            "    %cat_2 : [num_users=1] = call_function[target=torch.cat](args = ([%box_regression_per_level_1, %box_regression_per_level_3, %box_regression_per_level_5, %box_regression_per_level_7, %box_regression_per_level_9],), kwargs = {dim: 1})\n",
            "    %pred_bbox_deltas : [num_users=2] = call_method[target=reshape](args = (%cat_2, -1, 4), kwargs = {})\n",
            "    %detach : [num_users=1] = call_method[target=detach](args = (%pred_bbox_deltas,), kwargs = {})\n",
            "    %concat_boxes : [num_users=1] = call_function[target=torch.cat](args = ([%b],), kwargs = {dim: 0})\n",
            "    %rel_codes : [num_users=4] = call_method[target=reshape](args = (%detach, 159882, -1), kwargs = {})\n",
            "    %boxes : [num_users=6] = call_method[target=to](args = (%concat_boxes, torch.float32), kwargs = {})\n",
            "    %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 2)), kwargs = {})\n",
            "    %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 0)), kwargs = {})\n",
            "    %widths : [num_users=3] = call_function[target=operator.sub](args = (%getitem_15, %getitem_16), kwargs = {})\n",
            "    %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 3)), kwargs = {})\n",
            "    %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 1)), kwargs = {})\n",
            "    %heights : [num_users=3] = call_function[target=operator.sub](args = (%getitem_17, %getitem_18), kwargs = {})\n",
            "    %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 0)), kwargs = {})\n",
            "    %mul_10 : [num_users=1] = call_function[target=operator.mul](args = (0.5, %widths), kwargs = {})\n",
            "    %ctr_x : [num_users=1] = call_function[target=operator.add](args = (%getitem_19, %mul_10), kwargs = {})\n",
            "    %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 1)), kwargs = {})\n",
            "    %mul_11 : [num_users=1] = call_function[target=operator.mul](args = (0.5, %heights), kwargs = {})\n",
            "    %ctr_y : [num_users=1] = call_function[target=operator.add](args = (%getitem_20, %mul_11), kwargs = {})\n",
            "    %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(0, None, 4))), kwargs = {})\n",
            "    %dx : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_21, 1.0), kwargs = {})\n",
            "    %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(1, None, 4))), kwargs = {})\n",
            "    %dy : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_22, 1.0), kwargs = {})\n",
            "    %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(2, None, 4))), kwargs = {})\n",
            "    %dw : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_23, 1.0), kwargs = {})\n",
            "    %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(3, None, 4))), kwargs = {})\n",
            "    %dh : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_24, 1.0), kwargs = {})\n",
            "    %dw_1 : [num_users=1] = call_function[target=torch.clamp](args = (%dw,), kwargs = {max: 4.135166556742356})\n",
            "    %dh_1 : [num_users=1] = call_function[target=torch.clamp](args = (%dh,), kwargs = {max: 4.135166556742356})\n",
            "    %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%widths, (slice(None, None, None), None)), kwargs = {})\n",
            "    %mul_12 : [num_users=1] = call_function[target=operator.mul](args = (%dx, %getitem_25), kwargs = {})\n",
            "    %getitem_26 : [num_users=1] = call_function[target=operator.getitem](args = (%ctr_x, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_ctr_x : [num_users=2] = call_function[target=operator.add](args = (%mul_12, %getitem_26), kwargs = {})\n",
            "    %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%heights, (slice(None, None, None), None)), kwargs = {})\n",
            "    %mul_13 : [num_users=1] = call_function[target=operator.mul](args = (%dy, %getitem_27), kwargs = {})\n",
            "    %getitem_28 : [num_users=1] = call_function[target=operator.getitem](args = (%ctr_y, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_ctr_y : [num_users=2] = call_function[target=operator.add](args = (%mul_13, %getitem_28), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.exp](args = (%dw_1,), kwargs = {})\n",
            "    %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%widths, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_w : [num_users=1] = call_function[target=operator.mul](args = (%exp, %getitem_29), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.exp](args = (%dh_1,), kwargs = {})\n",
            "    %getitem_30 : [num_users=1] = call_function[target=operator.getitem](args = (%heights, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_h : [num_users=1] = call_function[target=operator.mul](args = (%exp_1, %getitem_30), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (0.5,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %c_to_c_h : [num_users=2] = call_function[target=operator.mul](args = (%tensor, %pred_h), kwargs = {})\n",
            "    %tensor_1 : [num_users=1] = call_function[target=torch.tensor](args = (0.5,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %c_to_c_w : [num_users=2] = call_function[target=operator.mul](args = (%tensor_1, %pred_w), kwargs = {})\n",
            "    %pred_boxes1 : [num_users=1] = call_function[target=operator.sub](args = (%pred_ctr_x, %c_to_c_w), kwargs = {})\n",
            "    %pred_boxes2 : [num_users=1] = call_function[target=operator.sub](args = (%pred_ctr_y, %c_to_c_h), kwargs = {})\n",
            "    %pred_boxes3 : [num_users=1] = call_function[target=operator.add](args = (%pred_ctr_x, %c_to_c_w), kwargs = {})\n",
            "    %pred_boxes4 : [num_users=1] = call_function[target=operator.add](args = (%pred_ctr_y, %c_to_c_h), kwargs = {})\n",
            "    %stack_5 : [num_users=1] = call_function[target=torch.stack](args = ((%pred_boxes1, %pred_boxes2, %pred_boxes3, %pred_boxes4),), kwargs = {dim: 2})\n",
            "    %pred_boxes : [num_users=1] = call_method[target=flatten](args = (%stack_5, 1), kwargs = {})\n",
            "    %proposals : [num_users=1] = call_method[target=reshape](args = (%pred_boxes, 159882, -1, 4), kwargs = {})\n",
            "    %proposals_1 : [num_users=1] = call_method[target=view](args = (%proposals, 1, -1, 4), kwargs = {})\n",
            "    return (proposals_1, objectness, pred_bbox_deltas, b, base_anchors, base_anchors_1, base_anchors_2, base_anchors_3, base_anchors_4)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %feature_map : torch.Tensor [num_users=1] = placeholder[target=L_features_0_]\n",
            "    %feature_map_1 : torch.Tensor [num_users=1] = placeholder[target=L_features_1_]\n",
            "    %feature_map_2 : torch.Tensor [num_users=1] = placeholder[target=L_features_2_]\n",
            "    %feature_map_3 : torch.Tensor [num_users=1] = placeholder[target=L_features_3_]\n",
            "    %feature_map_4 : torch.Tensor [num_users=1] = placeholder[target=L_features_pool_]\n",
            "    %clone_default_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_4,), kwargs = {})\n",
            "    %clone_default_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_3,), kwargs = {})\n",
            "    %clone_default_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_2,), kwargs = {})\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_1,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map,), kwargs = {})\n",
            "    %l__self___head_conv_0_0 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default,), kwargs = {})\n",
            "    %t : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_0,), kwargs = {})\n",
            "    %box_cls_per_level : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t,), kwargs = {})\n",
            "    %box_regression_per_level : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t,), kwargs = {})\n",
            "    %l__self___head_conv_0_2 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_1,), kwargs = {})\n",
            "    %t_1 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_2,), kwargs = {})\n",
            "    %box_cls_per_level_2 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_1,), kwargs = {})\n",
            "    %box_regression_per_level_2 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_1,), kwargs = {})\n",
            "    %l__self___head_conv_0_4 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_2,), kwargs = {})\n",
            "    %t_2 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_4,), kwargs = {})\n",
            "    %box_cls_per_level_4 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_2,), kwargs = {})\n",
            "    %box_regression_per_level_4 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_2,), kwargs = {})\n",
            "    %l__self___head_conv_0_6 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_3,), kwargs = {})\n",
            "    %t_3 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_6,), kwargs = {})\n",
            "    %box_cls_per_level_6 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_3,), kwargs = {})\n",
            "    %box_regression_per_level_6 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_3,), kwargs = {})\n",
            "    %l__self___head_conv_0_8 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_4,), kwargs = {})\n",
            "    %t_4 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_8,), kwargs = {})\n",
            "    %box_cls_per_level_8 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_4,), kwargs = {})\n",
            "    %box_regression_per_level_8 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_4,), kwargs = {})\n",
            "    %empty : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height : [num_users=1] = call_method[target=fill_](args = (%empty, 4), kwargs = {})\n",
            "    %empty_1 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width : [num_users=1] = call_method[target=fill_](args = (%empty_1, 4), kwargs = {})\n",
            "    %empty_2 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_1 : [num_users=1] = call_method[target=fill_](args = (%empty_2, 8), kwargs = {})\n",
            "    %empty_3 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_1 : [num_users=1] = call_method[target=fill_](args = (%empty_3, 8), kwargs = {})\n",
            "    %empty_4 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_2 : [num_users=1] = call_method[target=fill_](args = (%empty_4, 16), kwargs = {})\n",
            "    %empty_5 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_2 : [num_users=1] = call_method[target=fill_](args = (%empty_5, 16), kwargs = {})\n",
            "    %empty_6 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_3 : [num_users=1] = call_method[target=fill_](args = (%empty_6, 32), kwargs = {})\n",
            "    %empty_7 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_3 : [num_users=1] = call_method[target=fill_](args = (%empty_7, 32), kwargs = {})\n",
            "    %empty_8 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_4 : [num_users=1] = call_method[target=fill_](args = (%empty_8, 61), kwargs = {})\n",
            "    %empty_9 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_4 : [num_users=1] = call_method[target=fill_](args = (%empty_9, 61), kwargs = {})\n",
            "    %cell_anchor : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_0]\n",
            "    %base_anchors : [num_users=2] = call_method[target=to](args = (%cell_anchor,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_1 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_1]\n",
            "    %base_anchors_1 : [num_users=2] = call_method[target=to](args = (%cell_anchor_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_2 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_2]\n",
            "    %base_anchors_2 : [num_users=2] = call_method[target=to](args = (%cell_anchor_2,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_3 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_3]\n",
            "    %base_anchors_3 : [num_users=2] = call_method[target=to](args = (%cell_anchor_3,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_4 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_4]\n",
            "    %base_anchors_4 : [num_users=2] = call_method[target=to](args = (%cell_anchor_4,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %arange : [num_users=1] = call_function[target=torch.arange](args = (0, 200), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x : [num_users=1] = call_function[target=operator.mul](args = (%arange, %stride_width), kwargs = {})\n",
            "    %arange_1 : [num_users=1] = call_function[target=torch.arange](args = (0, 200), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y : [num_users=1] = call_function[target=operator.mul](args = (%arange_1, %stride_height), kwargs = {})\n",
            "    %meshgrid : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y, %shifts_x), kwargs = {indexing: ij})\n",
            "    %shift_y : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid, 0), kwargs = {})\n",
            "    %shift_x : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid, 1), kwargs = {})\n",
            "    %shift_x_1 : [num_users=1] = call_method[target=reshape](args = (%shift_x, -1), kwargs = {})\n",
            "    %shift_y_1 : [num_users=1] = call_method[target=reshape](args = (%shift_y, -1), kwargs = {})\n",
            "    %shifts : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_1, %shift_y_1, %shift_x_1, %shift_y_1),), kwargs = {dim: 1})\n",
            "    %view : [num_users=1] = call_method[target=view](args = (%shifts, -1, 1, 4), kwargs = {})\n",
            "    %view_1 : [num_users=1] = call_method[target=view](args = (%base_anchors, 1, -1, 4), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%view, %view_1), kwargs = {})\n",
            "    %anchors_per_feature_map : [num_users=1] = call_method[target=reshape](args = (%add, -1, 4), kwargs = {})\n",
            "    %arange_2 : [num_users=1] = call_function[target=torch.arange](args = (0, 100), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_1 : [num_users=1] = call_function[target=operator.mul](args = (%arange_2, %stride_width_1), kwargs = {})\n",
            "    %arange_3 : [num_users=1] = call_function[target=torch.arange](args = (0, 100), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_1 : [num_users=1] = call_function[target=operator.mul](args = (%arange_3, %stride_height_1), kwargs = {})\n",
            "    %meshgrid_1 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_1, %shifts_x_1), kwargs = {indexing: ij})\n",
            "    %shift_y_2 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_1, 0), kwargs = {})\n",
            "    %shift_x_2 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_1, 1), kwargs = {})\n",
            "    %shift_x_3 : [num_users=1] = call_method[target=reshape](args = (%shift_x_2, -1), kwargs = {})\n",
            "    %shift_y_3 : [num_users=1] = call_method[target=reshape](args = (%shift_y_2, -1), kwargs = {})\n",
            "    %shifts_1 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_3, %shift_y_3, %shift_x_3, %shift_y_3),), kwargs = {dim: 1})\n",
            "    %view_2 : [num_users=1] = call_method[target=view](args = (%shifts_1, -1, 1, 4), kwargs = {})\n",
            "    %view_3 : [num_users=1] = call_method[target=view](args = (%base_anchors_1, 1, -1, 4), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%view_2, %view_3), kwargs = {})\n",
            "    %anchors_per_feature_map_1 : [num_users=1] = call_method[target=reshape](args = (%add_1, -1, 4), kwargs = {})\n",
            "    %arange_4 : [num_users=1] = call_function[target=torch.arange](args = (0, 50), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_2 : [num_users=1] = call_function[target=operator.mul](args = (%arange_4, %stride_width_2), kwargs = {})\n",
            "    %arange_5 : [num_users=1] = call_function[target=torch.arange](args = (0, 50), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_2 : [num_users=1] = call_function[target=operator.mul](args = (%arange_5, %stride_height_2), kwargs = {})\n",
            "    %meshgrid_2 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_2, %shifts_x_2), kwargs = {indexing: ij})\n",
            "    %shift_y_4 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_2, 0), kwargs = {})\n",
            "    %shift_x_4 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_2, 1), kwargs = {})\n",
            "    %shift_x_5 : [num_users=1] = call_method[target=reshape](args = (%shift_x_4, -1), kwargs = {})\n",
            "    %shift_y_5 : [num_users=1] = call_method[target=reshape](args = (%shift_y_4, -1), kwargs = {})\n",
            "    %shifts_2 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_5, %shift_y_5, %shift_x_5, %shift_y_5),), kwargs = {dim: 1})\n",
            "    %view_4 : [num_users=1] = call_method[target=view](args = (%shifts_2, -1, 1, 4), kwargs = {})\n",
            "    %view_5 : [num_users=1] = call_method[target=view](args = (%base_anchors_2, 1, -1, 4), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%view_4, %view_5), kwargs = {})\n",
            "    %anchors_per_feature_map_2 : [num_users=1] = call_method[target=reshape](args = (%add_2, -1, 4), kwargs = {})\n",
            "    %arange_6 : [num_users=1] = call_function[target=torch.arange](args = (0, 25), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_3 : [num_users=1] = call_function[target=operator.mul](args = (%arange_6, %stride_width_3), kwargs = {})\n",
            "    %arange_7 : [num_users=1] = call_function[target=torch.arange](args = (0, 25), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_3 : [num_users=1] = call_function[target=operator.mul](args = (%arange_7, %stride_height_3), kwargs = {})\n",
            "    %meshgrid_3 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_3, %shifts_x_3), kwargs = {indexing: ij})\n",
            "    %shift_y_6 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_3, 0), kwargs = {})\n",
            "    %shift_x_6 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_3, 1), kwargs = {})\n",
            "    %shift_x_7 : [num_users=1] = call_method[target=reshape](args = (%shift_x_6, -1), kwargs = {})\n",
            "    %shift_y_7 : [num_users=1] = call_method[target=reshape](args = (%shift_y_6, -1), kwargs = {})\n",
            "    %shifts_3 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_7, %shift_y_7, %shift_x_7, %shift_y_7),), kwargs = {dim: 1})\n",
            "    %view_6 : [num_users=1] = call_method[target=view](args = (%shifts_3, -1, 1, 4), kwargs = {})\n",
            "    %view_7 : [num_users=1] = call_method[target=view](args = (%base_anchors_3, 1, -1, 4), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%view_6, %view_7), kwargs = {})\n",
            "    %anchors_per_feature_map_3 : [num_users=1] = call_method[target=reshape](args = (%add_3, -1, 4), kwargs = {})\n",
            "    %arange_8 : [num_users=1] = call_function[target=torch.arange](args = (0, 13), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_4 : [num_users=1] = call_function[target=operator.mul](args = (%arange_8, %stride_width_4), kwargs = {})\n",
            "    %arange_9 : [num_users=1] = call_function[target=torch.arange](args = (0, 13), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_4 : [num_users=1] = call_function[target=operator.mul](args = (%arange_9, %stride_height_4), kwargs = {})\n",
            "    %meshgrid_4 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_4, %shifts_x_4), kwargs = {indexing: ij})\n",
            "    %shift_y_8 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_4, 0), kwargs = {})\n",
            "    %shift_x_8 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_4, 1), kwargs = {})\n",
            "    %shift_x_9 : [num_users=1] = call_method[target=reshape](args = (%shift_x_8, -1), kwargs = {})\n",
            "    %shift_y_9 : [num_users=1] = call_method[target=reshape](args = (%shift_y_8, -1), kwargs = {})\n",
            "    %shifts_4 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_9, %shift_y_9, %shift_x_9, %shift_y_9),), kwargs = {dim: 1})\n",
            "    %view_8 : [num_users=1] = call_method[target=view](args = (%shifts_4, -1, 1, 4), kwargs = {})\n",
            "    %view_9 : [num_users=1] = call_method[target=view](args = (%base_anchors_4, 1, -1, 4), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%view_8, %view_9), kwargs = {})\n",
            "    %anchors_per_feature_map_4 : [num_users=1] = call_method[target=reshape](args = (%add_4, -1, 4), kwargs = {})\n",
            "    %b : [num_users=2] = call_function[target=torch.cat](args = ([%anchors_per_feature_map, %anchors_per_feature_map_1, %anchors_per_feature_map_2, %anchors_per_feature_map_3, %anchors_per_feature_map_4],), kwargs = {})\n",
            "    %layer : [num_users=1] = call_method[target=view](args = (%box_cls_per_level, 1, -1, 1, 200, 200), kwargs = {})\n",
            "    %layer_1 : [num_users=1] = call_method[target=permute](args = (%layer, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_1 : [num_users=1] = call_method[target=reshape](args = (%layer_1, 1, -1, 1), kwargs = {})\n",
            "    %layer_3 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level, 1, -1, 4, 200, 200), kwargs = {})\n",
            "    %layer_4 : [num_users=1] = call_method[target=permute](args = (%layer_3, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_1 : [num_users=1] = call_method[target=reshape](args = (%layer_4, 1, -1, 4), kwargs = {})\n",
            "    %layer_6 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_2, 1, -1, 1, 100, 100), kwargs = {})\n",
            "    %layer_7 : [num_users=1] = call_method[target=permute](args = (%layer_6, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_3 : [num_users=1] = call_method[target=reshape](args = (%layer_7, 1, -1, 1), kwargs = {})\n",
            "    %layer_9 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_2, 1, -1, 4, 100, 100), kwargs = {})\n",
            "    %layer_10 : [num_users=1] = call_method[target=permute](args = (%layer_9, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_3 : [num_users=1] = call_method[target=reshape](args = (%layer_10, 1, -1, 4), kwargs = {})\n",
            "    %layer_12 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_4, 1, -1, 1, 50, 50), kwargs = {})\n",
            "    %layer_13 : [num_users=1] = call_method[target=permute](args = (%layer_12, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_5 : [num_users=1] = call_method[target=reshape](args = (%layer_13, 1, -1, 1), kwargs = {})\n",
            "    %layer_15 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_4, 1, -1, 4, 50, 50), kwargs = {})\n",
            "    %layer_16 : [num_users=1] = call_method[target=permute](args = (%layer_15, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_5 : [num_users=1] = call_method[target=reshape](args = (%layer_16, 1, -1, 4), kwargs = {})\n",
            "    %layer_18 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_6, 1, -1, 1, 25, 25), kwargs = {})\n",
            "    %layer_19 : [num_users=1] = call_method[target=permute](args = (%layer_18, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_7 : [num_users=1] = call_method[target=reshape](args = (%layer_19, 1, -1, 1), kwargs = {})\n",
            "    %layer_21 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_6, 1, -1, 4, 25, 25), kwargs = {})\n",
            "    %layer_22 : [num_users=1] = call_method[target=permute](args = (%layer_21, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_7 : [num_users=1] = call_method[target=reshape](args = (%layer_22, 1, -1, 4), kwargs = {})\n",
            "    %layer_24 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_8, 1, -1, 1, 13, 13), kwargs = {})\n",
            "    %layer_25 : [num_users=1] = call_method[target=permute](args = (%layer_24, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_9 : [num_users=1] = call_method[target=reshape](args = (%layer_25, 1, -1, 1), kwargs = {})\n",
            "    %layer_27 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_8, 1, -1, 4, 13, 13), kwargs = {})\n",
            "    %layer_28 : [num_users=1] = call_method[target=permute](args = (%layer_27, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_9 : [num_users=1] = call_method[target=reshape](args = (%layer_28, 1, -1, 4), kwargs = {})\n",
            "    %cat_1 : [num_users=1] = call_function[target=torch.cat](args = ([%box_cls_per_level_1, %box_cls_per_level_3, %box_cls_per_level_5, %box_cls_per_level_7, %box_cls_per_level_9],), kwargs = {dim: 1})\n",
            "    %objectness : [num_users=1] = call_method[target=flatten](args = (%cat_1, 0, -2), kwargs = {})\n",
            "    %cat_2 : [num_users=1] = call_function[target=torch.cat](args = ([%box_regression_per_level_1, %box_regression_per_level_3, %box_regression_per_level_5, %box_regression_per_level_7, %box_regression_per_level_9],), kwargs = {dim: 1})\n",
            "    %pred_bbox_deltas : [num_users=2] = call_method[target=reshape](args = (%cat_2, -1, 4), kwargs = {})\n",
            "    %detach : [num_users=1] = call_method[target=detach](args = (%pred_bbox_deltas,), kwargs = {})\n",
            "    %concat_boxes : [num_users=1] = call_function[target=torch.cat](args = ([%b],), kwargs = {dim: 0})\n",
            "    %rel_codes : [num_users=4] = call_method[target=reshape](args = (%detach, 159882, -1), kwargs = {})\n",
            "    %boxes : [num_users=6] = call_method[target=to](args = (%concat_boxes, torch.float32), kwargs = {})\n",
            "    %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 2)), kwargs = {})\n",
            "    %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 0)), kwargs = {})\n",
            "    %widths : [num_users=3] = call_function[target=operator.sub](args = (%getitem_15, %getitem_16), kwargs = {})\n",
            "    %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 3)), kwargs = {})\n",
            "    %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 1)), kwargs = {})\n",
            "    %heights : [num_users=3] = call_function[target=operator.sub](args = (%getitem_17, %getitem_18), kwargs = {})\n",
            "    %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 0)), kwargs = {})\n",
            "    %mul_10 : [num_users=1] = call_function[target=operator.mul](args = (0.5, %widths), kwargs = {})\n",
            "    %ctr_x : [num_users=1] = call_function[target=operator.add](args = (%getitem_19, %mul_10), kwargs = {})\n",
            "    %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 1)), kwargs = {})\n",
            "    %mul_11 : [num_users=1] = call_function[target=operator.mul](args = (0.5, %heights), kwargs = {})\n",
            "    %ctr_y : [num_users=1] = call_function[target=operator.add](args = (%getitem_20, %mul_11), kwargs = {})\n",
            "    %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(0, None, 4))), kwargs = {})\n",
            "    %dx : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_21, 1.0), kwargs = {})\n",
            "    %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(1, None, 4))), kwargs = {})\n",
            "    %dy : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_22, 1.0), kwargs = {})\n",
            "    %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(2, None, 4))), kwargs = {})\n",
            "    %dw : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_23, 1.0), kwargs = {})\n",
            "    %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(3, None, 4))), kwargs = {})\n",
            "    %dh : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_24, 1.0), kwargs = {})\n",
            "    %dw_1 : [num_users=1] = call_function[target=torch.clamp](args = (%dw,), kwargs = {max: 4.135166556742356})\n",
            "    %dh_1 : [num_users=1] = call_function[target=torch.clamp](args = (%dh,), kwargs = {max: 4.135166556742356})\n",
            "    %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%widths, (slice(None, None, None), None)), kwargs = {})\n",
            "    %mul_12 : [num_users=1] = call_function[target=operator.mul](args = (%dx, %getitem_25), kwargs = {})\n",
            "    %getitem_26 : [num_users=1] = call_function[target=operator.getitem](args = (%ctr_x, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_ctr_x : [num_users=2] = call_function[target=operator.add](args = (%mul_12, %getitem_26), kwargs = {})\n",
            "    %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%heights, (slice(None, None, None), None)), kwargs = {})\n",
            "    %mul_13 : [num_users=1] = call_function[target=operator.mul](args = (%dy, %getitem_27), kwargs = {})\n",
            "    %getitem_28 : [num_users=1] = call_function[target=operator.getitem](args = (%ctr_y, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_ctr_y : [num_users=2] = call_function[target=operator.add](args = (%mul_13, %getitem_28), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.exp](args = (%dw_1,), kwargs = {})\n",
            "    %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%widths, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_w : [num_users=1] = call_function[target=operator.mul](args = (%exp, %getitem_29), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.exp](args = (%dh_1,), kwargs = {})\n",
            "    %getitem_30 : [num_users=1] = call_function[target=operator.getitem](args = (%heights, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_h : [num_users=1] = call_function[target=operator.mul](args = (%exp_1, %getitem_30), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (0.5,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %c_to_c_h : [num_users=2] = call_function[target=operator.mul](args = (%tensor, %pred_h), kwargs = {})\n",
            "    %tensor_1 : [num_users=1] = call_function[target=torch.tensor](args = (0.5,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %c_to_c_w : [num_users=2] = call_function[target=operator.mul](args = (%tensor_1, %pred_w), kwargs = {})\n",
            "    %pred_boxes1 : [num_users=1] = call_function[target=operator.sub](args = (%pred_ctr_x, %c_to_c_w), kwargs = {})\n",
            "    %pred_boxes2 : [num_users=1] = call_function[target=operator.sub](args = (%pred_ctr_y, %c_to_c_h), kwargs = {})\n",
            "    %pred_boxes3 : [num_users=1] = call_function[target=operator.add](args = (%pred_ctr_x, %c_to_c_w), kwargs = {})\n",
            "    %pred_boxes4 : [num_users=1] = call_function[target=operator.add](args = (%pred_ctr_y, %c_to_c_h), kwargs = {})\n",
            "    %stack_5 : [num_users=1] = call_function[target=torch.stack](args = ((%pred_boxes1, %pred_boxes2, %pred_boxes3, %pred_boxes4),), kwargs = {dim: 2})\n",
            "    %pred_boxes : [num_users=1] = call_method[target=flatten](args = (%stack_5, 1), kwargs = {})\n",
            "    %proposals : [num_users=1] = call_method[target=reshape](args = (%pred_boxes, 159882, -1, 4), kwargs = {})\n",
            "    %proposals_1 : [num_users=1] = call_method[target=view](args = (%proposals, 1, -1, 4), kwargs = {})\n",
            "    return (proposals_1, objectness, pred_bbox_deltas, b, base_anchors, base_anchors_1, base_anchors_2, base_anchors_3, base_anchors_4)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 1 detach nodes:\n",
            "graph():\n",
            "    %feature_map : torch.Tensor [num_users=1] = placeholder[target=L_features_0_]\n",
            "    %feature_map_1 : torch.Tensor [num_users=1] = placeholder[target=L_features_1_]\n",
            "    %feature_map_2 : torch.Tensor [num_users=1] = placeholder[target=L_features_2_]\n",
            "    %feature_map_3 : torch.Tensor [num_users=1] = placeholder[target=L_features_3_]\n",
            "    %feature_map_4 : torch.Tensor [num_users=1] = placeholder[target=L_features_pool_]\n",
            "    %clone_default_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_4,), kwargs = {})\n",
            "    %clone_default_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_3,), kwargs = {})\n",
            "    %clone_default_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_2,), kwargs = {})\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map_1,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%feature_map,), kwargs = {})\n",
            "    %l__self___head_conv_0_0 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default,), kwargs = {})\n",
            "    %t : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_0,), kwargs = {})\n",
            "    %box_cls_per_level : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t,), kwargs = {})\n",
            "    %box_regression_per_level : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t,), kwargs = {})\n",
            "    %l__self___head_conv_0_2 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_1,), kwargs = {})\n",
            "    %t_1 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_2,), kwargs = {})\n",
            "    %box_cls_per_level_2 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_1,), kwargs = {})\n",
            "    %box_regression_per_level_2 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_1,), kwargs = {})\n",
            "    %l__self___head_conv_0_4 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_2,), kwargs = {})\n",
            "    %t_2 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_4,), kwargs = {})\n",
            "    %box_cls_per_level_4 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_2,), kwargs = {})\n",
            "    %box_regression_per_level_4 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_2,), kwargs = {})\n",
            "    %l__self___head_conv_0_6 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_3,), kwargs = {})\n",
            "    %t_3 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_6,), kwargs = {})\n",
            "    %box_cls_per_level_6 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_3,), kwargs = {})\n",
            "    %box_regression_per_level_6 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_3,), kwargs = {})\n",
            "    %l__self___head_conv_0_8 : [num_users=1] = call_module[target=L__self___head_conv_0_0](args = (%clone_default_4,), kwargs = {})\n",
            "    %t_4 : [num_users=2] = call_module[target=L__self___head_conv_0_1](args = (%l__self___head_conv_0_8,), kwargs = {})\n",
            "    %box_cls_per_level_8 : [num_users=1] = call_module[target=L__self___head_cls_logits](args = (%t_4,), kwargs = {})\n",
            "    %box_regression_per_level_8 : [num_users=1] = call_module[target=L__self___head_bbox_pred](args = (%t_4,), kwargs = {})\n",
            "    %empty : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height : [num_users=1] = call_method[target=fill_](args = (%empty, 4), kwargs = {})\n",
            "    %empty_1 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width : [num_users=1] = call_method[target=fill_](args = (%empty_1, 4), kwargs = {})\n",
            "    %empty_2 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_1 : [num_users=1] = call_method[target=fill_](args = (%empty_2, 8), kwargs = {})\n",
            "    %empty_3 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_1 : [num_users=1] = call_method[target=fill_](args = (%empty_3, 8), kwargs = {})\n",
            "    %empty_4 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_2 : [num_users=1] = call_method[target=fill_](args = (%empty_4, 16), kwargs = {})\n",
            "    %empty_5 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_2 : [num_users=1] = call_method[target=fill_](args = (%empty_5, 16), kwargs = {})\n",
            "    %empty_6 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_3 : [num_users=1] = call_method[target=fill_](args = (%empty_6, 32), kwargs = {})\n",
            "    %empty_7 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_3 : [num_users=1] = call_method[target=fill_](args = (%empty_7, 32), kwargs = {})\n",
            "    %empty_8 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_height_4 : [num_users=1] = call_method[target=fill_](args = (%empty_8, 61), kwargs = {})\n",
            "    %empty_9 : [num_users=1] = call_function[target=torch.empty](args = ((),), kwargs = {dtype: torch.int64, device: cuda:0})\n",
            "    %stride_width_4 : [num_users=1] = call_method[target=fill_](args = (%empty_9, 61), kwargs = {})\n",
            "    %cell_anchor : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_0]\n",
            "    %base_anchors : [num_users=2] = call_method[target=to](args = (%cell_anchor,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_1 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_1]\n",
            "    %base_anchors_1 : [num_users=2] = call_method[target=to](args = (%cell_anchor_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_2 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_2]\n",
            "    %base_anchors_2 : [num_users=2] = call_method[target=to](args = (%cell_anchor_2,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_3 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_3]\n",
            "    %base_anchors_3 : [num_users=2] = call_method[target=to](args = (%cell_anchor_3,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %cell_anchor_4 : [num_users=1] = get_attr[target=self___anchor_generator_cell_anchors_4]\n",
            "    %base_anchors_4 : [num_users=2] = call_method[target=to](args = (%cell_anchor_4,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %arange : [num_users=1] = call_function[target=torch.arange](args = (0, 200), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x : [num_users=1] = call_function[target=operator.mul](args = (%arange, %stride_width), kwargs = {})\n",
            "    %arange_1 : [num_users=1] = call_function[target=torch.arange](args = (0, 200), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y : [num_users=1] = call_function[target=operator.mul](args = (%arange_1, %stride_height), kwargs = {})\n",
            "    %meshgrid : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y, %shifts_x), kwargs = {indexing: ij})\n",
            "    %shift_y : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid, 0), kwargs = {})\n",
            "    %shift_x : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid, 1), kwargs = {})\n",
            "    %shift_x_1 : [num_users=1] = call_method[target=reshape](args = (%shift_x, -1), kwargs = {})\n",
            "    %shift_y_1 : [num_users=1] = call_method[target=reshape](args = (%shift_y, -1), kwargs = {})\n",
            "    %shifts : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_1, %shift_y_1, %shift_x_1, %shift_y_1),), kwargs = {dim: 1})\n",
            "    %view : [num_users=1] = call_method[target=view](args = (%shifts, -1, 1, 4), kwargs = {})\n",
            "    %view_1 : [num_users=1] = call_method[target=view](args = (%base_anchors, 1, -1, 4), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%view, %view_1), kwargs = {})\n",
            "    %anchors_per_feature_map : [num_users=1] = call_method[target=reshape](args = (%add, -1, 4), kwargs = {})\n",
            "    %arange_2 : [num_users=1] = call_function[target=torch.arange](args = (0, 100), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_1 : [num_users=1] = call_function[target=operator.mul](args = (%arange_2, %stride_width_1), kwargs = {})\n",
            "    %arange_3 : [num_users=1] = call_function[target=torch.arange](args = (0, 100), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_1 : [num_users=1] = call_function[target=operator.mul](args = (%arange_3, %stride_height_1), kwargs = {})\n",
            "    %meshgrid_1 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_1, %shifts_x_1), kwargs = {indexing: ij})\n",
            "    %shift_y_2 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_1, 0), kwargs = {})\n",
            "    %shift_x_2 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_1, 1), kwargs = {})\n",
            "    %shift_x_3 : [num_users=1] = call_method[target=reshape](args = (%shift_x_2, -1), kwargs = {})\n",
            "    %shift_y_3 : [num_users=1] = call_method[target=reshape](args = (%shift_y_2, -1), kwargs = {})\n",
            "    %shifts_1 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_3, %shift_y_3, %shift_x_3, %shift_y_3),), kwargs = {dim: 1})\n",
            "    %view_2 : [num_users=1] = call_method[target=view](args = (%shifts_1, -1, 1, 4), kwargs = {})\n",
            "    %view_3 : [num_users=1] = call_method[target=view](args = (%base_anchors_1, 1, -1, 4), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%view_2, %view_3), kwargs = {})\n",
            "    %anchors_per_feature_map_1 : [num_users=1] = call_method[target=reshape](args = (%add_1, -1, 4), kwargs = {})\n",
            "    %arange_4 : [num_users=1] = call_function[target=torch.arange](args = (0, 50), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_2 : [num_users=1] = call_function[target=operator.mul](args = (%arange_4, %stride_width_2), kwargs = {})\n",
            "    %arange_5 : [num_users=1] = call_function[target=torch.arange](args = (0, 50), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_2 : [num_users=1] = call_function[target=operator.mul](args = (%arange_5, %stride_height_2), kwargs = {})\n",
            "    %meshgrid_2 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_2, %shifts_x_2), kwargs = {indexing: ij})\n",
            "    %shift_y_4 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_2, 0), kwargs = {})\n",
            "    %shift_x_4 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_2, 1), kwargs = {})\n",
            "    %shift_x_5 : [num_users=1] = call_method[target=reshape](args = (%shift_x_4, -1), kwargs = {})\n",
            "    %shift_y_5 : [num_users=1] = call_method[target=reshape](args = (%shift_y_4, -1), kwargs = {})\n",
            "    %shifts_2 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_5, %shift_y_5, %shift_x_5, %shift_y_5),), kwargs = {dim: 1})\n",
            "    %view_4 : [num_users=1] = call_method[target=view](args = (%shifts_2, -1, 1, 4), kwargs = {})\n",
            "    %view_5 : [num_users=1] = call_method[target=view](args = (%base_anchors_2, 1, -1, 4), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%view_4, %view_5), kwargs = {})\n",
            "    %anchors_per_feature_map_2 : [num_users=1] = call_method[target=reshape](args = (%add_2, -1, 4), kwargs = {})\n",
            "    %arange_6 : [num_users=1] = call_function[target=torch.arange](args = (0, 25), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_3 : [num_users=1] = call_function[target=operator.mul](args = (%arange_6, %stride_width_3), kwargs = {})\n",
            "    %arange_7 : [num_users=1] = call_function[target=torch.arange](args = (0, 25), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_3 : [num_users=1] = call_function[target=operator.mul](args = (%arange_7, %stride_height_3), kwargs = {})\n",
            "    %meshgrid_3 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_3, %shifts_x_3), kwargs = {indexing: ij})\n",
            "    %shift_y_6 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_3, 0), kwargs = {})\n",
            "    %shift_x_6 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_3, 1), kwargs = {})\n",
            "    %shift_x_7 : [num_users=1] = call_method[target=reshape](args = (%shift_x_6, -1), kwargs = {})\n",
            "    %shift_y_7 : [num_users=1] = call_method[target=reshape](args = (%shift_y_6, -1), kwargs = {})\n",
            "    %shifts_3 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_7, %shift_y_7, %shift_x_7, %shift_y_7),), kwargs = {dim: 1})\n",
            "    %view_6 : [num_users=1] = call_method[target=view](args = (%shifts_3, -1, 1, 4), kwargs = {})\n",
            "    %view_7 : [num_users=1] = call_method[target=view](args = (%base_anchors_3, 1, -1, 4), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%view_6, %view_7), kwargs = {})\n",
            "    %anchors_per_feature_map_3 : [num_users=1] = call_method[target=reshape](args = (%add_3, -1, 4), kwargs = {})\n",
            "    %arange_8 : [num_users=1] = call_function[target=torch.arange](args = (0, 13), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_x_4 : [num_users=1] = call_function[target=operator.mul](args = (%arange_8, %stride_width_4), kwargs = {})\n",
            "    %arange_9 : [num_users=1] = call_function[target=torch.arange](args = (0, 13), kwargs = {dtype: torch.int32, device: cuda:0})\n",
            "    %shifts_y_4 : [num_users=1] = call_function[target=operator.mul](args = (%arange_9, %stride_height_4), kwargs = {})\n",
            "    %meshgrid_4 : [num_users=2] = call_function[target=torch.functional.meshgrid](args = (%shifts_y_4, %shifts_x_4), kwargs = {indexing: ij})\n",
            "    %shift_y_8 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_4, 0), kwargs = {})\n",
            "    %shift_x_8 : [num_users=1] = call_function[target=operator.getitem](args = (%meshgrid_4, 1), kwargs = {})\n",
            "    %shift_x_9 : [num_users=1] = call_method[target=reshape](args = (%shift_x_8, -1), kwargs = {})\n",
            "    %shift_y_9 : [num_users=1] = call_method[target=reshape](args = (%shift_y_8, -1), kwargs = {})\n",
            "    %shifts_4 : [num_users=1] = call_function[target=torch.stack](args = ((%shift_x_9, %shift_y_9, %shift_x_9, %shift_y_9),), kwargs = {dim: 1})\n",
            "    %view_8 : [num_users=1] = call_method[target=view](args = (%shifts_4, -1, 1, 4), kwargs = {})\n",
            "    %view_9 : [num_users=1] = call_method[target=view](args = (%base_anchors_4, 1, -1, 4), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%view_8, %view_9), kwargs = {})\n",
            "    %anchors_per_feature_map_4 : [num_users=1] = call_method[target=reshape](args = (%add_4, -1, 4), kwargs = {})\n",
            "    %b : [num_users=2] = call_function[target=torch.cat](args = ([%anchors_per_feature_map, %anchors_per_feature_map_1, %anchors_per_feature_map_2, %anchors_per_feature_map_3, %anchors_per_feature_map_4],), kwargs = {})\n",
            "    %layer : [num_users=1] = call_method[target=view](args = (%box_cls_per_level, 1, -1, 1, 200, 200), kwargs = {})\n",
            "    %layer_1 : [num_users=1] = call_method[target=permute](args = (%layer, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_1 : [num_users=1] = call_method[target=reshape](args = (%layer_1, 1, -1, 1), kwargs = {})\n",
            "    %layer_3 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level, 1, -1, 4, 200, 200), kwargs = {})\n",
            "    %layer_4 : [num_users=1] = call_method[target=permute](args = (%layer_3, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_1 : [num_users=1] = call_method[target=reshape](args = (%layer_4, 1, -1, 4), kwargs = {})\n",
            "    %layer_6 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_2, 1, -1, 1, 100, 100), kwargs = {})\n",
            "    %layer_7 : [num_users=1] = call_method[target=permute](args = (%layer_6, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_3 : [num_users=1] = call_method[target=reshape](args = (%layer_7, 1, -1, 1), kwargs = {})\n",
            "    %layer_9 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_2, 1, -1, 4, 100, 100), kwargs = {})\n",
            "    %layer_10 : [num_users=1] = call_method[target=permute](args = (%layer_9, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_3 : [num_users=1] = call_method[target=reshape](args = (%layer_10, 1, -1, 4), kwargs = {})\n",
            "    %layer_12 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_4, 1, -1, 1, 50, 50), kwargs = {})\n",
            "    %layer_13 : [num_users=1] = call_method[target=permute](args = (%layer_12, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_5 : [num_users=1] = call_method[target=reshape](args = (%layer_13, 1, -1, 1), kwargs = {})\n",
            "    %layer_15 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_4, 1, -1, 4, 50, 50), kwargs = {})\n",
            "    %layer_16 : [num_users=1] = call_method[target=permute](args = (%layer_15, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_5 : [num_users=1] = call_method[target=reshape](args = (%layer_16, 1, -1, 4), kwargs = {})\n",
            "    %layer_18 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_6, 1, -1, 1, 25, 25), kwargs = {})\n",
            "    %layer_19 : [num_users=1] = call_method[target=permute](args = (%layer_18, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_7 : [num_users=1] = call_method[target=reshape](args = (%layer_19, 1, -1, 1), kwargs = {})\n",
            "    %layer_21 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_6, 1, -1, 4, 25, 25), kwargs = {})\n",
            "    %layer_22 : [num_users=1] = call_method[target=permute](args = (%layer_21, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_7 : [num_users=1] = call_method[target=reshape](args = (%layer_22, 1, -1, 4), kwargs = {})\n",
            "    %layer_24 : [num_users=1] = call_method[target=view](args = (%box_cls_per_level_8, 1, -1, 1, 13, 13), kwargs = {})\n",
            "    %layer_25 : [num_users=1] = call_method[target=permute](args = (%layer_24, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_cls_per_level_9 : [num_users=1] = call_method[target=reshape](args = (%layer_25, 1, -1, 1), kwargs = {})\n",
            "    %layer_27 : [num_users=1] = call_method[target=view](args = (%box_regression_per_level_8, 1, -1, 4, 13, 13), kwargs = {})\n",
            "    %layer_28 : [num_users=1] = call_method[target=permute](args = (%layer_27, 0, 3, 4, 1, 2), kwargs = {})\n",
            "    %box_regression_per_level_9 : [num_users=1] = call_method[target=reshape](args = (%layer_28, 1, -1, 4), kwargs = {})\n",
            "    %cat_1 : [num_users=1] = call_function[target=torch.cat](args = ([%box_cls_per_level_1, %box_cls_per_level_3, %box_cls_per_level_5, %box_cls_per_level_7, %box_cls_per_level_9],), kwargs = {dim: 1})\n",
            "    %objectness : [num_users=1] = call_method[target=flatten](args = (%cat_1, 0, -2), kwargs = {})\n",
            "    %cat_2 : [num_users=1] = call_function[target=torch.cat](args = ([%box_regression_per_level_1, %box_regression_per_level_3, %box_regression_per_level_5, %box_regression_per_level_7, %box_regression_per_level_9],), kwargs = {dim: 1})\n",
            "    %pred_bbox_deltas : [num_users=2] = call_method[target=reshape](args = (%cat_2, -1, 4), kwargs = {})\n",
            "    %concat_boxes : [num_users=1] = call_function[target=torch.cat](args = ([%b],), kwargs = {dim: 0})\n",
            "    %rel_codes : [num_users=4] = call_method[target=reshape](args = (%pred_bbox_deltas, 159882, -1), kwargs = {})\n",
            "    %boxes : [num_users=6] = call_method[target=to](args = (%concat_boxes, torch.float32), kwargs = {})\n",
            "    %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 2)), kwargs = {})\n",
            "    %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 0)), kwargs = {})\n",
            "    %widths : [num_users=3] = call_function[target=operator.sub](args = (%getitem_15, %getitem_16), kwargs = {})\n",
            "    %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 3)), kwargs = {})\n",
            "    %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 1)), kwargs = {})\n",
            "    %heights : [num_users=3] = call_function[target=operator.sub](args = (%getitem_17, %getitem_18), kwargs = {})\n",
            "    %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 0)), kwargs = {})\n",
            "    %mul_10 : [num_users=1] = call_function[target=operator.mul](args = (0.5, %widths), kwargs = {})\n",
            "    %ctr_x : [num_users=1] = call_function[target=operator.add](args = (%getitem_19, %mul_10), kwargs = {})\n",
            "    %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%boxes, (slice(None, None, None), 1)), kwargs = {})\n",
            "    %mul_11 : [num_users=1] = call_function[target=operator.mul](args = (0.5, %heights), kwargs = {})\n",
            "    %ctr_y : [num_users=1] = call_function[target=operator.add](args = (%getitem_20, %mul_11), kwargs = {})\n",
            "    %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(0, None, 4))), kwargs = {})\n",
            "    %dx : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_21, 1.0), kwargs = {})\n",
            "    %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(1, None, 4))), kwargs = {})\n",
            "    %dy : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_22, 1.0), kwargs = {})\n",
            "    %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(2, None, 4))), kwargs = {})\n",
            "    %dw : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_23, 1.0), kwargs = {})\n",
            "    %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%rel_codes, (slice(None, None, None), slice(3, None, 4))), kwargs = {})\n",
            "    %dh : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_24, 1.0), kwargs = {})\n",
            "    %dw_1 : [num_users=1] = call_function[target=torch.clamp](args = (%dw,), kwargs = {max: 4.135166556742356})\n",
            "    %dh_1 : [num_users=1] = call_function[target=torch.clamp](args = (%dh,), kwargs = {max: 4.135166556742356})\n",
            "    %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%widths, (slice(None, None, None), None)), kwargs = {})\n",
            "    %mul_12 : [num_users=1] = call_function[target=operator.mul](args = (%dx, %getitem_25), kwargs = {})\n",
            "    %getitem_26 : [num_users=1] = call_function[target=operator.getitem](args = (%ctr_x, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_ctr_x : [num_users=2] = call_function[target=operator.add](args = (%mul_12, %getitem_26), kwargs = {})\n",
            "    %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%heights, (slice(None, None, None), None)), kwargs = {})\n",
            "    %mul_13 : [num_users=1] = call_function[target=operator.mul](args = (%dy, %getitem_27), kwargs = {})\n",
            "    %getitem_28 : [num_users=1] = call_function[target=operator.getitem](args = (%ctr_y, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_ctr_y : [num_users=2] = call_function[target=operator.add](args = (%mul_13, %getitem_28), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.exp](args = (%dw_1,), kwargs = {})\n",
            "    %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%widths, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_w : [num_users=1] = call_function[target=operator.mul](args = (%exp, %getitem_29), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.exp](args = (%dh_1,), kwargs = {})\n",
            "    %getitem_30 : [num_users=1] = call_function[target=operator.getitem](args = (%heights, (slice(None, None, None), None)), kwargs = {})\n",
            "    %pred_h : [num_users=1] = call_function[target=operator.mul](args = (%exp_1, %getitem_30), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (0.5,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %c_to_c_h : [num_users=2] = call_function[target=operator.mul](args = (%tensor, %pred_h), kwargs = {})\n",
            "    %tensor_1 : [num_users=1] = call_function[target=torch.tensor](args = (0.5,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %c_to_c_w : [num_users=2] = call_function[target=operator.mul](args = (%tensor_1, %pred_w), kwargs = {})\n",
            "    %pred_boxes1 : [num_users=1] = call_function[target=operator.sub](args = (%pred_ctr_x, %c_to_c_w), kwargs = {})\n",
            "    %pred_boxes2 : [num_users=1] = call_function[target=operator.sub](args = (%pred_ctr_y, %c_to_c_h), kwargs = {})\n",
            "    %pred_boxes3 : [num_users=1] = call_function[target=operator.add](args = (%pred_ctr_x, %c_to_c_w), kwargs = {})\n",
            "    %pred_boxes4 : [num_users=1] = call_function[target=operator.add](args = (%pred_ctr_y, %c_to_c_h), kwargs = {})\n",
            "    %stack_5 : [num_users=1] = call_function[target=torch.stack](args = ((%pred_boxes1, %pred_boxes2, %pred_boxes3, %pred_boxes4),), kwargs = {dim: 2})\n",
            "    %pred_boxes : [num_users=1] = call_method[target=flatten](args = (%stack_5, 1), kwargs = {})\n",
            "    %proposals : [num_users=1] = call_method[target=reshape](args = (%pred_boxes, 159882, -1, 4), kwargs = {})\n",
            "    %proposals_1 : [num_users=1] = call_method[target=view](args = (%proposals, 1, -1, 4), kwargs = {})\n",
            "    return (proposals_1, objectness, pred_bbox_deltas, b, base_anchors, base_anchors_1, base_anchors_2, base_anchors_3, base_anchors_4)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg4_1,), kwargs = {})\n",
            "    %clone_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg3_1,), kwargs = {})\n",
            "    %clone_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg2_1,), kwargs = {})\n",
            "    %clone_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg1_1,), kwargs = {})\n",
            "    %clone_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%clone_4, %_param_constant0, %_param_constant1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %_param_constant2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant2, %_param_constant3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant4, %_param_constant5, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_1 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%clone_3, %_param_constant0_1, %_param_constant1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %_param_constant2_1 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_1 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant2_1, %_param_constant3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_1 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_1 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant4_1, %_param_constant5_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_2 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_2 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%clone_2, %_param_constant0_2, %_param_constant1_2, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})\n",
            "    %_param_constant2_2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_2 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant2_2, %_param_constant3_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_2 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_2 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant4_2, %_param_constant5_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_3 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_3 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%clone_1, %_param_constant0_3, %_param_constant1_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})\n",
            "    %_param_constant2_3 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant2_3, %_param_constant3_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_3 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_3 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant4_3, %_param_constant5_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_4 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_4 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%clone, %_param_constant0_4, %_param_constant1_4, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})\n",
            "    %_param_constant2_4 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_4 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_13 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant2_4, %_param_constant3_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_4 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant4_4, %_param_constant5_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %empty : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty, 4), kwargs = {pin_memory: False})\n",
            "    %empty_1 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_1 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_1, 4), kwargs = {pin_memory: False})\n",
            "    %empty_2 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_2 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_2, 8), kwargs = {pin_memory: False})\n",
            "    %empty_3 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_3 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_3, 8), kwargs = {pin_memory: False})\n",
            "    %empty_4 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_4 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_4, 16), kwargs = {pin_memory: False})\n",
            "    %empty_5 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_5 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_5, 16), kwargs = {pin_memory: False})\n",
            "    %empty_6 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_6 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_6, 32), kwargs = {pin_memory: False})\n",
            "    %empty_7 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_7 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_7, 32), kwargs = {pin_memory: False})\n",
            "    %empty_8 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_8 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_8, 61), kwargs = {pin_memory: False})\n",
            "    %empty_9 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_9 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_9, 61), kwargs = {pin_memory: False})\n",
            "    %arange : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 200), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange, %full_like_1), kwargs = {})\n",
            "    %arange_1 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 200), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_1, %full_like), kwargs = {})\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_1, [-1, 1]), kwargs = {})\n",
            "    %expand : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view, [200, 200]), kwargs = {})\n",
            "    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul, [1, -1]), kwargs = {})\n",
            "    %expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_1, [200, 200]), kwargs = {})\n",
            "    %clone_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_1,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_2 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_5, [40000]), kwargs = {})\n",
            "    %clone_6 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_3 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_6, [40000]), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_2, 1), kwargs = {})\n",
            "    %unsqueeze_1 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_3, 1), kwargs = {})\n",
            "    %unsqueeze_2 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_2, 1), kwargs = {})\n",
            "    %unsqueeze_3 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_3, 1), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze, %unsqueeze_1, %unsqueeze_2, %unsqueeze_3], 1), kwargs = {})\n",
            "    %view_4 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant6 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %view_5 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant6, [1, -1, 4]), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_4, %view_5), kwargs = {})\n",
            "    %view_6 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add, [-1, 4]), kwargs = {})\n",
            "    %arange_2 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 100), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_2, %full_like_3), kwargs = {})\n",
            "    %arange_3 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 100), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_3, %full_like_2), kwargs = {})\n",
            "    %view_7 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_3, [-1, 1]), kwargs = {})\n",
            "    %expand_2 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_7, [100, 100]), kwargs = {})\n",
            "    %view_8 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_2, [1, -1]), kwargs = {})\n",
            "    %expand_3 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_8, [100, 100]), kwargs = {})\n",
            "    %clone_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_3,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_9 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_7, [10000]), kwargs = {})\n",
            "    %clone_8 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_2,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_10 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_8, [10000]), kwargs = {})\n",
            "    %unsqueeze_4 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_9, 1), kwargs = {})\n",
            "    %unsqueeze_5 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_10, 1), kwargs = {})\n",
            "    %unsqueeze_6 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_9, 1), kwargs = {})\n",
            "    %unsqueeze_7 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_10, 1), kwargs = {})\n",
            "    %cat_1 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_4, %unsqueeze_5, %unsqueeze_6, %unsqueeze_7], 1), kwargs = {})\n",
            "    %view_11 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_1, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant7 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %view_12 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant7, [1, -1, 4]), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_11, %view_12), kwargs = {})\n",
            "    %view_13 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_1, [-1, 4]), kwargs = {})\n",
            "    %arange_4 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 50), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_4, %full_like_5), kwargs = {})\n",
            "    %arange_5 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 50), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_5 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_5, %full_like_4), kwargs = {})\n",
            "    %view_14 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_5, [-1, 1]), kwargs = {})\n",
            "    %expand_4 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_14, [50, 50]), kwargs = {})\n",
            "    %view_15 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_4, [1, -1]), kwargs = {})\n",
            "    %expand_5 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_15, [50, 50]), kwargs = {})\n",
            "    %clone_9 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_5,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_16 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_9, [2500]), kwargs = {})\n",
            "    %clone_10 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_4,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_17 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_10, [2500]), kwargs = {})\n",
            "    %unsqueeze_8 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_16, 1), kwargs = {})\n",
            "    %unsqueeze_9 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_17, 1), kwargs = {})\n",
            "    %unsqueeze_10 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_16, 1), kwargs = {})\n",
            "    %unsqueeze_11 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_17, 1), kwargs = {})\n",
            "    %cat_2 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_8, %unsqueeze_9, %unsqueeze_10, %unsqueeze_11], 1), kwargs = {})\n",
            "    %view_18 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_2, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant8 : [num_users=1] = get_attr[target=_param_constant8]\n",
            "    %view_19 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant8, [1, -1, 4]), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_18, %view_19), kwargs = {})\n",
            "    %view_20 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_2, [-1, 4]), kwargs = {})\n",
            "    %arange_6 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 25), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_6 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_6, %full_like_7), kwargs = {})\n",
            "    %arange_7 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 25), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_7 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_7, %full_like_6), kwargs = {})\n",
            "    %view_21 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_7, [-1, 1]), kwargs = {})\n",
            "    %expand_6 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_21, [25, 25]), kwargs = {})\n",
            "    %view_22 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_6, [1, -1]), kwargs = {})\n",
            "    %expand_7 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_22, [25, 25]), kwargs = {})\n",
            "    %clone_11 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_7,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_23 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_11, [625]), kwargs = {})\n",
            "    %clone_12 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_6,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_24 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_12, [625]), kwargs = {})\n",
            "    %unsqueeze_12 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_23, 1), kwargs = {})\n",
            "    %unsqueeze_13 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_24, 1), kwargs = {})\n",
            "    %unsqueeze_14 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_23, 1), kwargs = {})\n",
            "    %unsqueeze_15 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_24, 1), kwargs = {})\n",
            "    %cat_3 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_12, %unsqueeze_13, %unsqueeze_14, %unsqueeze_15], 1), kwargs = {})\n",
            "    %view_25 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_3, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant9 : [num_users=1] = get_attr[target=_param_constant9]\n",
            "    %view_26 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant9, [1, -1, 4]), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_25, %view_26), kwargs = {})\n",
            "    %view_27 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_3, [-1, 4]), kwargs = {})\n",
            "    %arange_8 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 13), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_8 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_8, %full_like_9), kwargs = {})\n",
            "    %arange_9 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 13), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_9 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_9, %full_like_8), kwargs = {})\n",
            "    %view_28 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_9, [-1, 1]), kwargs = {})\n",
            "    %expand_8 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_28, [13, 13]), kwargs = {})\n",
            "    %view_29 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_8, [1, -1]), kwargs = {})\n",
            "    %expand_9 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_29, [13, 13]), kwargs = {})\n",
            "    %clone_13 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_9,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_30 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_13, [169]), kwargs = {})\n",
            "    %clone_14 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_8,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_31 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_14, [169]), kwargs = {})\n",
            "    %unsqueeze_16 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_30, 1), kwargs = {})\n",
            "    %unsqueeze_17 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_31, 1), kwargs = {})\n",
            "    %unsqueeze_18 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_30, 1), kwargs = {})\n",
            "    %unsqueeze_19 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_31, 1), kwargs = {})\n",
            "    %cat_4 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_16, %unsqueeze_17, %unsqueeze_18, %unsqueeze_19], 1), kwargs = {})\n",
            "    %view_32 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_4, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant10 : [num_users=1] = get_attr[target=_param_constant10]\n",
            "    %view_33 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant10, [1, -1, 4]), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_32, %view_33), kwargs = {})\n",
            "    %view_34 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_4, [-1, 4]), kwargs = {})\n",
            "    %cat_5 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%view_6, %view_13, %view_20, %view_27, %view_34],), kwargs = {})\n",
            "    %view_35 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_1, [1, -1, 1, 200, 200]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_35, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_36 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_15, [1, 120000, 1]), kwargs = {})\n",
            "    %view_37 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_2, [1, -1, 4, 200, 200]), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_37, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_1,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_38 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_16, [1, 120000, 4]), kwargs = {})\n",
            "    %view_39 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_4, [1, -1, 1, 100, 100]), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_39, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_2,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_40 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_17, [1, 30000, 1]), kwargs = {})\n",
            "    %view_41 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_5, [1, -1, 4, 100, 100]), kwargs = {})\n",
            "    %permute_3 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_41, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_3,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_42 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_18, [1, 30000, 4]), kwargs = {})\n",
            "    %view_43 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_7, [1, -1, 1, 50, 50]), kwargs = {})\n",
            "    %permute_4 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_43, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_19 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_4,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_44 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_19, [1, 7500, 1]), kwargs = {})\n",
            "    %view_45 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_8, [1, -1, 4, 50, 50]), kwargs = {})\n",
            "    %permute_5 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_45, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_20 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_5,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_46 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_20, [1, 7500, 4]), kwargs = {})\n",
            "    %view_47 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_10, [1, -1, 1, 25, 25]), kwargs = {})\n",
            "    %permute_6 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_47, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_21 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_6,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_48 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_21, [1, 1875, 1]), kwargs = {})\n",
            "    %view_49 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_11, [1, -1, 4, 25, 25]), kwargs = {})\n",
            "    %permute_7 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_49, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_22 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_7,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_50 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_22, [1, 1875, 4]), kwargs = {})\n",
            "    %view_51 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_13, [1, -1, 1, 13, 13]), kwargs = {})\n",
            "    %permute_8 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_51, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_8,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_52 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_23, [1, 507, 1]), kwargs = {})\n",
            "    %view_53 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_14, [1, -1, 4, 13, 13]), kwargs = {})\n",
            "    %permute_9 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_53, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_24 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_9,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_54 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_24, [1, 507, 4]), kwargs = {})\n",
            "    %cat_6 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_36, %view_40, %view_44, %view_48, %view_52], 1), kwargs = {})\n",
            "    %view_55 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_6, [159882, 1]), kwargs = {})\n",
            "    %cat_7 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_38, %view_42, %view_46, %view_50, %view_54], 1), kwargs = {})\n",
            "    %view_56 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%cat_7, [-1, 4]), kwargs = {})\n",
            "    %cat_8 : [num_users=6] = call_function[target=torch.ops.aten.cat.default](args = ([%cat_5],), kwargs = {})\n",
            "    %view_57 : [num_users=4] = call_function[target=torch.ops.aten.view.default](args = (%view_56, [159882, -1]), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_1, 1, 2), kwargs = {})\n",
            "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_1 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_2, 1, 0), kwargs = {})\n",
            "    %sub : [num_users=3] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select, %select_1), kwargs = {})\n",
            "    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_2 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_3, 1, 3), kwargs = {})\n",
            "    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_3 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_4, 1, 1), kwargs = {})\n",
            "    %sub_1 : [num_users=3] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select_2, %select_3), kwargs = {})\n",
            "    %slice_5 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_4 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_5, 1, 0), kwargs = {})\n",
            "    %mul_10 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, 0.5), kwargs = {})\n",
            "    %add_5 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_4, %mul_10), kwargs = {})\n",
            "    %slice_6 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_5 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_6, 1, 1), kwargs = {})\n",
            "    %mul_11 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1, 0.5), kwargs = {})\n",
            "    %add_6 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_5, %mul_11), kwargs = {})\n",
            "    %slice_7 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 1, 0, 9223372036854775807, 4), kwargs = {})\n",
            "    %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_8, 1.0), kwargs = {})\n",
            "    %slice_9 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_10 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_9, 1, 1, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_10, 1.0), kwargs = {})\n",
            "    %slice_11 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_12 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_11, 1, 2, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_12, 1.0), kwargs = {})\n",
            "    %slice_13 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_14 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_13, 1, 3, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_14, 1.0), kwargs = {})\n",
            "    %clamp : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_2, None, 4.135166556742356), kwargs = {})\n",
            "    %clamp_1 : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_3, None, 4.135166556742356), kwargs = {})\n",
            "    %slice_15 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_20 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_15, 1), kwargs = {})\n",
            "    %mul_12 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div, %unsqueeze_20), kwargs = {})\n",
            "    %slice_16 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%add_5, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_21 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_16, 1), kwargs = {})\n",
            "    %add_7 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_12, %unsqueeze_21), kwargs = {})\n",
            "    %slice_17 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub_1, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_22 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_17, 1), kwargs = {})\n",
            "    %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %unsqueeze_22), kwargs = {})\n",
            "    %slice_18 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%add_6, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_23 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_18, 1), kwargs = {})\n",
            "    %add_8 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_13, %unsqueeze_23), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp,), kwargs = {})\n",
            "    %slice_19 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_24 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_19, 1), kwargs = {})\n",
            "    %mul_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp, %unsqueeze_24), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp_1,), kwargs = {})\n",
            "    %slice_20 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub_1, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_25 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_20, 1), kwargs = {})\n",
            "    %mul_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp_1, %unsqueeze_25), kwargs = {})\n",
            "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
            "    %lift_fresh_copy : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant0,), kwargs = {})\n",
            "    %mul_16 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%lift_fresh_copy, %mul_15), kwargs = {})\n",
            "    %_tensor_constant1 : [num_users=1] = get_attr[target=_tensor_constant1]\n",
            "    %lift_fresh_copy_1 : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant1,), kwargs = {})\n",
            "    %mul_17 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%lift_fresh_copy_1, %mul_14), kwargs = {})\n",
            "    %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %add_10 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %unsqueeze_26 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_2, 2), kwargs = {})\n",
            "    %unsqueeze_27 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_3, 2), kwargs = {})\n",
            "    %unsqueeze_28 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_9, 2), kwargs = {})\n",
            "    %unsqueeze_29 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_10, 2), kwargs = {})\n",
            "    %cat_9 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_26, %unsqueeze_27, %unsqueeze_28, %unsqueeze_29], 2), kwargs = {})\n",
            "    %view_58 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_9, [159882, 4]), kwargs = {})\n",
            "    %view_59 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_58, [159882, -1, 4]), kwargs = {})\n",
            "    %view_60 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_59, [1, -1, 4]), kwargs = {})\n",
            "    %_param_constant6_1 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %_param_constant7_1 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %_param_constant8_1 : [num_users=1] = get_attr[target=_param_constant8]\n",
            "    %_param_constant9_1 : [num_users=1] = get_attr[target=_param_constant9]\n",
            "    %_param_constant10_1 : [num_users=1] = get_attr[target=_param_constant10]\n",
            "    return (view_60, view_55, view_56, cat_5, _param_constant6_1, _param_constant7_1, _param_constant8_1, _param_constant9_1, _param_constant10_1)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_4 from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_3 from graph, since it is a clone node which is the only user of placeholder arg1_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_2 from graph, since it is a clone node which is the only user of placeholder arg2_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_1 from graph, since it is a clone node which is the only user of placeholder arg3_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg4_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg0_1, %_param_constant0, %_param_constant1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %_param_constant2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant2, %_param_constant3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant4, %_param_constant5, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_1 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg1_1, %_param_constant0_1, %_param_constant1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %_param_constant2_1 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_1 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant2_1, %_param_constant3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_1 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_1 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant4_1, %_param_constant5_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_2 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_2 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %_param_constant0_2, %_param_constant1_2, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})\n",
            "    %_param_constant2_2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_2 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant2_2, %_param_constant3_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_2 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_2 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant4_2, %_param_constant5_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_3 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_3 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg3_1, %_param_constant0_3, %_param_constant1_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})\n",
            "    %_param_constant2_3 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant2_3, %_param_constant3_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_3 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_3 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant4_3, %_param_constant5_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_4 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_4 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg4_1, %_param_constant0_4, %_param_constant1_4, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})\n",
            "    %_param_constant2_4 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_4 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_13 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant2_4, %_param_constant3_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_4 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant4_4, %_param_constant5_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %empty : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty, 4), kwargs = {pin_memory: False})\n",
            "    %empty_1 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_1 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_1, 4), kwargs = {pin_memory: False})\n",
            "    %empty_2 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_2 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_2, 8), kwargs = {pin_memory: False})\n",
            "    %empty_3 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_3 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_3, 8), kwargs = {pin_memory: False})\n",
            "    %empty_4 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_4 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_4, 16), kwargs = {pin_memory: False})\n",
            "    %empty_5 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_5 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_5, 16), kwargs = {pin_memory: False})\n",
            "    %empty_6 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_6 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_6, 32), kwargs = {pin_memory: False})\n",
            "    %empty_7 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_7 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_7, 32), kwargs = {pin_memory: False})\n",
            "    %empty_8 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_8 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_8, 61), kwargs = {pin_memory: False})\n",
            "    %empty_9 : [num_users=1] = call_function[target=torch.ops.aten.empty.memory_format](args = ([],), kwargs = {dtype: torch.int64, device: cuda:0, pin_memory: False})\n",
            "    %full_like_9 : [num_users=1] = call_function[target=torch.ops.aten.full_like.default](args = (%empty_9, 61), kwargs = {pin_memory: False})\n",
            "    %arange : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 200), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange, %full_like_1), kwargs = {})\n",
            "    %arange_1 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 200), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_1, %full_like), kwargs = {})\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_1, [-1, 1]), kwargs = {})\n",
            "    %expand : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view, [200, 200]), kwargs = {})\n",
            "    %view_1 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul, [1, -1]), kwargs = {})\n",
            "    %expand_1 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_1, [200, 200]), kwargs = {})\n",
            "    %clone_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_1,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_2 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_5, [40000]), kwargs = {})\n",
            "    %clone_6 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_3 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_6, [40000]), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_2, 1), kwargs = {})\n",
            "    %unsqueeze_1 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_3, 1), kwargs = {})\n",
            "    %unsqueeze_2 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_2, 1), kwargs = {})\n",
            "    %unsqueeze_3 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_3, 1), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze, %unsqueeze_1, %unsqueeze_2, %unsqueeze_3], 1), kwargs = {})\n",
            "    %view_4 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant6 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %view_5 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant6, [1, -1, 4]), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_4, %view_5), kwargs = {})\n",
            "    %view_6 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add, [-1, 4]), kwargs = {})\n",
            "    %arange_2 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 100), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_2, %full_like_3), kwargs = {})\n",
            "    %arange_3 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 100), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_3, %full_like_2), kwargs = {})\n",
            "    %view_7 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_3, [-1, 1]), kwargs = {})\n",
            "    %expand_2 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_7, [100, 100]), kwargs = {})\n",
            "    %view_8 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_2, [1, -1]), kwargs = {})\n",
            "    %expand_3 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_8, [100, 100]), kwargs = {})\n",
            "    %clone_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_3,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_9 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_7, [10000]), kwargs = {})\n",
            "    %clone_8 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_2,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_10 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_8, [10000]), kwargs = {})\n",
            "    %unsqueeze_4 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_9, 1), kwargs = {})\n",
            "    %unsqueeze_5 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_10, 1), kwargs = {})\n",
            "    %unsqueeze_6 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_9, 1), kwargs = {})\n",
            "    %unsqueeze_7 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_10, 1), kwargs = {})\n",
            "    %cat_1 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_4, %unsqueeze_5, %unsqueeze_6, %unsqueeze_7], 1), kwargs = {})\n",
            "    %view_11 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_1, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant7 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %view_12 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant7, [1, -1, 4]), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_11, %view_12), kwargs = {})\n",
            "    %view_13 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_1, [-1, 4]), kwargs = {})\n",
            "    %arange_4 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 50), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_4, %full_like_5), kwargs = {})\n",
            "    %arange_5 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 50), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_5 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_5, %full_like_4), kwargs = {})\n",
            "    %view_14 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_5, [-1, 1]), kwargs = {})\n",
            "    %expand_4 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_14, [50, 50]), kwargs = {})\n",
            "    %view_15 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_4, [1, -1]), kwargs = {})\n",
            "    %expand_5 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_15, [50, 50]), kwargs = {})\n",
            "    %clone_9 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_5,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_16 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_9, [2500]), kwargs = {})\n",
            "    %clone_10 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_4,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_17 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_10, [2500]), kwargs = {})\n",
            "    %unsqueeze_8 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_16, 1), kwargs = {})\n",
            "    %unsqueeze_9 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_17, 1), kwargs = {})\n",
            "    %unsqueeze_10 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_16, 1), kwargs = {})\n",
            "    %unsqueeze_11 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_17, 1), kwargs = {})\n",
            "    %cat_2 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_8, %unsqueeze_9, %unsqueeze_10, %unsqueeze_11], 1), kwargs = {})\n",
            "    %view_18 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_2, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant8 : [num_users=1] = get_attr[target=_param_constant8]\n",
            "    %view_19 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant8, [1, -1, 4]), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_18, %view_19), kwargs = {})\n",
            "    %view_20 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_2, [-1, 4]), kwargs = {})\n",
            "    %arange_6 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 25), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_6 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_6, %full_like_7), kwargs = {})\n",
            "    %arange_7 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 25), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_7 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_7, %full_like_6), kwargs = {})\n",
            "    %view_21 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_7, [-1, 1]), kwargs = {})\n",
            "    %expand_6 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_21, [25, 25]), kwargs = {})\n",
            "    %view_22 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_6, [1, -1]), kwargs = {})\n",
            "    %expand_7 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_22, [25, 25]), kwargs = {})\n",
            "    %clone_11 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_7,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_23 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_11, [625]), kwargs = {})\n",
            "    %clone_12 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_6,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_24 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_12, [625]), kwargs = {})\n",
            "    %unsqueeze_12 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_23, 1), kwargs = {})\n",
            "    %unsqueeze_13 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_24, 1), kwargs = {})\n",
            "    %unsqueeze_14 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_23, 1), kwargs = {})\n",
            "    %unsqueeze_15 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_24, 1), kwargs = {})\n",
            "    %cat_3 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_12, %unsqueeze_13, %unsqueeze_14, %unsqueeze_15], 1), kwargs = {})\n",
            "    %view_25 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_3, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant9 : [num_users=1] = get_attr[target=_param_constant9]\n",
            "    %view_26 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant9, [1, -1, 4]), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_25, %view_26), kwargs = {})\n",
            "    %view_27 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_3, [-1, 4]), kwargs = {})\n",
            "    %arange_8 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 13), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_8 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_8, %full_like_9), kwargs = {})\n",
            "    %arange_9 : [num_users=1] = call_function[target=torch.ops.aten.arange.start_step](args = (0, 13), kwargs = {dtype: torch.int32, layout: torch.strided, device: cuda:0, pin_memory: False})\n",
            "    %mul_9 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%arange_9, %full_like_8), kwargs = {})\n",
            "    %view_28 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_9, [-1, 1]), kwargs = {})\n",
            "    %expand_8 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_28, [13, 13]), kwargs = {})\n",
            "    %view_29 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%mul_8, [1, -1]), kwargs = {})\n",
            "    %expand_9 : [num_users=1] = call_function[target=torch.ops.aten.expand.default](args = (%view_29, [13, 13]), kwargs = {})\n",
            "    %clone_13 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_9,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_30 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_13, [169]), kwargs = {})\n",
            "    %clone_14 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%expand_8,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_31 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%clone_14, [169]), kwargs = {})\n",
            "    %unsqueeze_16 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_30, 1), kwargs = {})\n",
            "    %unsqueeze_17 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_31, 1), kwargs = {})\n",
            "    %unsqueeze_18 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_30, 1), kwargs = {})\n",
            "    %unsqueeze_19 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%view_31, 1), kwargs = {})\n",
            "    %cat_4 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_16, %unsqueeze_17, %unsqueeze_18, %unsqueeze_19], 1), kwargs = {})\n",
            "    %view_32 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_4, [-1, 1, 4]), kwargs = {})\n",
            "    %_param_constant10 : [num_users=1] = get_attr[target=_param_constant10]\n",
            "    %view_33 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%_param_constant10, [1, -1, 4]), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%view_32, %view_33), kwargs = {})\n",
            "    %view_34 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%add_4, [-1, 4]), kwargs = {})\n",
            "    %cat_5 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%view_6, %view_13, %view_20, %view_27, %view_34],), kwargs = {})\n",
            "    %view_35 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_1, [1, -1, 1, 200, 200]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_35, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_36 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_15, [1, 120000, 1]), kwargs = {})\n",
            "    %view_37 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_2, [1, -1, 4, 200, 200]), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_37, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_1,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_38 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_16, [1, 120000, 4]), kwargs = {})\n",
            "    %view_39 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_4, [1, -1, 1, 100, 100]), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_39, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_2,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_40 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_17, [1, 30000, 1]), kwargs = {})\n",
            "    %view_41 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_5, [1, -1, 4, 100, 100]), kwargs = {})\n",
            "    %permute_3 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_41, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_3,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_42 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_18, [1, 30000, 4]), kwargs = {})\n",
            "    %view_43 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_7, [1, -1, 1, 50, 50]), kwargs = {})\n",
            "    %permute_4 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_43, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_19 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_4,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_44 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_19, [1, 7500, 1]), kwargs = {})\n",
            "    %view_45 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_8, [1, -1, 4, 50, 50]), kwargs = {})\n",
            "    %permute_5 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_45, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_20 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_5,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_46 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_20, [1, 7500, 4]), kwargs = {})\n",
            "    %view_47 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_10, [1, -1, 1, 25, 25]), kwargs = {})\n",
            "    %permute_6 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_47, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_21 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_6,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_48 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_21, [1, 1875, 1]), kwargs = {})\n",
            "    %view_49 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_11, [1, -1, 4, 25, 25]), kwargs = {})\n",
            "    %permute_7 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_49, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_22 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_7,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_50 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_22, [1, 1875, 4]), kwargs = {})\n",
            "    %view_51 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_13, [1, -1, 1, 13, 13]), kwargs = {})\n",
            "    %permute_8 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_51, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_8,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_52 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_23, [1, 507, 1]), kwargs = {})\n",
            "    %view_53 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_14, [1, -1, 4, 13, 13]), kwargs = {})\n",
            "    %permute_9 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_53, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_24 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_9,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_54 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_24, [1, 507, 4]), kwargs = {})\n",
            "    %cat_6 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_36, %view_40, %view_44, %view_48, %view_52], 1), kwargs = {})\n",
            "    %view_55 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_6, [159882, 1]), kwargs = {})\n",
            "    %cat_7 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_38, %view_42, %view_46, %view_50, %view_54], 1), kwargs = {})\n",
            "    %view_56 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%cat_7, [-1, 4]), kwargs = {})\n",
            "    %cat_8 : [num_users=6] = call_function[target=torch.ops.aten.cat.default](args = ([%cat_5],), kwargs = {})\n",
            "    %view_57 : [num_users=4] = call_function[target=torch.ops.aten.view.default](args = (%view_56, [159882, -1]), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_1, 1, 2), kwargs = {})\n",
            "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_1 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_2, 1, 0), kwargs = {})\n",
            "    %sub : [num_users=3] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select, %select_1), kwargs = {})\n",
            "    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_2 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_3, 1, 3), kwargs = {})\n",
            "    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_3 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_4, 1, 1), kwargs = {})\n",
            "    %sub_1 : [num_users=3] = call_function[target=torch.ops.aten.sub.Tensor](args = (%select_2, %select_3), kwargs = {})\n",
            "    %slice_5 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_4 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_5, 1, 0), kwargs = {})\n",
            "    %mul_10 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, 0.5), kwargs = {})\n",
            "    %add_5 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_4, %mul_10), kwargs = {})\n",
            "    %slice_6 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%cat_8, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %select_5 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%slice_6, 1, 1), kwargs = {})\n",
            "    %mul_11 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1, 0.5), kwargs = {})\n",
            "    %add_6 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%select_5, %mul_11), kwargs = {})\n",
            "    %slice_7 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 1, 0, 9223372036854775807, 4), kwargs = {})\n",
            "    %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_8, 1.0), kwargs = {})\n",
            "    %slice_9 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_10 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_9, 1, 1, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_10, 1.0), kwargs = {})\n",
            "    %slice_11 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_12 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_11, 1, 2, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_12, 1.0), kwargs = {})\n",
            "    %slice_13 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_14 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_13, 1, 3, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_14, 1.0), kwargs = {})\n",
            "    %clamp : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_2, None, 4.135166556742356), kwargs = {})\n",
            "    %clamp_1 : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_3, None, 4.135166556742356), kwargs = {})\n",
            "    %slice_15 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_20 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_15, 1), kwargs = {})\n",
            "    %mul_12 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div, %unsqueeze_20), kwargs = {})\n",
            "    %slice_16 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%add_5, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_21 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_16, 1), kwargs = {})\n",
            "    %add_7 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_12, %unsqueeze_21), kwargs = {})\n",
            "    %slice_17 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub_1, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_22 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_17, 1), kwargs = {})\n",
            "    %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %unsqueeze_22), kwargs = {})\n",
            "    %slice_18 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%add_6, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_23 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_18, 1), kwargs = {})\n",
            "    %add_8 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_13, %unsqueeze_23), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp,), kwargs = {})\n",
            "    %slice_19 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_24 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_19, 1), kwargs = {})\n",
            "    %mul_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp, %unsqueeze_24), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp_1,), kwargs = {})\n",
            "    %slice_20 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub_1, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze_25 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_20, 1), kwargs = {})\n",
            "    %mul_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp_1, %unsqueeze_25), kwargs = {})\n",
            "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
            "    %lift_fresh_copy : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant0,), kwargs = {})\n",
            "    %mul_16 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%lift_fresh_copy, %mul_15), kwargs = {})\n",
            "    %_tensor_constant1 : [num_users=1] = get_attr[target=_tensor_constant1]\n",
            "    %lift_fresh_copy_1 : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant1,), kwargs = {})\n",
            "    %mul_17 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%lift_fresh_copy_1, %mul_14), kwargs = {})\n",
            "    %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %add_10 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %unsqueeze_26 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_2, 2), kwargs = {})\n",
            "    %unsqueeze_27 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_3, 2), kwargs = {})\n",
            "    %unsqueeze_28 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_9, 2), kwargs = {})\n",
            "    %unsqueeze_29 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_10, 2), kwargs = {})\n",
            "    %cat_9 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_26, %unsqueeze_27, %unsqueeze_28, %unsqueeze_29], 2), kwargs = {})\n",
            "    %view_58 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_9, [159882, 4]), kwargs = {})\n",
            "    %view_59 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_58, [159882, -1, 4]), kwargs = {})\n",
            "    %view_60 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_59, [1, -1, 4]), kwargs = {})\n",
            "    %_param_constant6_1 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %_param_constant7_1 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %_param_constant8_1 : [num_users=1] = get_attr[target=_param_constant8]\n",
            "    %_param_constant9_1 : [num_users=1] = get_attr[target=_param_constant9]\n",
            "    %_param_constant10_1 : [num_users=1] = get_attr[target=_param_constant10]\n",
            "    return (view_60, view_55, view_56, cat_5, _param_constant6_1, _param_constant7_1, _param_constant8_1, _param_constant9_1, _param_constant10_1)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg0_1, %_param_constant0, %_param_constant1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %_param_constant2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant2, %_param_constant3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant4, %_param_constant5, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_1 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg1_1, %_param_constant0_1, %_param_constant1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %_param_constant2_1 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_1 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant2_1, %_param_constant3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_1 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_1 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant4_1, %_param_constant5_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_2 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_2 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %_param_constant0_2, %_param_constant1_2, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})\n",
            "    %_param_constant2_2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_2 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant2_2, %_param_constant3_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_2 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_2 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant4_2, %_param_constant5_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_3 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_3 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg3_1, %_param_constant0_3, %_param_constant1_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})\n",
            "    %_param_constant2_3 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant2_3, %_param_constant3_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_3 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_3 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant4_3, %_param_constant5_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_4 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_4 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg4_1, %_param_constant0_4, %_param_constant1_4, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})\n",
            "    %_param_constant2_4 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_4 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_13 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant2_4, %_param_constant3_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_4 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant4_4, %_param_constant5_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %view_35 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_1, [1, -1, 1, 200, 200]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_35, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_36 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_15, [1, 120000, 1]), kwargs = {})\n",
            "    %view_37 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_2, [1, -1, 4, 200, 200]), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_37, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_1,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_38 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_16, [1, 120000, 4]), kwargs = {})\n",
            "    %view_39 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_4, [1, -1, 1, 100, 100]), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_39, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_2,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_40 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_17, [1, 30000, 1]), kwargs = {})\n",
            "    %view_41 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_5, [1, -1, 4, 100, 100]), kwargs = {})\n",
            "    %permute_3 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_41, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_3,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_42 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_18, [1, 30000, 4]), kwargs = {})\n",
            "    %view_43 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_7, [1, -1, 1, 50, 50]), kwargs = {})\n",
            "    %permute_4 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_43, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_19 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_4,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_44 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_19, [1, 7500, 1]), kwargs = {})\n",
            "    %view_45 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_8, [1, -1, 4, 50, 50]), kwargs = {})\n",
            "    %permute_5 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_45, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_20 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_5,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_46 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_20, [1, 7500, 4]), kwargs = {})\n",
            "    %view_47 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_10, [1, -1, 1, 25, 25]), kwargs = {})\n",
            "    %permute_6 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_47, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_21 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_6,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_48 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_21, [1, 1875, 1]), kwargs = {})\n",
            "    %view_49 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_11, [1, -1, 4, 25, 25]), kwargs = {})\n",
            "    %permute_7 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_49, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_22 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_7,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_50 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_22, [1, 1875, 4]), kwargs = {})\n",
            "    %view_51 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_13, [1, -1, 1, 13, 13]), kwargs = {})\n",
            "    %permute_8 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_51, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_8,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_52 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_23, [1, 507, 1]), kwargs = {})\n",
            "    %view_53 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%convolution_14, [1, -1, 4, 13, 13]), kwargs = {})\n",
            "    %permute_9 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%view_53, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_24 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_9,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %view_54 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone_24, [1, 507, 4]), kwargs = {})\n",
            "    %cat_6 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_36, %view_40, %view_44, %view_48, %view_52], 1), kwargs = {})\n",
            "    %view_55 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_6, [159882, 1]), kwargs = {})\n",
            "    %cat_7 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%view_38, %view_42, %view_46, %view_50, %view_54], 1), kwargs = {})\n",
            "    %view_56 : [num_users=2] = call_function[target=torch.ops.aten.view.default](args = (%cat_7, [-1, 4]), kwargs = {})\n",
            "    %view_57 : [num_users=4] = call_function[target=torch.ops.aten.view.default](args = (%view_56, [159882, -1]), kwargs = {})\n",
            "    %slice_7 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 1, 0, 9223372036854775807, 4), kwargs = {})\n",
            "    %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_8, 1.0), kwargs = {})\n",
            "    %slice_9 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_10 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_9, 1, 1, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_10, 1.0), kwargs = {})\n",
            "    %slice_11 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_12 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_11, 1, 2, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_12, 1.0), kwargs = {})\n",
            "    %slice_13 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%view_57, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_14 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_13, 1, 3, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_14, 1.0), kwargs = {})\n",
            "    %clamp : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_2, None, 4.135166556742356), kwargs = {})\n",
            "    %clamp_1 : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_3, None, 4.135166556742356), kwargs = {})\n",
            "    %_frozen_param1 : [num_users=1] = get_attr[target=_frozen_param1]\n",
            "    %mul_12 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div, %_frozen_param1), kwargs = {})\n",
            "    %_frozen_param2 : [num_users=1] = get_attr[target=_frozen_param2]\n",
            "    %add_7 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_12, %_frozen_param2), kwargs = {})\n",
            "    %_frozen_param3 : [num_users=1] = get_attr[target=_frozen_param3]\n",
            "    %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %_frozen_param3), kwargs = {})\n",
            "    %_frozen_param4 : [num_users=1] = get_attr[target=_frozen_param4]\n",
            "    %add_8 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_13, %_frozen_param4), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp,), kwargs = {})\n",
            "    %_frozen_param5 : [num_users=1] = get_attr[target=_frozen_param5]\n",
            "    %mul_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp, %_frozen_param5), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp_1,), kwargs = {})\n",
            "    %_frozen_param6 : [num_users=1] = get_attr[target=_frozen_param6]\n",
            "    %mul_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp_1, %_frozen_param6), kwargs = {})\n",
            "    %_frozen_param7 : [num_users=1] = get_attr[target=_frozen_param7]\n",
            "    %mul_16 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_frozen_param7, %mul_15), kwargs = {})\n",
            "    %_frozen_param8 : [num_users=1] = get_attr[target=_frozen_param8]\n",
            "    %mul_17 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_frozen_param8, %mul_14), kwargs = {})\n",
            "    %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %add_10 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %unsqueeze_26 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_2, 2), kwargs = {})\n",
            "    %unsqueeze_27 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_3, 2), kwargs = {})\n",
            "    %unsqueeze_28 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_9, 2), kwargs = {})\n",
            "    %unsqueeze_29 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_10, 2), kwargs = {})\n",
            "    %cat_9 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_26, %unsqueeze_27, %unsqueeze_28, %unsqueeze_29], 2), kwargs = {})\n",
            "    %view_58 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%cat_9, [159882, 4]), kwargs = {})\n",
            "    %view_59 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_58, [159882, -1, 4]), kwargs = {})\n",
            "    %view_60 : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%view_59, [1, -1, 4]), kwargs = {})\n",
            "    %_param_constant6_1 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %_param_constant7_1 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %_param_constant8_1 : [num_users=1] = get_attr[target=_param_constant8]\n",
            "    %_param_constant9_1 : [num_users=1] = get_attr[target=_param_constant9]\n",
            "    %_param_constant10_1 : [num_users=1] = get_attr[target=_param_constant10]\n",
            "    return (view_60, view_55, view_56, _frozen_param0, _param_constant6_1, _param_constant7_1, _param_constant8_1, _param_constant9_1, _param_constant10_1)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.view_to_reshape:Graph after replacing view with reshape:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg0_1, %_param_constant0, %_param_constant1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %_param_constant2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant2, %_param_constant3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant4, %_param_constant5, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_1 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg1_1, %_param_constant0_1, %_param_constant1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %_param_constant2_1 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_1 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant2_1, %_param_constant3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_1 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_1 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant4_1, %_param_constant5_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_2 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_2 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %_param_constant0_2, %_param_constant1_2, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})\n",
            "    %_param_constant2_2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_2 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant2_2, %_param_constant3_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_2 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_2 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant4_2, %_param_constant5_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_3 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_3 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg3_1, %_param_constant0_3, %_param_constant1_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})\n",
            "    %_param_constant2_3 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant2_3, %_param_constant3_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_3 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_3 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant4_3, %_param_constant5_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_4 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_4 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg4_1, %_param_constant0_4, %_param_constant1_4, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})\n",
            "    %_param_constant2_4 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_4 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_13 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant2_4, %_param_constant3_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_4 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant4_4, %_param_constant5_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_1, [1, -1, 1, 200, 200]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_2, [1, -1, 4, 200, 200]), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_2, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_1,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_4 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_4, [1, -1, 1, 100, 100]), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_4, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_2,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_6 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_5, [1, -1, 4, 100, 100]), kwargs = {})\n",
            "    %permute_3 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_6, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_3,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_8 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_7, [1, -1, 1, 50, 50]), kwargs = {})\n",
            "    %permute_4 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_8, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_19 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_4,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_10 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_8, [1, -1, 4, 50, 50]), kwargs = {})\n",
            "    %permute_5 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_10, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_20 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_5,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_12 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_10, [1, -1, 1, 25, 25]), kwargs = {})\n",
            "    %permute_6 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_12, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_21 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_6,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_14 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_11, [1, -1, 4, 25, 25]), kwargs = {})\n",
            "    %permute_7 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_14, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_22 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_7,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_16 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_13, [1, -1, 1, 13, 13]), kwargs = {})\n",
            "    %permute_8 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_16, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_8,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_18 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_14, [1, -1, 4, 13, 13]), kwargs = {})\n",
            "    %permute_9 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_18, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_24 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_9,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_15, [1, 120000, 1]), kwargs = {})\n",
            "    %reshape_default_5 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_17, [1, 30000, 1]), kwargs = {})\n",
            "    %reshape_default_9 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_19, [1, 7500, 1]), kwargs = {})\n",
            "    %reshape_default_13 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_21, [1, 1875, 1]), kwargs = {})\n",
            "    %reshape_default_17 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_23, [1, 507, 1]), kwargs = {})\n",
            "    %cat_6 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%reshape_default_1, %reshape_default_5, %reshape_default_9, %reshape_default_13, %reshape_default_17], 1), kwargs = {})\n",
            "    %reshape_default_3 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_16, [1, 120000, 4]), kwargs = {})\n",
            "    %reshape_default_7 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_18, [1, 30000, 4]), kwargs = {})\n",
            "    %reshape_default_11 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_20, [1, 7500, 4]), kwargs = {})\n",
            "    %reshape_default_15 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_22, [1, 1875, 4]), kwargs = {})\n",
            "    %reshape_default_19 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_24, [1, 507, 4]), kwargs = {})\n",
            "    %cat_7 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%reshape_default_3, %reshape_default_7, %reshape_default_11, %reshape_default_15, %reshape_default_19], 1), kwargs = {})\n",
            "    %reshape_default_21 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_7, [-1, 4]), kwargs = {})\n",
            "    %reshape_default_22 : [num_users=4] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_21, [159882, -1]), kwargs = {})\n",
            "    %slice_7 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 1, 0, 9223372036854775807, 4), kwargs = {})\n",
            "    %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_8, 1.0), kwargs = {})\n",
            "    %slice_9 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_10 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_9, 1, 1, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_10, 1.0), kwargs = {})\n",
            "    %slice_11 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_12 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_11, 1, 2, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_12, 1.0), kwargs = {})\n",
            "    %slice_13 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_14 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_13, 1, 3, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_14, 1.0), kwargs = {})\n",
            "    %clamp : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_2, None, 4.135166556742356), kwargs = {})\n",
            "    %clamp_1 : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_3, None, 4.135166556742356), kwargs = {})\n",
            "    %_frozen_param1 : [num_users=1] = get_attr[target=_frozen_param1]\n",
            "    %mul_12 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div, %_frozen_param1), kwargs = {})\n",
            "    %_frozen_param2 : [num_users=1] = get_attr[target=_frozen_param2]\n",
            "    %add_7 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_12, %_frozen_param2), kwargs = {})\n",
            "    %_frozen_param3 : [num_users=1] = get_attr[target=_frozen_param3]\n",
            "    %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %_frozen_param3), kwargs = {})\n",
            "    %_frozen_param4 : [num_users=1] = get_attr[target=_frozen_param4]\n",
            "    %add_8 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_13, %_frozen_param4), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp,), kwargs = {})\n",
            "    %_frozen_param5 : [num_users=1] = get_attr[target=_frozen_param5]\n",
            "    %mul_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp, %_frozen_param5), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp_1,), kwargs = {})\n",
            "    %_frozen_param6 : [num_users=1] = get_attr[target=_frozen_param6]\n",
            "    %mul_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp_1, %_frozen_param6), kwargs = {})\n",
            "    %_frozen_param7 : [num_users=1] = get_attr[target=_frozen_param7]\n",
            "    %mul_16 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_frozen_param7, %mul_15), kwargs = {})\n",
            "    %_frozen_param8 : [num_users=1] = get_attr[target=_frozen_param8]\n",
            "    %mul_17 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_frozen_param8, %mul_14), kwargs = {})\n",
            "    %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %add_10 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %unsqueeze_26 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_2, 2), kwargs = {})\n",
            "    %unsqueeze_27 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_3, 2), kwargs = {})\n",
            "    %unsqueeze_28 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_9, 2), kwargs = {})\n",
            "    %unsqueeze_29 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_10, 2), kwargs = {})\n",
            "    %cat_9 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_26, %unsqueeze_27, %unsqueeze_28, %unsqueeze_29], 2), kwargs = {})\n",
            "    %reshape_default_23 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_9, [159882, 4]), kwargs = {})\n",
            "    %reshape_default_24 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_23, [159882, -1, 4]), kwargs = {})\n",
            "    %_param_constant6_1 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %_param_constant7_1 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %_param_constant8_1 : [num_users=1] = get_attr[target=_param_constant8]\n",
            "    %_param_constant9_1 : [num_users=1] = get_attr[target=_param_constant9]\n",
            "    %_param_constant10_1 : [num_users=1] = get_attr[target=_param_constant10]\n",
            "    %reshape_default_20 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_6, [159882, 1]), kwargs = {})\n",
            "    %reshape_default_25 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_24, [1, -1, 4]), kwargs = {})\n",
            "    return (reshape_default_25, reshape_default_20, reshape_default_21, _frozen_param0, _param_constant6_1, _param_constant7_1, _param_constant8_1, _param_constant9_1, _param_constant10_1)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg0_1, %_param_constant0, %_param_constant1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %_param_constant2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant2, %_param_constant3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant4, %_param_constant5, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_1 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg1_1, %_param_constant0_1, %_param_constant1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %_param_constant2_1 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_1 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant2_1, %_param_constant3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_1 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_1 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant4_1, %_param_constant5_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_2 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_2 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %_param_constant0_2, %_param_constant1_2, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})\n",
            "    %_param_constant2_2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_2 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant2_2, %_param_constant3_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_2 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_2 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant4_2, %_param_constant5_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_3 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_3 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg3_1, %_param_constant0_3, %_param_constant1_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})\n",
            "    %_param_constant2_3 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant2_3, %_param_constant3_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_3 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_3 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant4_3, %_param_constant5_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant0_4 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_4 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg4_1, %_param_constant0_4, %_param_constant1_4, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})\n",
            "    %_param_constant2_4 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_4 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_13 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant2_4, %_param_constant3_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_4 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant4_4, %_param_constant5_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_1, [1, -1, 1, 200, 200]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_2, [1, -1, 4, 200, 200]), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_2, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_1,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_4 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_4, [1, -1, 1, 100, 100]), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_4, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_2,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_6 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_5, [1, -1, 4, 100, 100]), kwargs = {})\n",
            "    %permute_3 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_6, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_3,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_8 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_7, [1, -1, 1, 50, 50]), kwargs = {})\n",
            "    %permute_4 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_8, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_19 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_4,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_10 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_8, [1, -1, 4, 50, 50]), kwargs = {})\n",
            "    %permute_5 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_10, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_20 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_5,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_12 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_10, [1, -1, 1, 25, 25]), kwargs = {})\n",
            "    %permute_6 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_12, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_21 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_6,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_14 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_11, [1, -1, 4, 25, 25]), kwargs = {})\n",
            "    %permute_7 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_14, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_22 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_7,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_16 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_13, [1, -1, 1, 13, 13]), kwargs = {})\n",
            "    %permute_8 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_16, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_8,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_18 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_14, [1, -1, 4, 13, 13]), kwargs = {})\n",
            "    %permute_9 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_18, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_24 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_9,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_15, [1, 120000, 1]), kwargs = {})\n",
            "    %reshape_default_5 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_17, [1, 30000, 1]), kwargs = {})\n",
            "    %reshape_default_9 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_19, [1, 7500, 1]), kwargs = {})\n",
            "    %reshape_default_13 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_21, [1, 1875, 1]), kwargs = {})\n",
            "    %reshape_default_17 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_23, [1, 507, 1]), kwargs = {})\n",
            "    %cat_6 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%reshape_default_1, %reshape_default_5, %reshape_default_9, %reshape_default_13, %reshape_default_17], 1), kwargs = {})\n",
            "    %reshape_default_3 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_16, [1, 120000, 4]), kwargs = {})\n",
            "    %reshape_default_7 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_18, [1, 30000, 4]), kwargs = {})\n",
            "    %reshape_default_11 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_20, [1, 7500, 4]), kwargs = {})\n",
            "    %reshape_default_15 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_22, [1, 1875, 4]), kwargs = {})\n",
            "    %reshape_default_19 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_24, [1, 507, 4]), kwargs = {})\n",
            "    %cat_7 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%reshape_default_3, %reshape_default_7, %reshape_default_11, %reshape_default_15, %reshape_default_19], 1), kwargs = {})\n",
            "    %reshape_default_21 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_7, [-1, 4]), kwargs = {})\n",
            "    %reshape_default_22 : [num_users=4] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_21, [159882, -1]), kwargs = {})\n",
            "    %slice_7 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 1, 0, 9223372036854775807, 4), kwargs = {})\n",
            "    %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_8, 1.0), kwargs = {})\n",
            "    %slice_9 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_10 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_9, 1, 1, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_10, 1.0), kwargs = {})\n",
            "    %slice_11 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_12 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_11, 1, 2, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_12, 1.0), kwargs = {})\n",
            "    %slice_13 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_14 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_13, 1, 3, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_14, 1.0), kwargs = {})\n",
            "    %clamp : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_2, None, 4.135166556742356), kwargs = {})\n",
            "    %clamp_1 : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_3, None, 4.135166556742356), kwargs = {})\n",
            "    %_frozen_param1 : [num_users=1] = get_attr[target=_frozen_param1]\n",
            "    %mul_12 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div, %_frozen_param1), kwargs = {})\n",
            "    %_frozen_param2 : [num_users=1] = get_attr[target=_frozen_param2]\n",
            "    %add_7 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_12, %_frozen_param2), kwargs = {})\n",
            "    %_frozen_param3 : [num_users=1] = get_attr[target=_frozen_param3]\n",
            "    %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %_frozen_param3), kwargs = {})\n",
            "    %_frozen_param4 : [num_users=1] = get_attr[target=_frozen_param4]\n",
            "    %add_8 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_13, %_frozen_param4), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp,), kwargs = {})\n",
            "    %_frozen_param5 : [num_users=1] = get_attr[target=_frozen_param5]\n",
            "    %mul_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp, %_frozen_param5), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp_1,), kwargs = {})\n",
            "    %_frozen_param6 : [num_users=1] = get_attr[target=_frozen_param6]\n",
            "    %mul_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp_1, %_frozen_param6), kwargs = {})\n",
            "    %_frozen_param7 : [num_users=1] = get_attr[target=_frozen_param7]\n",
            "    %mul_16 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_frozen_param7, %mul_15), kwargs = {})\n",
            "    %_frozen_param8 : [num_users=1] = get_attr[target=_frozen_param8]\n",
            "    %mul_17 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_frozen_param8, %mul_14), kwargs = {})\n",
            "    %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %add_10 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %unsqueeze_26 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_2, 2), kwargs = {})\n",
            "    %unsqueeze_27 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_3, 2), kwargs = {})\n",
            "    %unsqueeze_28 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_9, 2), kwargs = {})\n",
            "    %unsqueeze_29 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_10, 2), kwargs = {})\n",
            "    %cat_9 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_26, %unsqueeze_27, %unsqueeze_28, %unsqueeze_29], 2), kwargs = {})\n",
            "    %reshape_default_23 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_9, [159882, 4]), kwargs = {})\n",
            "    %reshape_default_24 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_23, [159882, -1, 4]), kwargs = {})\n",
            "    %_param_constant6_1 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %_param_constant7_1 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %_param_constant8_1 : [num_users=1] = get_attr[target=_param_constant8]\n",
            "    %_param_constant9_1 : [num_users=1] = get_attr[target=_param_constant9]\n",
            "    %_param_constant10_1 : [num_users=1] = get_attr[target=_param_constant10]\n",
            "    %reshape_default_20 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_6, [159882, 1]), kwargs = {})\n",
            "    %reshape_default_25 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_24, [1, -1, 4]), kwargs = {})\n",
            "    return (reshape_default_25, reshape_default_20, reshape_default_21, _frozen_param0, _param_constant6_1, _param_constant7_1, _param_constant8_1, _param_constant9_1, _param_constant10_1)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.convolution.default + Operator Count: 15\n",
            "- torch.ops.aten.relu.default + Operator Count: 5\n",
            "- torch.ops.aten.reshape.default + Operator Count: 26\n",
            "- torch.ops.aten.permute.default + Operator Count: 10\n",
            "- torch.ops.aten.clone.default + Operator Count: 10\n",
            "- torch.ops.aten.cat.default + Operator Count: 3\n",
            "- torch.ops.aten.slice.Tensor + Operator Count: 8\n",
            "- torch.ops.aten.div.Tensor + Operator Count: 4\n",
            "- torch.ops.aten.clamp.default + Operator Count: 2\n",
            "- torch.ops.aten.mul.Tensor + Operator Count: 6\n",
            "- torch.ops.aten.add.Tensor + Operator Count: 4\n",
            "- torch.ops.aten.exp.default + Operator Count: 2\n",
            "- torch.ops.aten.sub.Tensor + Operator Count: 2\n",
            "- torch.ops.aten.unsqueeze.default + Operator Count: 4\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Detected support for 101 operators out of 101 in subgraph.\n",
            "WARNING:torch_tensorrt.dynamo._compiler:Node _param_constant0 of op type get_attr does not have metadata. This could sometimes lead to undefined behavior.\n",
            "WARNING:torch_tensorrt.dynamo._compiler:Some nodes do not have metadata (shape and dtype information). This could lead to problems sometimes if the graph has PyTorch and TensorRT segments.\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Number of TensorRT-Accelerated Engines Generated: 1\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.convolution.default + Operator Count: 15\n",
            "- torch.ops.aten.relu.default + Operator Count: 5\n",
            "- torch.ops.aten.reshape.default + Operator Count: 26\n",
            "- torch.ops.aten.permute.default + Operator Count: 10\n",
            "- torch.ops.aten.clone.default + Operator Count: 10\n",
            "- torch.ops.aten.cat.default + Operator Count: 3\n",
            "- torch.ops.aten.slice.Tensor + Operator Count: 8\n",
            "- torch.ops.aten.div.Tensor + Operator Count: 4\n",
            "- torch.ops.aten.clamp.default + Operator Count: 2\n",
            "- torch.ops.aten.mul.Tensor + Operator Count: 6\n",
            "- torch.ops.aten.add.Tensor + Operator Count: 4\n",
            "- torch.ops.aten.exp.default + Operator Count: 2\n",
            "- torch.ops.aten.sub.Tensor + Operator Count: 2\n",
            "- torch.ops.aten.unsqueeze.default + Operator Count: 4\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Submodule name: _run_on_acc_0\n",
            " Input shapes: [(1, 256, 200, 200), (1, 256, 100, 100), (1, 256, 50, 50), (1, 256, 25, 25), (1, 256, 13, 13)]\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg0_1, %_param_constant0, %_param_constant1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})\n",
            "    %_param_constant2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant2, %_param_constant3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %_param_constant4, %_param_constant5, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %_param_constant0_1 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg1_1, %_param_constant0_1, %_param_constant1_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})\n",
            "    %_param_constant2_1 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_1 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant2_1, %_param_constant3_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_1 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_1 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %_param_constant4_1, %_param_constant5_1, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %arg2_1 : [num_users=1] = placeholder[target=arg2_1]\n",
            "    %_param_constant0_2 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_2 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg2_1, %_param_constant0_2, %_param_constant1_2, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})\n",
            "    %_param_constant2_2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_2 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant2_2, %_param_constant3_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_2 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_2 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %_param_constant4_2, %_param_constant5_2, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %arg3_1 : [num_users=1] = placeholder[target=arg3_1]\n",
            "    %_param_constant0_3 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_3 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg3_1, %_param_constant0_3, %_param_constant1_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_3 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})\n",
            "    %_param_constant2_3 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant2_3, %_param_constant3_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_3 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_3 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_3, %_param_constant4_3, %_param_constant5_3, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %arg4_1 : [num_users=1] = placeholder[target=arg4_1]\n",
            "    %_param_constant0_4 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %_param_constant1_4 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%arg4_1, %_param_constant0_4, %_param_constant1_4, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %relu_4 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})\n",
            "    %_param_constant2_4 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %_param_constant3_4 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %convolution_13 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant2_4, %_param_constant3_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %_param_constant4_4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %_param_constant5_4 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %_param_constant4_4, %_param_constant5_4, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_1, [1, -1, 1, 200, 200]), kwargs = {})\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_2 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_2, [1, -1, 4, 200, 200]), kwargs = {})\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_2, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_1,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_4 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_4, [1, -1, 1, 100, 100]), kwargs = {})\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_4, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_2,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_6 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_5, [1, -1, 4, 100, 100]), kwargs = {})\n",
            "    %permute_3 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_6, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_3,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_8 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_7, [1, -1, 1, 50, 50]), kwargs = {})\n",
            "    %permute_4 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_8, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_19 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_4,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_10 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_8, [1, -1, 4, 50, 50]), kwargs = {})\n",
            "    %permute_5 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_10, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_20 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_5,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_12 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_10, [1, -1, 1, 25, 25]), kwargs = {})\n",
            "    %permute_6 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_12, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_21 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_6,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_14 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_11, [1, -1, 4, 25, 25]), kwargs = {})\n",
            "    %permute_7 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_14, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_22 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_7,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_16 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_13, [1, -1, 1, 13, 13]), kwargs = {})\n",
            "    %permute_8 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_16, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_8,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_18 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%convolution_14, [1, -1, 4, 13, 13]), kwargs = {})\n",
            "    %permute_9 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%reshape_default_18, [0, 3, 4, 1, 2]), kwargs = {})\n",
            "    %clone_24 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%permute_9,), kwargs = {memory_format: torch.contiguous_format})\n",
            "    %reshape_default_1 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_15, [1, 120000, 1]), kwargs = {})\n",
            "    %reshape_default_5 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_17, [1, 30000, 1]), kwargs = {})\n",
            "    %reshape_default_9 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_19, [1, 7500, 1]), kwargs = {})\n",
            "    %reshape_default_13 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_21, [1, 1875, 1]), kwargs = {})\n",
            "    %reshape_default_17 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_23, [1, 507, 1]), kwargs = {})\n",
            "    %cat_6 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%reshape_default_1, %reshape_default_5, %reshape_default_9, %reshape_default_13, %reshape_default_17], 1), kwargs = {})\n",
            "    %reshape_default_3 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_16, [1, 120000, 4]), kwargs = {})\n",
            "    %reshape_default_7 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_18, [1, 30000, 4]), kwargs = {})\n",
            "    %reshape_default_11 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_20, [1, 7500, 4]), kwargs = {})\n",
            "    %reshape_default_15 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_22, [1, 1875, 4]), kwargs = {})\n",
            "    %reshape_default_19 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%clone_24, [1, 507, 4]), kwargs = {})\n",
            "    %cat_7 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%reshape_default_3, %reshape_default_7, %reshape_default_11, %reshape_default_15, %reshape_default_19], 1), kwargs = {})\n",
            "    %reshape_default_21 : [num_users=2] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_7, [-1, 4]), kwargs = {})\n",
            "    %reshape_default_22 : [num_users=4] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_21, [159882, -1]), kwargs = {})\n",
            "    %slice_7 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_8 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_7, 1, 0, 9223372036854775807, 4), kwargs = {})\n",
            "    %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_8, 1.0), kwargs = {})\n",
            "    %slice_9 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_10 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_9, 1, 1, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_10, 1.0), kwargs = {})\n",
            "    %slice_11 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_12 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_11, 1, 2, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_2 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_12, 1.0), kwargs = {})\n",
            "    %slice_13 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%reshape_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %slice_14 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%slice_13, 1, 3, 9223372036854775807, 4), kwargs = {})\n",
            "    %div_3 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%slice_14, 1.0), kwargs = {})\n",
            "    %clamp : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_2, None, 4.135166556742356), kwargs = {})\n",
            "    %clamp_1 : [num_users=1] = call_function[target=torch.ops.aten.clamp.default](args = (%div_3, None, 4.135166556742356), kwargs = {})\n",
            "    %_frozen_param1 : [num_users=1] = get_attr[target=_frozen_param1]\n",
            "    %mul_12 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div, %_frozen_param1), kwargs = {})\n",
            "    %_frozen_param2 : [num_users=1] = get_attr[target=_frozen_param2]\n",
            "    %add_7 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_12, %_frozen_param2), kwargs = {})\n",
            "    %_frozen_param3 : [num_users=1] = get_attr[target=_frozen_param3]\n",
            "    %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%div_1, %_frozen_param3), kwargs = {})\n",
            "    %_frozen_param4 : [num_users=1] = get_attr[target=_frozen_param4]\n",
            "    %add_8 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_13, %_frozen_param4), kwargs = {})\n",
            "    %exp : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp,), kwargs = {})\n",
            "    %_frozen_param5 : [num_users=1] = get_attr[target=_frozen_param5]\n",
            "    %mul_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp, %_frozen_param5), kwargs = {})\n",
            "    %exp_1 : [num_users=1] = call_function[target=torch.ops.aten.exp.default](args = (%clamp_1,), kwargs = {})\n",
            "    %_frozen_param6 : [num_users=1] = get_attr[target=_frozen_param6]\n",
            "    %mul_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%exp_1, %_frozen_param6), kwargs = {})\n",
            "    %_frozen_param7 : [num_users=1] = get_attr[target=_frozen_param7]\n",
            "    %mul_16 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_frozen_param7, %mul_15), kwargs = {})\n",
            "    %_frozen_param8 : [num_users=1] = get_attr[target=_frozen_param8]\n",
            "    %mul_17 : [num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_frozen_param8, %mul_14), kwargs = {})\n",
            "    %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_7, %mul_17), kwargs = {})\n",
            "    %add_10 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_8, %mul_16), kwargs = {})\n",
            "    %unsqueeze_26 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_2, 2), kwargs = {})\n",
            "    %unsqueeze_27 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%sub_3, 2), kwargs = {})\n",
            "    %unsqueeze_28 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_9, 2), kwargs = {})\n",
            "    %unsqueeze_29 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%add_10, 2), kwargs = {})\n",
            "    %cat_9 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_26, %unsqueeze_27, %unsqueeze_28, %unsqueeze_29], 2), kwargs = {})\n",
            "    %reshape_default_23 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_9, [159882, 4]), kwargs = {})\n",
            "    %reshape_default_24 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_23, [159882, -1, 4]), kwargs = {})\n",
            "    %reshape_default_20 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%cat_6, [159882, 1]), kwargs = {})\n",
            "    %reshape_default_25 : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%reshape_default_24, [1, -1, 4]), kwargs = {})\n",
            "    return (reshape_default_25, reshape_default_20, reshape_default_21)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg0_1 [shape=[1, 256, 200, 200], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution (kind: aten.convolution.default, args: ('arg0_1 <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu (kind: aten.relu.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_1 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(3, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(3,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_2 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu]_output <tensorrt.ITensor [shape=(1, 256, 200, 200), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(12, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(12,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg1_1 [shape=[1, 256, 100, 100], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_3 (kind: aten.convolution.default, args: ('arg1_1 <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_1 (kind: aten.relu.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_3]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_4 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_1]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(3, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(3,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_5 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_1]_output <tensorrt.ITensor [shape=(1, 256, 100, 100), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(12, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(12,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg2_1 [shape=[1, 256, 50, 50], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_6 (kind: aten.convolution.default, args: ('arg2_1 <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_2 (kind: aten.relu.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_6]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_7 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_2]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(3, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(3,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_8 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_2]_output <tensorrt.ITensor [shape=(1, 256, 50, 50), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(12, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(12,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg3_1 [shape=[1, 256, 25, 25], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_9 (kind: aten.convolution.default, args: ('arg3_1 <tensorrt.ITensor [shape=(1, 256, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_3 (kind: aten.relu.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_9]_output <tensorrt.ITensor [shape=(1, 256, 25, 25), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_10 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_3]_output <tensorrt.ITensor [shape=(1, 256, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(3, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(3,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_11 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_3]_output <tensorrt.ITensor [shape=(1, 256, 25, 25), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(12, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(12,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg4_1 [shape=[1, 256, 13, 13], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_12 (kind: aten.convolution.default, args: ('arg4_1 <tensorrt.ITensor [shape=(1, 256, 13, 13), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(256, 256, 3, 3), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(256,), dtype=float32]>', [1, 1], [1, 1], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_4 (kind: aten.relu.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_12]_output <tensorrt.ITensor [shape=(1, 256, 13, 13), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_13 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_4]_output <tensorrt.ITensor [shape=(1, 256, 13, 13), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(3, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(3,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node convolution_14 (kind: aten.convolution.default, args: ('[RELU]-[aten_ops.relu.default]-[relu_4]_output <tensorrt.ITensor [shape=(1, 256, 13, 13), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(12, 256, 1, 1), dtype=float32]>', '<torch.Tensor as np.ndarray [shape=(12,), dtype=float32]>', [1, 1], [0, 0], [1, 1], False, [0, 0], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_1]_output <tensorrt.ITensor [shape=(1, 3, 200, 200), dtype=DataType.FLOAT]>', [1, -1, 1, 200, 200]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default]_output <tensorrt.ITensor [shape=(1, 3, 1, 200, 200), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_15 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute]_output <tensorrt.ITensor [shape=(1, 200, 200, 3, 1), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_2 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_2]_output <tensorrt.ITensor [shape=(1, 12, 200, 200), dtype=DataType.FLOAT]>', [1, -1, 4, 200, 200]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_1 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_2]_output <tensorrt.ITensor [shape=(1, 3, 4, 200, 200), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_16 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_1]_output <tensorrt.ITensor [shape=(1, 200, 200, 3, 4), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_4 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_4]_output <tensorrt.ITensor [shape=(1, 3, 100, 100), dtype=DataType.FLOAT]>', [1, -1, 1, 100, 100]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_2 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_4]_output <tensorrt.ITensor [shape=(1, 3, 1, 100, 100), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_17 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_2]_output <tensorrt.ITensor [shape=(1, 100, 100, 3, 1), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_6 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_5]_output <tensorrt.ITensor [shape=(1, 12, 100, 100), dtype=DataType.FLOAT]>', [1, -1, 4, 100, 100]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_3 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_6]_output <tensorrt.ITensor [shape=(1, 3, 4, 100, 100), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_18 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_3]_output <tensorrt.ITensor [shape=(1, 100, 100, 3, 4), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_8 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_7]_output <tensorrt.ITensor [shape=(1, 3, 50, 50), dtype=DataType.FLOAT]>', [1, -1, 1, 50, 50]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_4 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_8]_output <tensorrt.ITensor [shape=(1, 3, 1, 50, 50), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_19 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_4]_output <tensorrt.ITensor [shape=(1, 50, 50, 3, 1), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_10 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_8]_output <tensorrt.ITensor [shape=(1, 12, 50, 50), dtype=DataType.FLOAT]>', [1, -1, 4, 50, 50]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_5 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_10]_output <tensorrt.ITensor [shape=(1, 3, 4, 50, 50), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_20 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_5]_output <tensorrt.ITensor [shape=(1, 50, 50, 3, 4), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_12 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_10]_output <tensorrt.ITensor [shape=(1, 3, 25, 25), dtype=DataType.FLOAT]>', [1, -1, 1, 25, 25]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_6 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_12]_output <tensorrt.ITensor [shape=(1, 3, 1, 25, 25), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_21 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_6]_output <tensorrt.ITensor [shape=(1, 25, 25, 3, 1), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_14 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_11]_output <tensorrt.ITensor [shape=(1, 12, 25, 25), dtype=DataType.FLOAT]>', [1, -1, 4, 25, 25]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_7 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_14]_output <tensorrt.ITensor [shape=(1, 3, 4, 25, 25), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_22 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_7]_output <tensorrt.ITensor [shape=(1, 25, 25, 3, 4), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_16 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_13]_output <tensorrt.ITensor [shape=(1, 3, 13, 13), dtype=DataType.FLOAT]>', [1, -1, 1, 13, 13]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_8 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_16]_output <tensorrt.ITensor [shape=(1, 3, 1, 13, 13), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_23 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_8]_output <tensorrt.ITensor [shape=(1, 13, 13, 3, 1), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_18 (kind: aten.reshape.default, args: ('[CONVOLUTION]-[aten_ops.convolution.default]-[convolution_14]_output <tensorrt.ITensor [shape=(1, 12, 13, 13), dtype=DataType.FLOAT]>', [1, -1, 4, 13, 13]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node permute_9 (kind: aten.permute.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_18]_output <tensorrt.ITensor [shape=(1, 3, 4, 13, 13), dtype=DataType.FLOAT]>', [0, 3, 4, 1, 2]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clone_24 (kind: aten.clone.default, args: ('[SHUFFLE]-[aten_ops.permute.default]-[permute_9]_output <tensorrt.ITensor [shape=(1, 13, 13, 3, 4), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_1 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_15]_output <tensorrt.ITensor [shape=(1, 200, 200, 3, 1), dtype=DataType.FLOAT]>', [1, 120000, 1]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_5 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_2]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_17]_output <tensorrt.ITensor [shape=(1, 100, 100, 3, 1), dtype=DataType.FLOAT]>', [1, 30000, 1]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_9 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_4]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_19]_output <tensorrt.ITensor [shape=(1, 50, 50, 3, 1), dtype=DataType.FLOAT]>', [1, 7500, 1]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_13 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_6]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_21]_output <tensorrt.ITensor [shape=(1, 25, 25, 3, 1), dtype=DataType.FLOAT]>', [1, 1875, 1]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_17 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_8]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_23]_output <tensorrt.ITensor [shape=(1, 13, 13, 3, 1), dtype=DataType.FLOAT]>', [1, 507, 1]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node cat_6 (kind: aten.cat.default, args: (['[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_1]_output <tensorrt.ITensor [shape=(1, 120000, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_5]_output <tensorrt.ITensor [shape=(1, 30000, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_9]_output <tensorrt.ITensor [shape=(1, 7500, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_13]_output <tensorrt.ITensor [shape=(1, 1875, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_17]_output <tensorrt.ITensor [shape=(1, 507, 1), dtype=DataType.FLOAT]>'], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_3 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_1]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_16]_output <tensorrt.ITensor [shape=(1, 200, 200, 3, 4), dtype=DataType.FLOAT]>', [1, 120000, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_7 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_3]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_18]_output <tensorrt.ITensor [shape=(1, 100, 100, 3, 4), dtype=DataType.FLOAT]>', [1, 30000, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_11 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_5]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_20]_output <tensorrt.ITensor [shape=(1, 50, 50, 3, 4), dtype=DataType.FLOAT]>', [1, 7500, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_15 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_7]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_22]_output <tensorrt.ITensor [shape=(1, 25, 25, 3, 4), dtype=DataType.FLOAT]>', [1, 1875, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_19 (kind: aten.reshape.default, args: ('Forced Cast ITensor [SHUFFLE]-[aten_ops.permute.default]-[permute_9]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[clone_24]_output <tensorrt.ITensor [shape=(1, 13, 13, 3, 4), dtype=DataType.FLOAT]>', [1, 507, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node cat_7 (kind: aten.cat.default, args: (['[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_3]_output <tensorrt.ITensor [shape=(1, 120000, 4), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_7]_output <tensorrt.ITensor [shape=(1, 30000, 4), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_11]_output <tensorrt.ITensor [shape=(1, 7500, 4), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_15]_output <tensorrt.ITensor [shape=(1, 1875, 4), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_19]_output <tensorrt.ITensor [shape=(1, 507, 4), dtype=DataType.FLOAT]>'], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_21 (kind: aten.reshape.default, args: ('[CONCATENATION]-[aten_ops.cat.default]-[cat_7_gather]_output <tensorrt.ITensor [shape=(1, 159882, 4), dtype=DataType.FLOAT]>', [-1, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_22 (kind: aten.reshape.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_21]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', [159882, -1]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_7 (kind: aten.slice.Tensor, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_22]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', 0, 0, 9223372036854775807))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_8 (kind: aten.slice.Tensor, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_7]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', 1, 0, 9223372036854775807, 4))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node div (kind: aten.div.Tensor, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_8]_output <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', 1.0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_9 (kind: aten.slice.Tensor, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_22]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', 0, 0, 9223372036854775807))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_10 (kind: aten.slice.Tensor, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_9]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', 1, 1, 9223372036854775807, 4))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node div_1 (kind: aten.div.Tensor, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_10]_output <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', 1.0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_11 (kind: aten.slice.Tensor, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_22]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', 0, 0, 9223372036854775807))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_12 (kind: aten.slice.Tensor, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_11]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', 1, 2, 9223372036854775807, 4))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node div_2 (kind: aten.div.Tensor, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_12]_output <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', 1.0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_13 (kind: aten.slice.Tensor, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_22]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', 0, 0, 9223372036854775807))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_14 (kind: aten.slice.Tensor, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_13]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', 1, 3, 9223372036854775807, 4))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node div_3 (kind: aten.div.Tensor, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_14]_output <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', 1.0))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clamp (kind: aten.clamp.default, args: ('[ELEMENTWISE]-[aten_ops.div.Tensor]-[div_2]_output_div.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', None, 4.135166556742356))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node clamp_1 (kind: aten.clamp.default, args: ('[ELEMENTWISE]-[aten_ops.div.Tensor]-[div_3]_output_div.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', None, 4.135166556742356))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_12 (kind: aten.mul.Tensor, args: ('[ELEMENTWISE]-[aten_ops.div.Tensor]-[div]_output_div.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(159882, 1), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_7 (kind: aten.add.Tensor, args: ('[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_12]_output_mul.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(159882, 1), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_13 (kind: aten.mul.Tensor, args: ('[ELEMENTWISE]-[aten_ops.div.Tensor]-[div_1]_output_div.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(159882, 1), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_8 (kind: aten.add.Tensor, args: ('[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_13]_output_mul.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(159882, 1), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node exp (kind: aten.exp.default, args: ('[ELEMENTWISE]-[aten_ops.clamp.default]-[clamp_min]_output_clamp.default <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_14 (kind: aten.mul.Tensor, args: ('[UNARY]-[aten_ops.exp.default]-[exp]_output_exp.default <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(159882, 1), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node exp_1 (kind: aten.exp.default, args: ('[ELEMENTWISE]-[aten_ops.clamp.default]-[clamp_1_min]_output_clamp.default <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_15 (kind: aten.mul.Tensor, args: ('[UNARY]-[aten_ops.exp.default]-[exp_1]_output_exp.default <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(159882, 1), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_16 (kind: aten.mul.Tensor, args: ('<torch.Tensor as np.ndarray [shape=(), dtype=float32]>', '[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_15]_output_mul.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_17 (kind: aten.mul.Tensor, args: ('<torch.Tensor as np.ndarray [shape=(), dtype=float32]>', '[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_14]_output_mul.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node sub_2 (kind: aten.sub.Tensor, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_7]_output_add.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_17]_output_mul.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node sub_3 (kind: aten.sub.Tensor, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_8]_output_add.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_16]_output_mul.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_9 (kind: aten.add.Tensor, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_7]_output_add.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_17]_output_mul.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_10 (kind: aten.add.Tensor, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_8]_output_add.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', '[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_16]_output_mul.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze_26 (kind: aten.unsqueeze.default, args: ('[ELEMENTWISE]-[aten_ops.sub.Tensor]-[sub_2]_output_sub.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', 2))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze_27 (kind: aten.unsqueeze.default, args: ('[ELEMENTWISE]-[aten_ops.sub.Tensor]-[sub_3]_output_sub.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', 2))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze_28 (kind: aten.unsqueeze.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_9]_output_add.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', 2))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze_29 (kind: aten.unsqueeze.default, args: ('[ELEMENTWISE]-[aten_ops.add.Tensor]-[add_10]_output_add.Tensor <tensorrt.ITensor [shape=(159882, 1), dtype=DataType.FLOAT]>', 2))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node cat_9 (kind: aten.cat.default, args: (['[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze_26]_output <tensorrt.ITensor [shape=(159882, 1, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze_27]_output <tensorrt.ITensor [shape=(159882, 1, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze_28]_output <tensorrt.ITensor [shape=(159882, 1, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze_29]_output <tensorrt.ITensor [shape=(159882, 1, 1), dtype=DataType.FLOAT]>'], 2))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_23 (kind: aten.reshape.default, args: ('[CONCATENATION]-[aten_ops.cat.default]-[cat_9_gather]_output <tensorrt.ITensor [shape=(159882, 1, 4), dtype=DataType.FLOAT]>', [159882, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_24 (kind: aten.reshape.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_23]_output <tensorrt.ITensor [shape=(159882, 4), dtype=DataType.FLOAT]>', [159882, -1, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_20 (kind: aten.reshape.default, args: ('[CONCATENATION]-[aten_ops.cat.default]-[cat_6_gather]_output <tensorrt.ITensor [shape=(1, 159882, 1), dtype=DataType.FLOAT]>', [159882, 1]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default_25 (kind: aten.reshape.default, args: ('[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default_24]_output <tensorrt.ITensor [shape=(159882, 1, 4), dtype=DataType.FLOAT]>', [1, -1, 4]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output0 [shape=(1, 159882, 4), dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output1 [shape=(159882, 1), dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output2 [shape=(159882, 4), dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.455186\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:22.104894\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 10642124 bytes of Memory\n",
            "DEBUG:torch_tensorrt.dynamo._DryRunTracker:\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++ Dry-Run Results for Graph ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "The graph consists of 101 Total Operators, of which 101 operators are supported, 100.0% coverage\n",
            "\n",
            "Compiled with: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "  Graph Structure:\n",
            "\n",
            "   Inputs: List[Tensor: (1, 256, 200, 200)@float32, Tensor: (1, 256, 100, 100)@float32, Tensor: (1, 256, 50, 50)@float32, Tensor: (1, 256, 25, 25)@float32, Tensor: (1, 256, 13, 13)@float32]\n",
            "    ...\n",
            "    TRT Engine #1 - Submodule name: _run_on_acc_0\n",
            "     Engine Inputs: List[Tensor: (1, 256, 200, 200)@float32, Tensor: (1, 256, 100, 100)@float32, Tensor: (1, 256, 50, 50)@float32, Tensor: (1, 256, 25, 25)@float32, Tensor: (1, 256, 13, 13)@float32]\n",
            "     Number of Operators in Engine: 101\n",
            "     Engine Outputs: Tuple(Tensor: (1, 159882, 4)@float32, Tensor: (159882, 1)@float32, Tensor: (159882, 4)@float32)\n",
            "    ...\n",
            "   Outputs: Tuple(Tensor: (1, 159882, 4)@float32, Tensor: (159882, 1)@float32, Tensor: (159882, 4)@float32, Tensor: (159882, 4)@float32, Tensor: (3, 4)@float32, Tensor: (3, 4)@float32, Tensor: (3, 4)@float32, Tensor: (3, 4)@float32, Tensor: (3, 4)@float32)\n",
            "\n",
            "  ------------------------- Aggregate Stats -------------------------\n",
            "\n",
            "   Average Number of Operators per TRT Engine: 101.0\n",
            "   Most Operators in a TRT Engine: 101\n",
            "\n",
            "  ********** Recommendations **********\n",
            "\n",
            "   - For minimal graph segmentation, select min_block_size=101 which would generate 1 TRT engine(s)\n",
            "   - The current level of graph segmentation is equivalent to selecting min_block_size=101 which generates 1 TRT engine(s)\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %l_objectness_ : torch.Tensor [num_users=1] = placeholder[target=L_objectness_]\n",
            "    %split : [num_users=5] = call_method[target=split](args = (%l_objectness_, [120000, 30000, 7500, 1875, 507], 1), kwargs = {})\n",
            "    %ob : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n",
            "    %ob_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n",
            "    %ob_2 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 2), kwargs = {})\n",
            "    %ob_3 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 3), kwargs = {})\n",
            "    %ob_4 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 4), kwargs = {})\n",
            "    %topk : [num_users=1] = call_method[target=topk](args = (%ob, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx : [num_users=1] = call_function[target=operator.getitem](args = (%topk, 1), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx, 0), kwargs = {})\n",
            "    %topk_1 : [num_users=1] = call_method[target=topk](args = (%ob_1, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_1 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_1, 120000), kwargs = {})\n",
            "    %topk_2 : [num_users=1] = call_method[target=topk](args = (%ob_2, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_2 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_2, 1), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_2, 150000), kwargs = {})\n",
            "    %topk_3 : [num_users=1] = call_method[target=topk](args = (%ob_3, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_3 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_3, 1), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_3, 157500), kwargs = {})\n",
            "    %topk_4 : [num_users=1] = call_method[target=topk](args = (%ob_4, 507), kwargs = {dim: 1})\n",
            "    %top_n_idx_4 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_4, 1), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_4, 159375), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.cat](args = ([%add, %add_1, %add_2, %add_3, %add_4],), kwargs = {dim: 1})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %l_objectness_ : torch.Tensor [num_users=1] = placeholder[target=L_objectness_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_objectness_,), kwargs = {})\n",
            "    %split : [num_users=5] = call_method[target=split](args = (%clone_default, [120000, 30000, 7500, 1875, 507], 1), kwargs = {})\n",
            "    %ob : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n",
            "    %ob_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n",
            "    %ob_2 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 2), kwargs = {})\n",
            "    %ob_3 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 3), kwargs = {})\n",
            "    %ob_4 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 4), kwargs = {})\n",
            "    %topk : [num_users=1] = call_method[target=topk](args = (%ob, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx : [num_users=1] = call_function[target=operator.getitem](args = (%topk, 1), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx, 0), kwargs = {})\n",
            "    %topk_1 : [num_users=1] = call_method[target=topk](args = (%ob_1, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_1 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_1, 120000), kwargs = {})\n",
            "    %topk_2 : [num_users=1] = call_method[target=topk](args = (%ob_2, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_2 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_2, 1), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_2, 150000), kwargs = {})\n",
            "    %topk_3 : [num_users=1] = call_method[target=topk](args = (%ob_3, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_3 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_3, 1), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_3, 157500), kwargs = {})\n",
            "    %topk_4 : [num_users=1] = call_method[target=topk](args = (%ob_4, 507), kwargs = {dim: 1})\n",
            "    %top_n_idx_4 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_4, 1), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_4, 159375), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.cat](args = ([%add, %add_1, %add_2, %add_3, %add_4],), kwargs = {dim: 1})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %l_objectness_ : torch.Tensor [num_users=1] = placeholder[target=L_objectness_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_objectness_,), kwargs = {})\n",
            "    %split : [num_users=5] = call_method[target=split](args = (%clone_default, [120000, 30000, 7500, 1875, 507], 1), kwargs = {})\n",
            "    %ob : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n",
            "    %ob_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n",
            "    %ob_2 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 2), kwargs = {})\n",
            "    %ob_3 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 3), kwargs = {})\n",
            "    %ob_4 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 4), kwargs = {})\n",
            "    %topk : [num_users=1] = call_method[target=topk](args = (%ob, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx : [num_users=1] = call_function[target=operator.getitem](args = (%topk, 1), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx, 0), kwargs = {})\n",
            "    %topk_1 : [num_users=1] = call_method[target=topk](args = (%ob_1, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_1 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_1, 120000), kwargs = {})\n",
            "    %topk_2 : [num_users=1] = call_method[target=topk](args = (%ob_2, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_2 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_2, 1), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_2, 150000), kwargs = {})\n",
            "    %topk_3 : [num_users=1] = call_method[target=topk](args = (%ob_3, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_3 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_3, 1), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_3, 157500), kwargs = {})\n",
            "    %topk_4 : [num_users=1] = call_method[target=topk](args = (%ob_4, 507), kwargs = {dim: 1})\n",
            "    %top_n_idx_4 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_4, 1), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_4, 159375), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.cat](args = ([%add, %add_1, %add_2, %add_3, %add_4],), kwargs = {dim: 1})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %l_objectness_ : torch.Tensor [num_users=1] = placeholder[target=L_objectness_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_objectness_,), kwargs = {})\n",
            "    %split : [num_users=5] = call_method[target=split](args = (%clone_default, [120000, 30000, 7500, 1875, 507], 1), kwargs = {})\n",
            "    %ob : [num_users=1] = call_function[target=operator.getitem](args = (%split, 0), kwargs = {})\n",
            "    %ob_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 1), kwargs = {})\n",
            "    %ob_2 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 2), kwargs = {})\n",
            "    %ob_3 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 3), kwargs = {})\n",
            "    %ob_4 : [num_users=1] = call_function[target=operator.getitem](args = (%split, 4), kwargs = {})\n",
            "    %topk : [num_users=1] = call_method[target=topk](args = (%ob, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx : [num_users=1] = call_function[target=operator.getitem](args = (%topk, 1), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx, 0), kwargs = {})\n",
            "    %topk_1 : [num_users=1] = call_method[target=topk](args = (%ob_1, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_1 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_1, 120000), kwargs = {})\n",
            "    %topk_2 : [num_users=1] = call_method[target=topk](args = (%ob_2, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_2 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_2, 1), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_2, 150000), kwargs = {})\n",
            "    %topk_3 : [num_users=1] = call_method[target=topk](args = (%ob_3, 1000), kwargs = {dim: 1})\n",
            "    %top_n_idx_3 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_3, 1), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_3, 157500), kwargs = {})\n",
            "    %topk_4 : [num_users=1] = call_method[target=topk](args = (%ob_4, 507), kwargs = {dim: 1})\n",
            "    %top_n_idx_4 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_4, 1), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%top_n_idx_4, 159375), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.cat](args = ([%add, %add_1, %add_2, %add_3, %add_4],), kwargs = {dim: 1})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %split_with_sizes : [num_users=5] = call_function[target=torch.ops.aten.split_with_sizes.default](args = (%clone, [120000, 30000, 7500, 1875, 507], 1), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 0), kwargs = {})\n",
            "    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 1), kwargs = {})\n",
            "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 2), kwargs = {})\n",
            "    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 3), kwargs = {})\n",
            "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 4), kwargs = {})\n",
            "    %topk : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem, 1000, 1), kwargs = {})\n",
            "    %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%topk, 1), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_6, 0), kwargs = {})\n",
            "    %topk_1 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_1, 1000, 1), kwargs = {})\n",
            "    %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_8, 120000), kwargs = {})\n",
            "    %topk_2 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_2, 1000, 1), kwargs = {})\n",
            "    %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_2, 1), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_10, 150000), kwargs = {})\n",
            "    %topk_3 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_3, 1000, 1), kwargs = {})\n",
            "    %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_3, 1), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_12, 157500), kwargs = {})\n",
            "    %topk_4 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_4, 507, 1), kwargs = {})\n",
            "    %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_4, 1), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_14, 159375), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%add, %add_1, %add_2, %add_3, %add_4], 1), kwargs = {})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %split_with_sizes : [num_users=5] = call_function[target=torch.ops.aten.split_with_sizes.default](args = (%arg0_1, [120000, 30000, 7500, 1875, 507], 1), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 0), kwargs = {})\n",
            "    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 1), kwargs = {})\n",
            "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 2), kwargs = {})\n",
            "    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 3), kwargs = {})\n",
            "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 4), kwargs = {})\n",
            "    %topk : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem, 1000, 1), kwargs = {})\n",
            "    %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%topk, 1), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_6, 0), kwargs = {})\n",
            "    %topk_1 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_1, 1000, 1), kwargs = {})\n",
            "    %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_8, 120000), kwargs = {})\n",
            "    %topk_2 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_2, 1000, 1), kwargs = {})\n",
            "    %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_2, 1), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_10, 150000), kwargs = {})\n",
            "    %topk_3 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_3, 1000, 1), kwargs = {})\n",
            "    %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_3, 1), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_12, 157500), kwargs = {})\n",
            "    %topk_4 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_4, 507, 1), kwargs = {})\n",
            "    %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_4, 1), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_14, 159375), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%add, %add_1, %add_2, %add_3, %add_4], 1), kwargs = {})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %split_with_sizes : [num_users=5] = call_function[target=torch.ops.aten.split_with_sizes.default](args = (%arg0_1, [120000, 30000, 7500, 1875, 507], 1), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 0), kwargs = {})\n",
            "    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 1), kwargs = {})\n",
            "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 2), kwargs = {})\n",
            "    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 3), kwargs = {})\n",
            "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 4), kwargs = {})\n",
            "    %topk : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem, 1000, 1), kwargs = {})\n",
            "    %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%topk, 1), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_6, 0), kwargs = {})\n",
            "    %topk_1 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_1, 1000, 1), kwargs = {})\n",
            "    %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_8, 120000), kwargs = {})\n",
            "    %topk_2 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_2, 1000, 1), kwargs = {})\n",
            "    %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_2, 1), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_10, 150000), kwargs = {})\n",
            "    %topk_3 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_3, 1000, 1), kwargs = {})\n",
            "    %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_3, 1), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_12, 157500), kwargs = {})\n",
            "    %topk_4 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_4, 507, 1), kwargs = {})\n",
            "    %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_4, 1), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_14, 159375), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%add, %add_1, %add_2, %add_3, %add_4], 1), kwargs = {})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %split_with_sizes : [num_users=5] = call_function[target=torch.ops.aten.split_with_sizes.default](args = (%arg0_1, [120000, 30000, 7500, 1875, 507], 1), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 0), kwargs = {})\n",
            "    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 1), kwargs = {})\n",
            "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 2), kwargs = {})\n",
            "    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 3), kwargs = {})\n",
            "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%split_with_sizes, 4), kwargs = {})\n",
            "    %topk : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem, 1000, 1), kwargs = {})\n",
            "    %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%topk, 1), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_6, 0), kwargs = {})\n",
            "    %topk_1 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_1, 1000, 1), kwargs = {})\n",
            "    %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_8, 120000), kwargs = {})\n",
            "    %topk_2 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_2, 1000, 1), kwargs = {})\n",
            "    %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_2, 1), kwargs = {})\n",
            "    %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_10, 150000), kwargs = {})\n",
            "    %topk_3 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_3, 1000, 1), kwargs = {})\n",
            "    %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_3, 1), kwargs = {})\n",
            "    %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_12, 157500), kwargs = {})\n",
            "    %topk_4 : [num_users=1] = call_function[target=torch.ops.aten.topk.default](args = (%getitem_4, 507, 1), kwargs = {})\n",
            "    %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%topk_4, 1), kwargs = {})\n",
            "    %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_14, 159375), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%add, %add_1, %add_2, %add_3, %add_4], 1), kwargs = {})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.split_with_sizes.default + Operator Count: 1\n",
            "- _operator.getitem + Operator Count: 5\n",
            "- torch.ops.aten.add.Tensor + Operator Count: 5\n",
            "- torch.ops.aten.cat.default + Operator Count: 1\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Unsupported or Excluded Nodes:\n",
            "- torch.ops.aten.topk.default + Operator Count: 5\n",
            "- _operator.getitem + Operator Count: 5\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Detected support for 12 operators out of 22 in subgraph.\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:Eliminating acc subgraph because it's smaller than the threshold: 6 < 7\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:Eliminating acc subgraph because it's smaller than the threshold: 6 < 7\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Number of TensorRT-Accelerated Engines Generated: 0\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.split_with_sizes.default + Operator Count: 1\n",
            "- _operator.getitem + Operator Count: 5\n",
            "- torch.ops.aten.add.Tensor + Operator Count: 5\n",
            "- torch.ops.aten.cat.default + Operator Count: 1\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Unsupported or Excluded Nodes:\n",
            "- torch.ops.aten.topk.default + Operator Count: 5\n",
            "- _operator.getitem + Operator Count: 5\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._DryRunTracker:\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++ Dry-Run Results for Graph ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "The graph consists of 22 Total Operators, of which 12 operators are supported, 54.55% coverage\n",
            "\n",
            "The following ops are currently unsupported or excluded from conversion, and are listed with their op-count in the graph:\n",
            " torch.ops.aten.topk.default: 5\n",
            "_operator.getitem: 5\n",
            "\n",
            "The following nodes are currently set to run in Torch:\n",
            "Node: torch.ops.aten.split_with_sizes.default, with layer location: split_with_sizes\n",
            "Node: torch.ops.aten.topk.default, with layer location: topk\n",
            "Node: torch.ops.aten.add.Tensor, with layer location: add\n",
            "Node: torch.ops.aten.topk.default, with layer location: topk_1\n",
            "Node: torch.ops.aten.add.Tensor, with layer location: add_1\n",
            "Node: torch.ops.aten.topk.default, with layer location: topk_2\n",
            "Node: torch.ops.aten.add.Tensor, with layer location: add_2\n",
            "Node: torch.ops.aten.topk.default, with layer location: topk_3\n",
            "Node: torch.ops.aten.add.Tensor, with layer location: add_3\n",
            "Node: torch.ops.aten.topk.default, with layer location: topk_4\n",
            "Node: torch.ops.aten.add.Tensor, with layer location: add_4\n",
            "Node: torch.ops.aten.cat.default, with layer location: cat\n",
            "Note: Some of the above nodes may be supported, but were not included in a TRT graph by the partitioner\n",
            "\n",
            "Compiled with: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "  Graph Structure:\n",
            "\n",
            "   Inputs: List[Tensor: (1, 159882)@float32]\n",
            "    ...\n",
            "   Outputs: Tuple(Tensor: (1, 4507)@int64)\n",
            "\n",
            "  Aggregate stats not available since no TRT Engines were generated.\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/_library/abstract_impl.py:127: UserWarning: create_unbacked_symint is deprecated, please use new_dynamic_size instead\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.batched_nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.batched_nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.batched_nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.batched_nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "WARNING:torch_tensorrt.dynamo._compiler:0 supported operations detected in subgraph containing 0 computational nodes. Skipping this subgraph, since min_block_size was detected to be 7\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/_library/abstract_impl.py:127: UserWarning: create_unbacked_symint is deprecated, please use new_dynamic_size instead\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %l_boxes_ : torch.Tensor [num_users=4] = placeholder[target=L_boxes_]\n",
            "    %l_idxs_ : torch.Tensor [num_users=1] = placeholder[target=L_idxs_]\n",
            "    %max_coordinate : [num_users=1] = call_method[target=max](args = (%l_boxes_,), kwargs = {})\n",
            "    %to : [num_users=1] = call_method[target=to](args = (%l_idxs_, %l_boxes_), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (1,), kwargs = {})\n",
            "    %to_1 : [num_users=1] = call_method[target=to](args = (%tensor, %l_boxes_), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%max_coordinate, %to_1), kwargs = {})\n",
            "    %offsets : [num_users=1] = call_function[target=operator.mul](args = (%to, %add), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%offsets, (slice(None, None, None), None)), kwargs = {})\n",
            "    %boxes_for_nms : [num_users=1] = call_function[target=operator.add](args = (%l_boxes_, %getitem), kwargs = {})\n",
            "    return (boxes_for_nms,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %l_boxes_ : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_idxs_ : torch.Tensor [num_users=1] = placeholder[target=L_idxs_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_idxs_,), kwargs = {})\n",
            "    %clone_default : [num_users=4] = call_function[target=torch.ops.aten.clone.default](args = (%l_boxes_,), kwargs = {})\n",
            "    %max_coordinate : [num_users=1] = call_method[target=max](args = (%clone_default,), kwargs = {})\n",
            "    %to : [num_users=1] = call_method[target=to](args = (%clone_default_1, %clone_default), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (1,), kwargs = {})\n",
            "    %to_1 : [num_users=1] = call_method[target=to](args = (%tensor, %clone_default), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%max_coordinate, %to_1), kwargs = {})\n",
            "    %offsets : [num_users=1] = call_function[target=operator.mul](args = (%to, %add), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%offsets, (slice(None, None, None), None)), kwargs = {})\n",
            "    %boxes_for_nms : [num_users=1] = call_function[target=operator.add](args = (%clone_default, %getitem), kwargs = {})\n",
            "    return (boxes_for_nms,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %l_boxes_ : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_idxs_ : torch.Tensor [num_users=1] = placeholder[target=L_idxs_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_idxs_,), kwargs = {})\n",
            "    %clone_default : [num_users=4] = call_function[target=torch.ops.aten.clone.default](args = (%l_boxes_,), kwargs = {})\n",
            "    %max_coordinate : [num_users=1] = call_method[target=max](args = (%clone_default,), kwargs = {})\n",
            "    %to : [num_users=1] = call_method[target=to](args = (%clone_default_1, %clone_default), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (1,), kwargs = {})\n",
            "    %to_1 : [num_users=1] = call_method[target=to](args = (%tensor, %clone_default), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%max_coordinate, %to_1), kwargs = {})\n",
            "    %offsets : [num_users=1] = call_function[target=operator.mul](args = (%to, %add), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%offsets, (slice(None, None, None), None)), kwargs = {})\n",
            "    %boxes_for_nms : [num_users=1] = call_function[target=operator.add](args = (%clone_default, %getitem), kwargs = {})\n",
            "    return (boxes_for_nms,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %l_boxes_ : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_idxs_ : torch.Tensor [num_users=1] = placeholder[target=L_idxs_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_idxs_,), kwargs = {})\n",
            "    %clone_default : [num_users=4] = call_function[target=torch.ops.aten.clone.default](args = (%l_boxes_,), kwargs = {})\n",
            "    %max_coordinate : [num_users=1] = call_method[target=max](args = (%clone_default,), kwargs = {})\n",
            "    %to : [num_users=1] = call_method[target=to](args = (%clone_default_1, %clone_default), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (1,), kwargs = {})\n",
            "    %to_1 : [num_users=1] = call_method[target=to](args = (%tensor, %clone_default), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%max_coordinate, %to_1), kwargs = {})\n",
            "    %offsets : [num_users=1] = call_function[target=operator.mul](args = (%to, %add), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%offsets, (slice(None, None, None), None)), kwargs = {})\n",
            "    %boxes_for_nms : [num_users=1] = call_function[target=operator.add](args = (%clone_default, %getitem), kwargs = {})\n",
            "    return (boxes_for_nms,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg1_1,), kwargs = {})\n",
            "    %clone_1 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%clone_1,), kwargs = {})\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%clone,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
            "    %lift_fresh_copy : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant0,), kwargs = {})\n",
            "    %_to_copy_1 : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%lift_fresh_copy,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_to_copy_1), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%clone_1, %unsqueeze), kwargs = {})\n",
            "    return (add_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_1 from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg1_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=2] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%arg0_1,), kwargs = {})\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%arg1_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
            "    %lift_fresh_copy : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant0,), kwargs = {})\n",
            "    %_to_copy_1 : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%lift_fresh_copy,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_to_copy_1), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %unsqueeze), kwargs = {})\n",
            "    return (add_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=2] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%arg0_1,), kwargs = {})\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%arg1_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_frozen_param0), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %unsqueeze), kwargs = {})\n",
            "    return (add_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=2] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%arg0_1,), kwargs = {})\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%arg1_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_frozen_param0), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %unsqueeze), kwargs = {})\n",
            "    return (add_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.max.default + Operator Count: 1\n",
            "- torch.ops.aten._to_copy.default + Operator Count: 1\n",
            "- torch.ops.aten.add.Tensor + Operator Count: 2\n",
            "- torch.ops.aten.mul.Tensor + Operator Count: 1\n",
            "- torch.ops.aten.slice.Tensor + Operator Count: 1\n",
            "- torch.ops.aten.unsqueeze.default + Operator Count: 1\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Detected support for 7 operators out of 7 in subgraph.\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Number of TensorRT-Accelerated Engines Generated: 1\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.max.default + Operator Count: 1\n",
            "- torch.ops.aten._to_copy.default + Operator Count: 1\n",
            "- torch.ops.aten.add.Tensor + Operator Count: 2\n",
            "- torch.ops.aten.mul.Tensor + Operator Count: 1\n",
            "- torch.ops.aten.slice.Tensor + Operator Count: 1\n",
            "- torch.ops.aten.unsqueeze.default + Operator Count: 1\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Submodule name: _run_on_acc_0\n",
            " Input shapes: [(4090, 4), (4090,)]\n",
            " graph():\n",
            "    %arg0_1 : [num_users=2] = placeholder[target=arg0_1]\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%arg0_1,), kwargs = {})\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%arg1_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_frozen_param0), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %unsqueeze), kwargs = {})\n",
            "    return add_1\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg0_1 [shape=[4090, 4], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node max_1 (kind: aten.max.default, args: ('arg0_1 <tensorrt.ITensor [shape=(4090, 4), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg1_1 [shape=[4090], dtype=DataType.INT64]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _to_copy (kind: aten._to_copy.default, args: ('arg1_1 <tensorrt.ITensor [shape=(4090,), dtype=DataType.INT64]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add (kind: aten.add.Tensor, args: ('[REDUCE]-[aten_ops.max.default]-[max_1]_output <tensorrt.ITensor [shape=(), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul (kind: aten.mul.Tensor, args: ('Forced Cast ITensor arg1_1 from DataType.INT64 to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[_to_copy]_output <tensorrt.ITensor [shape=(4090,), dtype=DataType.FLOAT]>', '[ELEMENTWISE]-[aten_ops.add.Tensor]-[add]_output_add.Tensor <tensorrt.ITensor [shape=(), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_1 (kind: aten.slice.Tensor, args: ('[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul]_output_mul.Tensor <tensorrt.ITensor [shape=(4090,), dtype=DataType.FLOAT]>', 0, 0, 9223372036854775807))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze (kind: aten.unsqueeze.default, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_1]_output <tensorrt.ITensor [shape=(4090,), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_1 (kind: aten.add.Tensor, args: ('arg0_1 <tensorrt.ITensor [shape=(4090, 4), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze]_output <tensorrt.ITensor [shape=(4090, 1), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output0 [shape=(4090, 4), dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.020515\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:00.156491\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 17084 bytes of Memory\n",
            "DEBUG:torch_tensorrt.dynamo._DryRunTracker:\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++ Dry-Run Results for Graph ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "The graph consists of 7 Total Operators, of which 7 operators are supported, 100.0% coverage\n",
            "\n",
            "Compiled with: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "  Graph Structure:\n",
            "\n",
            "   Inputs: List[Tensor: (4090, 4)@float32, Tensor: (4090,)@int64]\n",
            "    ...\n",
            "    TRT Engine #1 - Submodule name: _run_on_acc_0\n",
            "     Engine Inputs: List[Tensor: (4090, 4)@float32, Tensor: (4090,)@int64]\n",
            "     Number of Operators in Engine: 7\n",
            "     Engine Outputs: Tensor: (4090, 4)@float32\n",
            "    ...\n",
            "   Outputs: Tuple(Tensor: (4090, 4)@float32)\n",
            "\n",
            "  ------------------------- Aggregate Stats -------------------------\n",
            "\n",
            "   Average Number of Operators per TRT Engine: 7.0\n",
            "   Most Operators in a TRT Engine: 7\n",
            "\n",
            "  ********** Recommendations **********\n",
            "\n",
            "   - For minimal graph segmentation, select min_block_size=7 which would generate 1 TRT engine(s)\n",
            "   - The current level of graph segmentation is equivalent to selecting min_block_size=7 which generates 1 TRT engine(s)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/_library/abstract_impl.py:127: UserWarning: create_unbacked_symint is deprecated, please use new_dynamic_size instead\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "WARNING:torch_tensorrt.dynamo._compiler:0 supported operations detected in subgraph containing 0 computational nodes. Skipping this subgraph, since min_block_size was detected to be 7\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%l_input_, %rois, 0.25, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.25, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.25, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.25, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg1_1,), kwargs = {})\n",
            "    %clone_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%clone, %clone_1, 0.25, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_1 from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg1_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.25, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.25, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.25, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Unsupported or Excluded Nodes:\n",
            "- torch.ops.torchvision.roi_align.default + Operator Count: 1\n",
            "\n",
            "WARNING:torch_tensorrt.dynamo._compiler:0 supported operations detected in subgraph containing 1 computational nodes. Skipping this subgraph, since min_block_size was detected to be 7\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%l_input_, %rois, 0.125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg1_1,), kwargs = {})\n",
            "    %clone_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%clone, %clone_1, 0.125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_1 from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg1_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Unsupported or Excluded Nodes:\n",
            "- torch.ops.torchvision.roi_align.default + Operator Count: 1\n",
            "\n",
            "WARNING:torch_tensorrt.dynamo._compiler:0 supported operations detected in subgraph containing 1 computational nodes. Skipping this subgraph, since min_block_size was detected to be 7\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%l_input_, %rois, 0.0625, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.0625, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.0625, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.0625, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg1_1,), kwargs = {})\n",
            "    %clone_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%clone, %clone_1, 0.0625, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_1 from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg1_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.0625, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.0625, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.0625, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Unsupported or Excluded Nodes:\n",
            "- torch.ops.torchvision.roi_align.default + Operator Count: 1\n",
            "\n",
            "WARNING:torch_tensorrt.dynamo._compiler:0 supported operations detected in subgraph containing 1 computational nodes. Skipping this subgraph, since min_block_size was detected to be 7\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%l_input_, %rois, 0.03125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.03125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.03125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %rois : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_input_ : torch.Tensor [num_users=1] = placeholder[target=L_input_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_input_,), kwargs = {})\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%rois,), kwargs = {})\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.roi_align.roi_align,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align](args = (%clone_default_1, %clone_default, 0.03125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg1_1,), kwargs = {})\n",
            "    %clone_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%clone, %clone_1, 0.03125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_1 from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg1_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.03125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.03125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %roi_align : [num_users=1] = call_function[target=torch.ops.torchvision.roi_align.default](args = (%arg1_1, %arg0_1, 0.03125, 7, 7, 2, False), kwargs = {})\n",
            "    return (roi_align,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Unsupported or Excluded Nodes:\n",
            "- torch.ops.torchvision.roi_align.default + Operator Count: 1\n",
            "\n",
            "WARNING:torch_tensorrt.dynamo._compiler:0 supported operations detected in subgraph containing 1 computational nodes. Skipping this subgraph, since min_block_size was detected to be 7\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %box_features : torch.Tensor [num_users=1] = placeholder[target=L_stack0_]\n",
            "    %x : [num_users=1] = call_method[target=flatten](args = (%box_features,), kwargs = {start_dim: 1})\n",
            "    %l__self___box_head_fc6 : [num_users=1] = call_module[target=L__self___box_head_fc6](args = (%x,), kwargs = {})\n",
            "    %x_1 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%l__self___box_head_fc6,), kwargs = {})\n",
            "    %l__self___box_head_fc7 : [num_users=1] = call_module[target=L__self___box_head_fc7](args = (%x_1,), kwargs = {})\n",
            "    %box_features_1 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%l__self___box_head_fc7,), kwargs = {})\n",
            "    %x_3 : [num_users=2] = call_method[target=flatten](args = (%box_features_1,), kwargs = {start_dim: 1})\n",
            "    %class_logits : [num_users=1] = call_module[target=L__self___box_predictor_cls_score](args = (%x_3,), kwargs = {})\n",
            "    %box_regression : [num_users=1] = call_module[target=L__self___box_predictor_bbox_pred](args = (%x_3,), kwargs = {})\n",
            "    return (class_logits, box_regression)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %box_features : torch.Tensor [num_users=1] = placeholder[target=L_stack0_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%box_features,), kwargs = {})\n",
            "    %x : [num_users=1] = call_method[target=flatten](args = (%clone_default,), kwargs = {start_dim: 1})\n",
            "    %l__self___box_head_fc6 : [num_users=1] = call_module[target=L__self___box_head_fc6](args = (%x,), kwargs = {})\n",
            "    %x_1 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%l__self___box_head_fc6,), kwargs = {})\n",
            "    %l__self___box_head_fc7 : [num_users=1] = call_module[target=L__self___box_head_fc7](args = (%x_1,), kwargs = {})\n",
            "    %box_features_1 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%l__self___box_head_fc7,), kwargs = {})\n",
            "    %x_3 : [num_users=2] = call_method[target=flatten](args = (%box_features_1,), kwargs = {start_dim: 1})\n",
            "    %class_logits : [num_users=1] = call_module[target=L__self___box_predictor_cls_score](args = (%x_3,), kwargs = {})\n",
            "    %box_regression : [num_users=1] = call_module[target=L__self___box_predictor_bbox_pred](args = (%x_3,), kwargs = {})\n",
            "    return (class_logits, box_regression)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %box_features : torch.Tensor [num_users=1] = placeholder[target=L_stack0_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%box_features,), kwargs = {})\n",
            "    %x : [num_users=1] = call_method[target=flatten](args = (%clone_default,), kwargs = {start_dim: 1})\n",
            "    %l__self___box_head_fc6 : [num_users=1] = call_module[target=L__self___box_head_fc6](args = (%x,), kwargs = {})\n",
            "    %x_1 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%l__self___box_head_fc6,), kwargs = {})\n",
            "    %l__self___box_head_fc7 : [num_users=1] = call_module[target=L__self___box_head_fc7](args = (%x_1,), kwargs = {})\n",
            "    %box_features_1 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%l__self___box_head_fc7,), kwargs = {})\n",
            "    %x_3 : [num_users=2] = call_method[target=flatten](args = (%box_features_1,), kwargs = {start_dim: 1})\n",
            "    %class_logits : [num_users=1] = call_module[target=L__self___box_predictor_cls_score](args = (%x_3,), kwargs = {})\n",
            "    %box_regression : [num_users=1] = call_module[target=L__self___box_predictor_bbox_pred](args = (%x_3,), kwargs = {})\n",
            "    return (class_logits, box_regression)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %box_features : torch.Tensor [num_users=1] = placeholder[target=L_stack0_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%box_features,), kwargs = {})\n",
            "    %x : [num_users=1] = call_method[target=flatten](args = (%clone_default,), kwargs = {start_dim: 1})\n",
            "    %l__self___box_head_fc6 : [num_users=1] = call_module[target=L__self___box_head_fc6](args = (%x,), kwargs = {})\n",
            "    %x_1 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%l__self___box_head_fc6,), kwargs = {})\n",
            "    %l__self___box_head_fc7 : [num_users=1] = call_module[target=L__self___box_head_fc7](args = (%x_1,), kwargs = {})\n",
            "    %box_features_1 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%l__self___box_head_fc7,), kwargs = {})\n",
            "    %x_3 : [num_users=2] = call_method[target=flatten](args = (%box_features_1,), kwargs = {start_dim: 1})\n",
            "    %class_logits : [num_users=1] = call_module[target=L__self___box_predictor_cls_score](args = (%x_3,), kwargs = {})\n",
            "    %box_regression : [num_users=1] = call_module[target=L__self___box_predictor_bbox_pred](args = (%x_3,), kwargs = {})\n",
            "    return (class_logits, box_regression)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%clone, [1000, 12544]), kwargs = {})\n",
            "    %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%_param_constant0, [1, 0]), kwargs = {})\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant1, %view, %permute), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %_param_constant2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%_param_constant2, [1, 0]), kwargs = {})\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant3, %relu, %permute_1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %_param_constant4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%_param_constant4, [1, 0]), kwargs = {})\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant5, %relu_1, %permute_2), kwargs = {})\n",
            "    %_param_constant6 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %permute_3 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%_param_constant6, [1, 0]), kwargs = {})\n",
            "    %_param_constant7 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %addmm_3 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant7, %relu_1, %permute_3), kwargs = {})\n",
            "    return (addmm_2, addmm_3)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%arg0_1, [1000, 12544]), kwargs = {})\n",
            "    %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\n",
            "    %permute : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%_param_constant0, [1, 0]), kwargs = {})\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant1, %view, %permute), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %_param_constant2 : [num_users=1] = get_attr[target=_param_constant2]\n",
            "    %permute_1 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%_param_constant2, [1, 0]), kwargs = {})\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant3, %relu, %permute_1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %_param_constant4 : [num_users=1] = get_attr[target=_param_constant4]\n",
            "    %permute_2 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%_param_constant4, [1, 0]), kwargs = {})\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant5, %relu_1, %permute_2), kwargs = {})\n",
            "    %_param_constant6 : [num_users=1] = get_attr[target=_param_constant6]\n",
            "    %permute_3 : [num_users=1] = call_function[target=torch.ops.aten.permute.default](args = (%_param_constant6, [1, 0]), kwargs = {})\n",
            "    %_param_constant7 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %addmm_3 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant7, %relu_1, %permute_3), kwargs = {})\n",
            "    return (addmm_2, addmm_3)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %view : [num_users=1] = call_function[target=torch.ops.aten.view.default](args = (%arg0_1, [1000, 12544]), kwargs = {})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant1, %view, %_frozen_param0), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %_frozen_param1 : [num_users=1] = get_attr[target=_frozen_param1]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant3, %relu, %_frozen_param1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %_frozen_param2 : [num_users=1] = get_attr[target=_frozen_param2]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant5, %relu_1, %_frozen_param2), kwargs = {})\n",
            "    %_frozen_param3 : [num_users=1] = get_attr[target=_frozen_param3]\n",
            "    %_param_constant7 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %addmm_3 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant7, %relu_1, %_frozen_param3), kwargs = {})\n",
            "    return (addmm_2, addmm_3)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.view_to_reshape:Graph after replacing view with reshape:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%arg0_1, [1000, 12544]), kwargs = {})\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant1, %reshape_default, %_frozen_param0), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %_frozen_param1 : [num_users=1] = get_attr[target=_frozen_param1]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant3, %relu, %_frozen_param1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %_frozen_param2 : [num_users=1] = get_attr[target=_frozen_param2]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant5, %relu_1, %_frozen_param2), kwargs = {})\n",
            "    %_frozen_param3 : [num_users=1] = get_attr[target=_frozen_param3]\n",
            "    %_param_constant7 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %addmm_3 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant7, %relu_1, %_frozen_param3), kwargs = {})\n",
            "    return (addmm_2, addmm_3)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%arg0_1, [1000, 12544]), kwargs = {})\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant1, %reshape_default, %_frozen_param0), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %_frozen_param1 : [num_users=1] = get_attr[target=_frozen_param1]\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant3, %relu, %_frozen_param1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %_frozen_param2 : [num_users=1] = get_attr[target=_frozen_param2]\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant5, %relu_1, %_frozen_param2), kwargs = {})\n",
            "    %_frozen_param3 : [num_users=1] = get_attr[target=_frozen_param3]\n",
            "    %_param_constant7 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %addmm_3 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant7, %relu_1, %_frozen_param3), kwargs = {})\n",
            "    return (addmm_2, addmm_3)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.reshape.default + Operator Count: 1\n",
            "- torch.ops.aten.addmm.default + Operator Count: 4\n",
            "- torch.ops.aten.relu.default + Operator Count: 2\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Detected support for 7 operators out of 7 in subgraph.\n",
            "WARNING:torch_tensorrt.dynamo._compiler:Node _param_constant1 of op type get_attr does not have metadata. This could sometimes lead to undefined behavior.\n",
            "WARNING:torch_tensorrt.dynamo._compiler:Some nodes do not have metadata (shape and dtype information). This could lead to problems sometimes if the graph has PyTorch and TensorRT segments.\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Number of TensorRT-Accelerated Engines Generated: 1\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.reshape.default + Operator Count: 1\n",
            "- torch.ops.aten.addmm.default + Operator Count: 4\n",
            "- torch.ops.aten.relu.default + Operator Count: 2\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Submodule name: _run_on_acc_0\n",
            " Input shapes: [(1000, 256, 7, 7)]\n",
            " graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %reshape_default : [num_users=1] = call_function[target=torch.ops.aten.reshape.default](args = (%arg0_1, [1000, 12544]), kwargs = {})\n",
            "    %_param_constant1 : [num_users=1] = get_attr[target=_param_constant1]\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %addmm : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant1, %reshape_default, %_frozen_param0), kwargs = {})\n",
            "    %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%addmm,), kwargs = {})\n",
            "    %_param_constant3 : [num_users=1] = get_attr[target=_param_constant3]\n",
            "    %_frozen_param1 : [num_users=1] = get_attr[target=_frozen_param1]\n",
            "    %addmm_1 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant3, %relu, %_frozen_param1), kwargs = {})\n",
            "    %relu_1 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%addmm_1,), kwargs = {})\n",
            "    %_param_constant5 : [num_users=1] = get_attr[target=_param_constant5]\n",
            "    %_frozen_param2 : [num_users=1] = get_attr[target=_frozen_param2]\n",
            "    %addmm_2 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant5, %relu_1, %_frozen_param2), kwargs = {})\n",
            "    %_param_constant7 : [num_users=1] = get_attr[target=_param_constant7]\n",
            "    %_frozen_param3 : [num_users=1] = get_attr[target=_frozen_param3]\n",
            "    %addmm_3 : [num_users=1] = call_function[target=torch.ops.aten.addmm.default](args = (%_param_constant7, %relu_1, %_frozen_param3), kwargs = {})\n",
            "    return (addmm_2, addmm_3)\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg0_1 [shape=[1000, 256, 7, 7], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node reshape_default (kind: aten.reshape.default, args: ('arg0_1 <tensorrt.ITensor [shape=(1000, 256, 7, 7), dtype=DataType.FLOAT]>', [1000, 12544]))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node addmm (kind: aten.addmm.default, args: ('<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default]_output <tensorrt.ITensor [shape=(1000, 12544), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(12544, 1024), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.converter_utils:Freezing tensor addmm_constant_0 to TRT IConstantLayer\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.addmm.default]-[addmm_add]_output_addmm.default <tensorrt.ITensor [shape=(1000, 1024), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node addmm_1 (kind: aten.addmm.default, args: ('<torch.Tensor as np.ndarray [shape=(1024,), dtype=float32]>', '[RELU]-[aten_ops.relu.default]-[relu]_output <tensorrt.ITensor [shape=(1000, 1024), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 1024), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.converter_utils:Freezing tensor addmm_1_constant_0 to TRT IConstantLayer\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node relu_1 (kind: aten.relu.default, args: ('[ELEMENTWISE]-[aten_ops.addmm.default]-[addmm_1_add]_output_addmm.default <tensorrt.ITensor [shape=(1000, 1024), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node addmm_2 (kind: aten.addmm.default, args: ('<torch.Tensor as np.ndarray [shape=(2,), dtype=float32]>', '[RELU]-[aten_ops.relu.default]-[relu_1]_output <tensorrt.ITensor [shape=(1000, 1024), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 2), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.converter_utils:Freezing tensor addmm_2_constant_0 to TRT IConstantLayer\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node addmm_3 (kind: aten.addmm.default, args: ('<torch.Tensor as np.ndarray [shape=(8,), dtype=float32]>', '[RELU]-[aten_ops.relu.default]-[relu_1]_output <tensorrt.ITensor [shape=(1000, 1024), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(1024, 8), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion.converter_utils:Freezing tensor addmm_3_constant_0 to TRT IConstantLayer\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output0 [shape=(1000, 2), dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output1 [shape=(1000, 8), dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.163414\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:10.052012\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 56201444 bytes of Memory\n",
            "DEBUG:torch_tensorrt.dynamo._DryRunTracker:\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++ Dry-Run Results for Graph ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "The graph consists of 7 Total Operators, of which 7 operators are supported, 100.0% coverage\n",
            "\n",
            "Compiled with: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "  Graph Structure:\n",
            "\n",
            "   Inputs: List[Tensor: (1000, 256, 7, 7)@float32]\n",
            "    ...\n",
            "    TRT Engine #1 - Submodule name: _run_on_acc_0\n",
            "     Engine Inputs: List[Tensor: (1000, 256, 7, 7)@float32]\n",
            "     Number of Operators in Engine: 7\n",
            "     Engine Outputs: Tuple(Tensor: (1000, 2)@float32, Tensor: (1000, 8)@float32)\n",
            "    ...\n",
            "   Outputs: Tuple(Tensor: (1000, 2)@float32, Tensor: (1000, 8)@float32)\n",
            "\n",
            "  ------------------------- Aggregate Stats -------------------------\n",
            "\n",
            "   Average Number of Operators per TRT Engine: 7.0\n",
            "   Most Operators in a TRT Engine: 7\n",
            "\n",
            "  ********** Recommendations **********\n",
            "\n",
            "   - For minimal graph segmentation, select min_block_size=7 which would generate 1 TRT engine(s)\n",
            "   - The current level of graph segmentation is equivalent to selecting min_block_size=7 which generates 1 TRT engine(s)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/_library/abstract_impl.py:127: UserWarning: create_unbacked_symint is deprecated, please use new_dynamic_size instead\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.batched_nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.batched_nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.batched_nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.batched_nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "WARNING:torch_tensorrt.dynamo._compiler:0 supported operations detected in subgraph containing 0 computational nodes. Skipping this subgraph, since min_block_size was detected to be 7\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/_library/abstract_impl.py:127: UserWarning: create_unbacked_symint is deprecated, please use new_dynamic_size instead\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %l_boxes_ : torch.Tensor [num_users=4] = placeholder[target=L_boxes_]\n",
            "    %l_idxs_ : torch.Tensor [num_users=1] = placeholder[target=L_idxs_]\n",
            "    %max_coordinate : [num_users=1] = call_method[target=max](args = (%l_boxes_,), kwargs = {})\n",
            "    %to : [num_users=1] = call_method[target=to](args = (%l_idxs_, %l_boxes_), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (1,), kwargs = {})\n",
            "    %to_1 : [num_users=1] = call_method[target=to](args = (%tensor, %l_boxes_), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%max_coordinate, %to_1), kwargs = {})\n",
            "    %offsets : [num_users=1] = call_function[target=operator.mul](args = (%to, %add), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%offsets, (slice(None, None, None), None)), kwargs = {})\n",
            "    %boxes_for_nms : [num_users=1] = call_function[target=operator.add](args = (%l_boxes_, %getitem), kwargs = {})\n",
            "    return (boxes_for_nms,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %l_boxes_ : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_idxs_ : torch.Tensor [num_users=1] = placeholder[target=L_idxs_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_idxs_,), kwargs = {})\n",
            "    %clone_default : [num_users=4] = call_function[target=torch.ops.aten.clone.default](args = (%l_boxes_,), kwargs = {})\n",
            "    %max_coordinate : [num_users=1] = call_method[target=max](args = (%clone_default,), kwargs = {})\n",
            "    %to : [num_users=1] = call_method[target=to](args = (%clone_default_1, %clone_default), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (1,), kwargs = {})\n",
            "    %to_1 : [num_users=1] = call_method[target=to](args = (%tensor, %clone_default), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%max_coordinate, %to_1), kwargs = {})\n",
            "    %offsets : [num_users=1] = call_function[target=operator.mul](args = (%to, %add), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%offsets, (slice(None, None, None), None)), kwargs = {})\n",
            "    %boxes_for_nms : [num_users=1] = call_function[target=operator.add](args = (%clone_default, %getitem), kwargs = {})\n",
            "    return (boxes_for_nms,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %l_boxes_ : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_idxs_ : torch.Tensor [num_users=1] = placeholder[target=L_idxs_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_idxs_,), kwargs = {})\n",
            "    %clone_default : [num_users=4] = call_function[target=torch.ops.aten.clone.default](args = (%l_boxes_,), kwargs = {})\n",
            "    %max_coordinate : [num_users=1] = call_method[target=max](args = (%clone_default,), kwargs = {})\n",
            "    %to : [num_users=1] = call_method[target=to](args = (%clone_default_1, %clone_default), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (1,), kwargs = {})\n",
            "    %to_1 : [num_users=1] = call_method[target=to](args = (%tensor, %clone_default), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%max_coordinate, %to_1), kwargs = {})\n",
            "    %offsets : [num_users=1] = call_function[target=operator.mul](args = (%to, %add), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%offsets, (slice(None, None, None), None)), kwargs = {})\n",
            "    %boxes_for_nms : [num_users=1] = call_function[target=operator.add](args = (%clone_default, %getitem), kwargs = {})\n",
            "    return (boxes_for_nms,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %l_boxes_ : torch.Tensor [num_users=1] = placeholder[target=L_boxes_]\n",
            "    %l_idxs_ : torch.Tensor [num_users=1] = placeholder[target=L_idxs_]\n",
            "    %clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%l_idxs_,), kwargs = {})\n",
            "    %clone_default : [num_users=4] = call_function[target=torch.ops.aten.clone.default](args = (%l_boxes_,), kwargs = {})\n",
            "    %max_coordinate : [num_users=1] = call_method[target=max](args = (%clone_default,), kwargs = {})\n",
            "    %to : [num_users=1] = call_method[target=to](args = (%clone_default_1, %clone_default), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (1,), kwargs = {})\n",
            "    %to_1 : [num_users=1] = call_method[target=to](args = (%tensor, %clone_default), kwargs = {})\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%max_coordinate, %to_1), kwargs = {})\n",
            "    %offsets : [num_users=1] = call_function[target=operator.mul](args = (%to, %add), kwargs = {})\n",
            "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%offsets, (slice(None, None, None), None)), kwargs = {})\n",
            "    %boxes_for_nms : [num_users=1] = call_function[target=operator.add](args = (%clone_default, %getitem), kwargs = {})\n",
            "    return (boxes_for_nms,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %clone : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%arg1_1,), kwargs = {})\n",
            "    %clone_1 : [num_users=2] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%clone_1,), kwargs = {})\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%clone,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
            "    %lift_fresh_copy : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant0,), kwargs = {})\n",
            "    %_to_copy_1 : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%lift_fresh_copy,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_to_copy_1), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%clone_1, %unsqueeze), kwargs = {})\n",
            "    return (add_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone_1 from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg1_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=2] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%arg0_1,), kwargs = {})\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%arg1_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
            "    %lift_fresh_copy : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant0,), kwargs = {})\n",
            "    %_to_copy_1 : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%lift_fresh_copy,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_to_copy_1), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %unsqueeze), kwargs = {})\n",
            "    return (add_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=2] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%arg0_1,), kwargs = {})\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%arg1_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_frozen_param0), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %unsqueeze), kwargs = {})\n",
            "    return (add_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=2] = placeholder[target=arg0_1]\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%arg0_1,), kwargs = {})\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%arg1_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_frozen_param0), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %unsqueeze), kwargs = {})\n",
            "    return (add_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.max.default + Operator Count: 1\n",
            "- torch.ops.aten._to_copy.default + Operator Count: 1\n",
            "- torch.ops.aten.add.Tensor + Operator Count: 2\n",
            "- torch.ops.aten.mul.Tensor + Operator Count: 1\n",
            "- torch.ops.aten.slice.Tensor + Operator Count: 1\n",
            "- torch.ops.aten.unsqueeze.default + Operator Count: 1\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Detected support for 7 operators out of 7 in subgraph.\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Number of TensorRT-Accelerated Engines Generated: 1\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.max.default + Operator Count: 1\n",
            "- torch.ops.aten._to_copy.default + Operator Count: 1\n",
            "- torch.ops.aten.add.Tensor + Operator Count: 2\n",
            "- torch.ops.aten.mul.Tensor + Operator Count: 1\n",
            "- torch.ops.aten.slice.Tensor + Operator Count: 1\n",
            "- torch.ops.aten.unsqueeze.default + Operator Count: 1\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Submodule name: _run_on_acc_0\n",
            " Input shapes: [(454, 4), (454,)]\n",
            " graph():\n",
            "    %arg0_1 : [num_users=2] = placeholder[target=arg0_1]\n",
            "    %max_1 : [num_users=1] = call_function[target=torch.ops.aten.max.default](args = (%arg0_1,), kwargs = {})\n",
            "    %arg1_1 : [num_users=1] = placeholder[target=arg1_1]\n",
            "    %_to_copy : [num_users=1] = call_function[target=torch.ops.aten._to_copy.default](args = (%arg1_1,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %_frozen_param0 : [num_users=1] = get_attr[target=_frozen_param0]\n",
            "    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%max_1, %_frozen_param0), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%_to_copy, %add), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%mul, 0, 0, 9223372036854775807), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%slice_1, 1), kwargs = {})\n",
            "    %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %unsqueeze), kwargs = {})\n",
            "    return add_1\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg0_1 [shape=[454, 4], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node max_1 (kind: aten.max.default, args: ('arg0_1 <tensorrt.ITensor [shape=(454, 4), dtype=DataType.FLOAT]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg1_1 [shape=[454], dtype=DataType.INT64]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node _to_copy (kind: aten._to_copy.default, args: ('arg1_1 <tensorrt.ITensor [shape=(454,), dtype=DataType.INT64]>',))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add (kind: aten.add.Tensor, args: ('[REDUCE]-[aten_ops.max.default]-[max_1]_output <tensorrt.ITensor [shape=(), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul (kind: aten.mul.Tensor, args: ('Forced Cast ITensor arg1_1 from DataType.INT64 to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[_to_copy]_output <tensorrt.ITensor [shape=(454,), dtype=DataType.FLOAT]>', '[ELEMENTWISE]-[aten_ops.add.Tensor]-[add]_output_add.Tensor <tensorrt.ITensor [shape=(), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_1 (kind: aten.slice.Tensor, args: ('[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul]_output_mul.Tensor <tensorrt.ITensor [shape=(454,), dtype=DataType.FLOAT]>', 0, 0, 9223372036854775807))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze (kind: aten.unsqueeze.default, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_1]_output <tensorrt.ITensor [shape=(454,), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node add_1 (kind: aten.add.Tensor, args: ('arg0_1 <tensorrt.ITensor [shape=(454, 4), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze]_output <tensorrt.ITensor [shape=(454, 1), dtype=DataType.FLOAT]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output0 [shape=(454, 4), dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.018059\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:00.152821\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 16060 bytes of Memory\n",
            "DEBUG:torch_tensorrt.dynamo._DryRunTracker:\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++ Dry-Run Results for Graph ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "The graph consists of 7 Total Operators, of which 7 operators are supported, 100.0% coverage\n",
            "\n",
            "Compiled with: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "  Graph Structure:\n",
            "\n",
            "   Inputs: List[Tensor: (454, 4)@float32, Tensor: (454,)@int64]\n",
            "    ...\n",
            "    TRT Engine #1 - Submodule name: _run_on_acc_0\n",
            "     Engine Inputs: List[Tensor: (454, 4)@float32, Tensor: (454,)@int64]\n",
            "     Number of Operators in Engine: 7\n",
            "     Engine Outputs: Tensor: (454, 4)@float32\n",
            "    ...\n",
            "   Outputs: Tuple(Tensor: (454, 4)@float32)\n",
            "\n",
            "  ------------------------- Aggregate Stats -------------------------\n",
            "\n",
            "   Average Number of Operators per TRT Engine: 7.0\n",
            "   Most Operators in a TRT Engine: 7\n",
            "\n",
            "  ********** Recommendations **********\n",
            "\n",
            "   - For minimal graph segmentation, select min_block_size=7 which would generate 1 TRT engine(s)\n",
            "   - The current level of graph segmentation is equivalent to selecting min_block_size=7 which generates 1 TRT engine(s)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/_library/abstract_impl.py:127: UserWarning: create_unbacked_symint is deprecated, please use new_dynamic_size instead\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %_log_api_usage_once : [num_users=0] = call_function[target=torch._C._log_api_usage_once](args = (torchvision.ops.boxes.nms,), kwargs = {})\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    return ()\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "WARNING:torch_tensorrt.dynamo._compiler:0 supported operations detected in subgraph containing 0 computational nodes. Skipping this subgraph, since min_block_size was detected to be 7\n",
            "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
            "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
            "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Pre-AOT Autograd graph:\n",
            "graph():\n",
            "    %boxes : torch.Tensor [num_users=1] = placeholder[target=L_stack0_0_0_boxes_]\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (200,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %tensor_1 : [num_users=1] = call_function[target=torch.tensor](args = (800,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %ratio_height : [num_users=2] = call_function[target=operator.truediv](args = (%tensor, %tensor_1), kwargs = {})\n",
            "    %tensor_2 : [num_users=1] = call_function[target=torch.tensor](args = (200,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %tensor_3 : [num_users=1] = call_function[target=torch.tensor](args = (800,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %ratio_width : [num_users=2] = call_function[target=operator.truediv](args = (%tensor_2, %tensor_3), kwargs = {})\n",
            "    %unbind : [num_users=4] = call_method[target=unbind](args = (%boxes, 1), kwargs = {})\n",
            "    %xmin : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 0), kwargs = {})\n",
            "    %ymin : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 1), kwargs = {})\n",
            "    %xmax : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 2), kwargs = {})\n",
            "    %ymax : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 3), kwargs = {})\n",
            "    %xmin_1 : [num_users=1] = call_function[target=operator.mul](args = (%xmin, %ratio_width), kwargs = {})\n",
            "    %xmax_1 : [num_users=1] = call_function[target=operator.mul](args = (%xmax, %ratio_width), kwargs = {})\n",
            "    %ymin_1 : [num_users=1] = call_function[target=operator.mul](args = (%ymin, %ratio_height), kwargs = {})\n",
            "    %ymax_1 : [num_users=1] = call_function[target=operator.mul](args = (%ymax, %ratio_height), kwargs = {})\n",
            "    %boxes_1 : [num_users=1] = call_function[target=torch.stack](args = ((%xmin_1, %ymin_1, %xmax_1, %ymax_1),), kwargs = {dim: 1})\n",
            "    return (boxes_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._repair_input_aliasing:Inserted auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %boxes : torch.Tensor [num_users=1] = placeholder[target=L_stack0_0_0_boxes_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%boxes,), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (200,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %tensor_1 : [num_users=1] = call_function[target=torch.tensor](args = (800,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %ratio_height : [num_users=2] = call_function[target=operator.truediv](args = (%tensor, %tensor_1), kwargs = {})\n",
            "    %tensor_2 : [num_users=1] = call_function[target=torch.tensor](args = (200,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %tensor_3 : [num_users=1] = call_function[target=torch.tensor](args = (800,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %ratio_width : [num_users=2] = call_function[target=operator.truediv](args = (%tensor_2, %tensor_3), kwargs = {})\n",
            "    %unbind : [num_users=4] = call_method[target=unbind](args = (%clone_default, 1), kwargs = {})\n",
            "    %xmin : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 0), kwargs = {})\n",
            "    %ymin : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 1), kwargs = {})\n",
            "    %xmax : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 2), kwargs = {})\n",
            "    %ymax : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 3), kwargs = {})\n",
            "    %xmin_1 : [num_users=1] = call_function[target=operator.mul](args = (%xmin, %ratio_width), kwargs = {})\n",
            "    %xmax_1 : [num_users=1] = call_function[target=operator.mul](args = (%xmax, %ratio_width), kwargs = {})\n",
            "    %ymin_1 : [num_users=1] = call_function[target=operator.mul](args = (%ymin, %ratio_height), kwargs = {})\n",
            "    %ymax_1 : [num_users=1] = call_function[target=operator.mul](args = (%ymax, %ratio_height), kwargs = {})\n",
            "    %boxes_1 : [num_users=1] = call_function[target=torch.stack](args = ((%xmin_1, %ymin_1, %xmax_1, %ymax_1),), kwargs = {dim: 1})\n",
            "    return (boxes_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering._remove_sym_nodes:Removed SymInt placeholders:\n",
            "graph():\n",
            "    %boxes : torch.Tensor [num_users=1] = placeholder[target=L_stack0_0_0_boxes_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%boxes,), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (200,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %tensor_1 : [num_users=1] = call_function[target=torch.tensor](args = (800,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %ratio_height : [num_users=2] = call_function[target=operator.truediv](args = (%tensor, %tensor_1), kwargs = {})\n",
            "    %tensor_2 : [num_users=1] = call_function[target=torch.tensor](args = (200,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %tensor_3 : [num_users=1] = call_function[target=torch.tensor](args = (800,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %ratio_width : [num_users=2] = call_function[target=operator.truediv](args = (%tensor_2, %tensor_3), kwargs = {})\n",
            "    %unbind : [num_users=4] = call_method[target=unbind](args = (%clone_default, 1), kwargs = {})\n",
            "    %xmin : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 0), kwargs = {})\n",
            "    %ymin : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 1), kwargs = {})\n",
            "    %xmax : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 2), kwargs = {})\n",
            "    %ymax : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 3), kwargs = {})\n",
            "    %xmin_1 : [num_users=1] = call_function[target=operator.mul](args = (%xmin, %ratio_width), kwargs = {})\n",
            "    %xmax_1 : [num_users=1] = call_function[target=operator.mul](args = (%xmax, %ratio_width), kwargs = {})\n",
            "    %ymin_1 : [num_users=1] = call_function[target=operator.mul](args = (%ymin, %ratio_height), kwargs = {})\n",
            "    %ymax_1 : [num_users=1] = call_function[target=operator.mul](args = (%ymax, %ratio_height), kwargs = {})\n",
            "    %boxes_1 : [num_users=1] = call_function[target=torch.stack](args = ((%xmin_1, %ymin_1, %xmax_1, %ymax_1),), kwargs = {dim: 1})\n",
            "    return (boxes_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_detach:Removed 0 detach nodes:\n",
            "graph():\n",
            "    %boxes : torch.Tensor [num_users=1] = placeholder[target=L_stack0_0_0_boxes_]\n",
            "    %clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.default](args = (%boxes,), kwargs = {})\n",
            "    %tensor : [num_users=1] = call_function[target=torch.tensor](args = (200,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %tensor_1 : [num_users=1] = call_function[target=torch.tensor](args = (800,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %ratio_height : [num_users=2] = call_function[target=operator.truediv](args = (%tensor, %tensor_1), kwargs = {})\n",
            "    %tensor_2 : [num_users=1] = call_function[target=torch.tensor](args = (200,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %tensor_3 : [num_users=1] = call_function[target=torch.tensor](args = (800,), kwargs = {dtype: torch.float32, device: cuda:0})\n",
            "    %ratio_width : [num_users=2] = call_function[target=operator.truediv](args = (%tensor_2, %tensor_3), kwargs = {})\n",
            "    %unbind : [num_users=4] = call_method[target=unbind](args = (%clone_default, 1), kwargs = {})\n",
            "    %xmin : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 0), kwargs = {})\n",
            "    %ymin : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 1), kwargs = {})\n",
            "    %xmax : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 2), kwargs = {})\n",
            "    %ymax : [num_users=1] = call_function[target=operator.getitem](args = (%unbind, 3), kwargs = {})\n",
            "    %xmin_1 : [num_users=1] = call_function[target=operator.mul](args = (%xmin, %ratio_width), kwargs = {})\n",
            "    %xmax_1 : [num_users=1] = call_function[target=operator.mul](args = (%xmax, %ratio_width), kwargs = {})\n",
            "    %ymin_1 : [num_users=1] = call_function[target=operator.mul](args = (%ymin, %ratio_height), kwargs = {})\n",
            "    %ymax_1 : [num_users=1] = call_function[target=operator.mul](args = (%ymax, %ratio_height), kwargs = {})\n",
            "    %boxes_1 : [num_users=1] = call_function[target=torch.stack](args = ((%xmin_1, %ymin_1, %xmax_1, %ymax_1),), kwargs = {dim: 1})\n",
            "    return (boxes_1,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Post-AOT Autograd graph:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=1] = placeholder[target=arg0_1]\n",
            "    %clone : [num_users=4] = call_function[target=torch.ops.aten.clone.default](args = (%arg0_1,), kwargs = {})\n",
            "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
            "    %lift_fresh_copy : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant0,), kwargs = {})\n",
            "    %_tensor_constant1 : [num_users=1] = get_attr[target=_tensor_constant1]\n",
            "    %lift_fresh_copy_1 : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant1,), kwargs = {})\n",
            "    %div : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor](args = (%lift_fresh_copy, %lift_fresh_copy_1), kwargs = {})\n",
            "    %_tensor_constant2 : [num_users=1] = get_attr[target=_tensor_constant2]\n",
            "    %lift_fresh_copy_2 : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant2,), kwargs = {})\n",
            "    %_tensor_constant3 : [num_users=1] = get_attr[target=_tensor_constant3]\n",
            "    %lift_fresh_copy_3 : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant3,), kwargs = {})\n",
            "    %div_1 : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor](args = (%lift_fresh_copy_2, %lift_fresh_copy_3), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%clone, 1, 0, 1), kwargs = {})\n",
            "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%clone, 1, 1, 2), kwargs = {})\n",
            "    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%clone, 1, 2, 3), kwargs = {})\n",
            "    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%clone, 1, 3, 4), kwargs = {})\n",
            "    %squeeze : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_1, 1), kwargs = {})\n",
            "    %squeeze_1 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_2, 1), kwargs = {})\n",
            "    %squeeze_2 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_3, 1), kwargs = {})\n",
            "    %squeeze_3 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_4, 1), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze, %div_1), kwargs = {})\n",
            "    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_2, %div_1), kwargs = {})\n",
            "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_1, %div), kwargs = {})\n",
            "    %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_3, %div), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul, 1), kwargs = {})\n",
            "    %unsqueeze_1 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_2, 1), kwargs = {})\n",
            "    %unsqueeze_2 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_1, 1), kwargs = {})\n",
            "    %unsqueeze_3 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_3, 1), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze, %unsqueeze_1, %unsqueeze_2, %unsqueeze_3], 1), kwargs = {})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removing node clone from graph, since it is a clone node which is the only user of placeholder arg0_1 and was inserted by the compiler.\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.remove_input_alias_fixing_clones:Removed auxiliary clone nodes for placeholders:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=4] = placeholder[target=arg0_1]\n",
            "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
            "    %lift_fresh_copy : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant0,), kwargs = {})\n",
            "    %_tensor_constant1 : [num_users=1] = get_attr[target=_tensor_constant1]\n",
            "    %lift_fresh_copy_1 : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant1,), kwargs = {})\n",
            "    %div : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor](args = (%lift_fresh_copy, %lift_fresh_copy_1), kwargs = {})\n",
            "    %_tensor_constant2 : [num_users=1] = get_attr[target=_tensor_constant2]\n",
            "    %lift_fresh_copy_2 : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant2,), kwargs = {})\n",
            "    %_tensor_constant3 : [num_users=1] = get_attr[target=_tensor_constant3]\n",
            "    %lift_fresh_copy_3 : [num_users=1] = call_function[target=torch.ops.aten.lift_fresh_copy.default](args = (%_tensor_constant3,), kwargs = {})\n",
            "    %div_1 : [num_users=2] = call_function[target=torch.ops.aten.div.Tensor](args = (%lift_fresh_copy_2, %lift_fresh_copy_3), kwargs = {})\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 0, 1), kwargs = {})\n",
            "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 1, 2), kwargs = {})\n",
            "    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 2, 3), kwargs = {})\n",
            "    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 3, 4), kwargs = {})\n",
            "    %squeeze : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_1, 1), kwargs = {})\n",
            "    %squeeze_1 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_2, 1), kwargs = {})\n",
            "    %squeeze_2 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_3, 1), kwargs = {})\n",
            "    %squeeze_3 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_4, 1), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze, %div_1), kwargs = {})\n",
            "    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_2, %div_1), kwargs = {})\n",
            "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_1, %div), kwargs = {})\n",
            "    %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_3, %div), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul, 1), kwargs = {})\n",
            "    %unsqueeze_1 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_2, 1), kwargs = {})\n",
            "    %unsqueeze_2 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_1, 1), kwargs = {})\n",
            "    %unsqueeze_3 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_3, 1), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze, %unsqueeze_1, %unsqueeze_2, %unsqueeze_3], 1), kwargs = {})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.lowering.passes.constant_folding:Graph after constant folding:\n",
            "graph():\n",
            "    %arg0_1 : [num_users=4] = placeholder[target=arg0_1]\n",
            "    %_frozen_param0 : [num_users=2] = get_attr[target=_frozen_param0]\n",
            "    %_frozen_param1 : [num_users=2] = get_attr[target=_frozen_param1]\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 0, 1), kwargs = {})\n",
            "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 1, 2), kwargs = {})\n",
            "    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 2, 3), kwargs = {})\n",
            "    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 3, 4), kwargs = {})\n",
            "    %squeeze : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_1, 1), kwargs = {})\n",
            "    %squeeze_1 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_2, 1), kwargs = {})\n",
            "    %squeeze_2 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_3, 1), kwargs = {})\n",
            "    %squeeze_3 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_4, 1), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze, %_frozen_param1), kwargs = {})\n",
            "    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_2, %_frozen_param1), kwargs = {})\n",
            "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_1, %_frozen_param0), kwargs = {})\n",
            "    %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_3, %_frozen_param0), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul, 1), kwargs = {})\n",
            "    %unsqueeze_1 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_2, 1), kwargs = {})\n",
            "    %unsqueeze_2 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_1, 1), kwargs = {})\n",
            "    %unsqueeze_3 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_3, 1), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze, %unsqueeze_1, %unsqueeze_2, %unsqueeze_3], 1), kwargs = {})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.backend.backends:Lowered Input graph:\n",
            " graph():\n",
            "    %arg0_1 : [num_users=4] = placeholder[target=arg0_1]\n",
            "    %_frozen_param0 : [num_users=2] = get_attr[target=_frozen_param0]\n",
            "    %_frozen_param1 : [num_users=2] = get_attr[target=_frozen_param1]\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 0, 1), kwargs = {})\n",
            "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 1, 2), kwargs = {})\n",
            "    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 2, 3), kwargs = {})\n",
            "    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 3, 4), kwargs = {})\n",
            "    %squeeze : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_1, 1), kwargs = {})\n",
            "    %squeeze_1 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_2, 1), kwargs = {})\n",
            "    %squeeze_2 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_3, 1), kwargs = {})\n",
            "    %squeeze_3 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_4, 1), kwargs = {})\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze, %_frozen_param1), kwargs = {})\n",
            "    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_2, %_frozen_param1), kwargs = {})\n",
            "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_1, %_frozen_param0), kwargs = {})\n",
            "    %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_3, %_frozen_param0), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul, 1), kwargs = {})\n",
            "    %unsqueeze_1 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_2, 1), kwargs = {})\n",
            "    %unsqueeze_2 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_1, 1), kwargs = {})\n",
            "    %unsqueeze_3 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_3, 1), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze, %unsqueeze_1, %unsqueeze_2, %unsqueeze_3], 1), kwargs = {})\n",
            "    return (cat,)\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.slice.Tensor + Operator Count: 4\n",
            "- torch.ops.aten.squeeze.dim + Operator Count: 4\n",
            "- torch.ops.aten.mul.Tensor + Operator Count: 4\n",
            "- torch.ops.aten.unsqueeze.default + Operator Count: 4\n",
            "- torch.ops.aten.cat.default + Operator Count: 1\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._global_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Detected support for 17 operators out of 17 in subgraph.\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Number of TensorRT-Accelerated Engines Generated: 1\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "Supported Nodes:\n",
            "- torch.ops.aten.slice.Tensor + Operator Count: 4\n",
            "- torch.ops.aten.squeeze.dim + Operator Count: 4\n",
            "- torch.ops.aten.mul.Tensor + Operator Count: 4\n",
            "- torch.ops.aten.unsqueeze.default + Operator Count: 4\n",
            "- torch.ops.aten.cat.default + Operator Count: 1\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo.partitioning._adjacency_partitioner:\n",
            "All Nodes Supported\n",
            "\n",
            "DEBUG:torch_tensorrt.dynamo._compiler:Submodule name: _run_on_acc_0\n",
            " Input shapes: [(100, 4)]\n",
            " graph():\n",
            "    %arg0_1 : [num_users=4] = placeholder[target=arg0_1]\n",
            "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 0, 1), kwargs = {})\n",
            "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 1, 2), kwargs = {})\n",
            "    %slice_3 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 2, 3), kwargs = {})\n",
            "    %slice_4 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%arg0_1, 1, 3, 4), kwargs = {})\n",
            "    %squeeze : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_1, 1), kwargs = {})\n",
            "    %squeeze_1 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_2, 1), kwargs = {})\n",
            "    %squeeze_2 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_3, 1), kwargs = {})\n",
            "    %squeeze_3 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.dim](args = (%slice_4, 1), kwargs = {})\n",
            "    %_frozen_param1 : [num_users=2] = get_attr[target=_frozen_param1]\n",
            "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze, %_frozen_param1), kwargs = {})\n",
            "    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_2, %_frozen_param1), kwargs = {})\n",
            "    %_frozen_param0 : [num_users=2] = get_attr[target=_frozen_param0]\n",
            "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_1, %_frozen_param0), kwargs = {})\n",
            "    %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%squeeze_3, %_frozen_param0), kwargs = {})\n",
            "    %unsqueeze : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul, 1), kwargs = {})\n",
            "    %unsqueeze_1 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_2, 1), kwargs = {})\n",
            "    %unsqueeze_2 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_1, 1), kwargs = {})\n",
            "    %unsqueeze_3 : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze.default](args = (%mul_3, 1), kwargs = {})\n",
            "    %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze, %unsqueeze_1, %unsqueeze_2, %unsqueeze_3], 1), kwargs = {})\n",
            "    return cat\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Adding input to in-progress INetwork: arg0_1 [shape=[100, 4], dtype=DataType.FLOAT]\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_1 (kind: aten.slice.Tensor, args: ('arg0_1 <tensorrt.ITensor [shape=(100, 4), dtype=DataType.FLOAT]>', 1, 0, 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_2 (kind: aten.slice.Tensor, args: ('arg0_1 <tensorrt.ITensor [shape=(100, 4), dtype=DataType.FLOAT]>', 1, 1, 2))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_3 (kind: aten.slice.Tensor, args: ('arg0_1 <tensorrt.ITensor [shape=(100, 4), dtype=DataType.FLOAT]>', 1, 2, 3))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node slice_4 (kind: aten.slice.Tensor, args: ('arg0_1 <tensorrt.ITensor [shape=(100, 4), dtype=DataType.FLOAT]>', 1, 3, 4))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node squeeze (kind: aten.squeeze.dim, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_1]_output <tensorrt.ITensor [shape=(100, 1), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node squeeze_1 (kind: aten.squeeze.dim, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_2]_output <tensorrt.ITensor [shape=(100, 1), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node squeeze_2 (kind: aten.squeeze.dim, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_3]_output <tensorrt.ITensor [shape=(100, 1), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node squeeze_3 (kind: aten.squeeze.dim, args: ('[SLICE]-[unknown_ir_ops.slice.Tensor]-[slice_4]_output <tensorrt.ITensor [shape=(100, 1), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul (kind: aten.mul.Tensor, args: ('[SHUFFLE]-[aten_ops.squeeze.dim]-[squeeze]_output <tensorrt.ITensor [shape=(100,), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_1 (kind: aten.mul.Tensor, args: ('[SHUFFLE]-[aten_ops.squeeze.dim]-[squeeze_2]_output <tensorrt.ITensor [shape=(100,), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_2 (kind: aten.mul.Tensor, args: ('[SHUFFLE]-[aten_ops.squeeze.dim]-[squeeze_1]_output <tensorrt.ITensor [shape=(100,), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node mul_3 (kind: aten.mul.Tensor, args: ('[SHUFFLE]-[aten_ops.squeeze.dim]-[squeeze_3]_output <tensorrt.ITensor [shape=(100,), dtype=DataType.FLOAT]>', '<torch.Tensor as np.ndarray [shape=(), dtype=float32]>'))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze (kind: aten.unsqueeze.default, args: ('[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul]_output_mul.Tensor <tensorrt.ITensor [shape=(100,), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze_1 (kind: aten.unsqueeze.default, args: ('[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_2]_output_mul.Tensor <tensorrt.ITensor [shape=(100,), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze_2 (kind: aten.unsqueeze.default, args: ('[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_1]_output_mul.Tensor <tensorrt.ITensor [shape=(100,), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node unsqueeze_3 (kind: aten.unsqueeze.default, args: ('[ELEMENTWISE]-[aten_ops.mul.Tensor]-[mul_3]_output_mul.Tensor <tensorrt.ITensor [shape=(100,), dtype=DataType.FLOAT]>', 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Converting node cat (kind: aten.cat.default, args: (['[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze]_output <tensorrt.ITensor [shape=(100, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze_1]_output <tensorrt.ITensor [shape=(100, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze_2]_output <tensorrt.ITensor [shape=(100, 1), dtype=DataType.FLOAT]>', '[SHUFFLE]-[aten_ops.unsqueeze.default]-[unsqueeze_3]_output <tensorrt.ITensor [shape=(100, 1), dtype=DataType.FLOAT]>'], 1))\n",
            "DEBUG:torch_tensorrt.dynamo.conversion._TRTInterpreter:Marking output output0 [shape=(100, 4), dtype=DataType.FLOAT]\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.040412\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:00.147493\n",
            "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 35956 bytes of Memory\n",
            "DEBUG:torch_tensorrt.dynamo._DryRunTracker:\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++ Dry-Run Results for Graph ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "The graph consists of 17 Total Operators, of which 17 operators are supported, 100.0% coverage\n",
            "\n",
            "Compiled with: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=True, workspace_size=21474836480, min_block_size=7, torch_executed_ops={}, pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False)\n",
            "\n",
            "  Graph Structure:\n",
            "\n",
            "   Inputs: List[Tensor: (100, 4)@float32]\n",
            "    ...\n",
            "    TRT Engine #1 - Submodule name: _run_on_acc_0\n",
            "     Engine Inputs: List[Tensor: (100, 4)@float32]\n",
            "     Number of Operators in Engine: 17\n",
            "     Engine Outputs: Tensor: (100, 4)@float32\n",
            "    ...\n",
            "   Outputs: Tuple(Tensor: (100, 4)@float32)\n",
            "\n",
            "  ------------------------- Aggregate Stats -------------------------\n",
            "\n",
            "   Average Number of Operators per TRT Engine: 17.0\n",
            "   Most Operators in a TRT Engine: 17\n",
            "\n",
            "  ********** Recommendations **********\n",
            "\n",
            "   - For minimal graph segmentation, select min_block_size=17 which would generate 1 TRT engine(s)\n",
            "   - The current level of graph segmentation is equivalent to selecting min_block_size=17 which generates 1 TRT engine(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trt_time = %timeit -o trt_model(*inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez1TrWKBG_tR",
        "outputId": "95cc8134-36e8-486e-8bb6-232dfb42117c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26.1 ms ± 207 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "runtime = [\n",
        "    'cpu',\n",
        "    'quant',\n",
        "    'onnx',\n",
        "    'gpu',\n",
        "    'gpu half',\n",
        "    'tensorrt'\n",
        "    ]\n",
        "latency = [\n",
        "    cpu_time.average,\n",
        "    quant_time.average,\n",
        "    onnx_time.average,\n",
        "    gpu_time.average,\n",
        "    gpu_half_time.average,\n",
        "    trt_time.average\n",
        "    ]\n",
        "latency = [round(n, 3) for n in latency]\n",
        "\n",
        "ax.bar(runtime, latency)\n",
        "\n",
        "ax.set_ylabel('latency (ms)')\n",
        "ax.set_yscale('log')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "U94DlIWMG_le",
        "outputId": "90f3c99e-36be-4f17-b4f5-1d8a49d32e76"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "... half precision on the GPU is nearly as fast as TensorRT.. with TensorRT can also use half-precision to improve latency even more ..."
      ],
      "metadata": {
        "id": "q8omBOEnltfg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9XRpoZxVXYWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#| code-fold: true\n",
        "# plot latency for all methods (bar chart)"
      ],
      "metadata": {
        "id": "22ODTOhgdl_s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}